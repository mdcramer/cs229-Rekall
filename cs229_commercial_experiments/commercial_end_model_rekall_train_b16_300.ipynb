{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "data_root = '/home/rsundar/cs229/commercials_big/'\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = 3     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/rekall_train.txt'\n",
    "train_file_new_points = 'commercials/data/rekall_big_train_new.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, filename_new_points=None, load_percentage = 1):\n",
    "    # Assumes that there is no overlap in datapoints between filename and filename_new_points!\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    num_total_videos = 0\n",
    "    \n",
    "    with open(data_root + filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = sorted(list(set(videos))) # set of all videos\n",
    "        num_total_videos = len(videos)\n",
    "        num_videos = int(len(videos) * load_percentage) # number of videos to use\n",
    "        videos = videos[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "    \n",
    "    videos = []\n",
    "    if filename_new_points is not None and load_percentage > 1:\n",
    "        print(\"Fetching points from new data file\")\n",
    "        with open(data_root + filename_new_points, 'r') as f:\n",
    "\n",
    "            # find set of unique videos on file\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                videos.append(video)\n",
    "            videos = sorted(list(set(videos))) # set of all videos\n",
    "            num_videos_to_fetch = int(num_total_videos * (load_percentage - 1))\n",
    "            if num_videos_to_fetch > len(videos):\n",
    "                print(\"Trying to fetch a larger data_percentage than is available\")\n",
    "                num_videos_to_fetch = len(videos)\n",
    "            videos = videos[:num_videos_to_fetch] # take first 'num_videos'\n",
    "            f.seek(0) # go back to beginning of file\n",
    "\n",
    "            # read in data only using videos in possibly reduced set from above\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                if video in videos: # load it up only if it's in the list of videos to use\n",
    "                    paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                    labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching points from new data file\n"
     ]
    }
   ],
   "source": [
    "train_paths, Y_train = read_file(train_file, train_file_new_points, load_percentage=data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = 4,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 218839, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2722 Acc: 0.9001 Pre: 0.8163 Rec: 0.8159 F1: 0.8161 Time in epoch: 5320.0501\n",
      "TP: 48536.0 TN: 148434.0 FP: 10920.0 FN: 10949.0\n",
      "val Loss: 0.1172 Acc: 0.9707 Pre: 0.9464 Rec: 0.9532 F1: 0.9498 Time in epoch: 5404.8409\n",
      "TP: 2629.0 TN: 6572.0 FP: 149.0 FN: 129.0\n",
      "test Loss: 0.1544 Acc: 0.9530 Pre: 0.9204 Rec: 0.9321 F1: 0.9262 Time in epoch: 5471.5494\n",
      "TP: 2210.0 TN: 4934.0 FP: 191.0 FN: 161.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2428 Acc: 0.9142 Pre: 0.8392 Rec: 0.8467 F1: 0.8429 Time in epoch: 5337.0200\n",
      "TP: 50366.0 TN: 149700.0 FP: 9654.0 FN: 9119.0\n",
      "val Loss: 0.1077 Acc: 0.9765 Pre: 0.9675 Rec: 0.9511 F1: 0.9592 Time in epoch: 5421.6741\n",
      "TP: 2623.0 TN: 6633.0 FP: 88.0 FN: 135.0\n",
      "test Loss: 0.1486 Acc: 0.9569 Pre: 0.9324 Rec: 0.9313 F1: 0.9318 Time in epoch: 5488.7899\n",
      "TP: 2208.0 TN: 4965.0 FP: 160.0 FN: 163.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2327 Acc: 0.9181 Pre: 0.8456 Rec: 0.8547 F1: 0.8501 Time in epoch: 5320.9370\n",
      "TP: 50839.0 TN: 150072.0 FP: 9282.0 FN: 8646.0\n",
      "val Loss: 0.1334 Acc: 0.9711 Pre: 0.9439 Rec: 0.9576 F1: 0.9507 Time in epoch: 5405.4818\n",
      "TP: 2641.0 TN: 6564.0 FP: 157.0 FN: 117.0\n",
      "test Loss: 0.1713 Acc: 0.9520 Pre: 0.9129 Rec: 0.9376 F1: 0.9251 Time in epoch: 5472.3989\n",
      "TP: 2223.0 TN: 4913.0 FP: 212.0 FN: 148.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2263 Acc: 0.9206 Pre: 0.8498 Rec: 0.8597 F1: 0.8547 Time in epoch: 5322.3736\n",
      "TP: 51138.0 TN: 150317.0 FP: 9037.0 FN: 8347.0\n",
      "val Loss: 0.1025 Acc: 0.9736 Pre: 0.9590 Rec: 0.9500 F1: 0.9545 Time in epoch: 5407.2777\n",
      "TP: 2620.0 TN: 6609.0 FP: 112.0 FN: 138.0\n",
      "test Loss: 0.1360 Acc: 0.9586 Pre: 0.9510 Rec: 0.9165 F1: 0.9334 Time in epoch: 5474.1586\n",
      "TP: 2173.0 TN: 5013.0 FP: 112.0 FN: 198.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2197 Acc: 0.9228 Pre: 0.8537 Rec: 0.8639 F1: 0.8587 Time in epoch: 5316.7406\n",
      "TP: 51388.0 TN: 150546.0 FP: 8808.0 FN: 8097.0\n",
      "val Loss: 0.0882 Acc: 0.9758 Pre: 0.9610 Rec: 0.9558 F1: 0.9584 Time in epoch: 5400.8024\n",
      "TP: 2636.0 TN: 6614.0 FP: 107.0 FN: 122.0\n",
      "test Loss: 0.1280 Acc: 0.9586 Pre: 0.9376 Rec: 0.9313 F1: 0.9344 Time in epoch: 5467.9927\n",
      "TP: 2208.0 TN: 4978.0 FP: 147.0 FN: 163.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2174 Acc: 0.9230 Pre: 0.8547 Rec: 0.8634 F1: 0.8590 Time in epoch: 5319.1205\n",
      "TP: 51360.0 TN: 150624.0 FP: 8730.0 FN: 8125.0\n",
      "val Loss: 0.1068 Acc: 0.9724 Pre: 0.9538 Rec: 0.9511 F1: 0.9524 Time in epoch: 5406.9485\n",
      "TP: 2623.0 TN: 6594.0 FP: 127.0 FN: 135.0\n",
      "test Loss: 0.1397 Acc: 0.9546 Pre: 0.9349 Rec: 0.9207 F1: 0.9278 Time in epoch: 5476.2595\n",
      "TP: 2183.0 TN: 4973.0 FP: 152.0 FN: 188.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2035 Acc: 0.9279 Pre: 0.8631 Rec: 0.8734 F1: 0.8682 Time in epoch: 5293.4096\n",
      "TP: 51953.0 TN: 151111.0 FP: 8243.0 FN: 7532.0\n",
      "val Loss: 0.0917 Acc: 0.9761 Pre: 0.9607 Rec: 0.9569 F1: 0.9588 Time in epoch: 5380.7822\n",
      "TP: 2639.0 TN: 6613.0 FP: 108.0 FN: 119.0\n",
      "test Loss: 0.1281 Acc: 0.9597 Pre: 0.9415 Rec: 0.9304 F1: 0.9359 Time in epoch: 5450.1635\n",
      "TP: 2206.0 TN: 4988.0 FP: 137.0 FN: 165.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1998 Acc: 0.9284 Pre: 0.8635 Rec: 0.8750 F1: 0.8692 Time in epoch: 5309.1054\n",
      "TP: 52049.0 TN: 151124.0 FP: 8230.0 FN: 7436.0\n",
      "val Loss: 0.0964 Acc: 0.9736 Pre: 0.9482 Rec: 0.9619 F1: 0.9550 Time in epoch: 5394.3322\n",
      "TP: 2653.0 TN: 6576.0 FP: 145.0 FN: 105.0\n",
      "test Loss: 0.1307 Acc: 0.9584 Pre: 0.9288 Rec: 0.9405 F1: 0.9346 Time in epoch: 5461.9776\n",
      "TP: 2230.0 TN: 4954.0 FP: 171.0 FN: 141.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1991 Acc: 0.9290 Pre: 0.8649 Rec: 0.8757 F1: 0.8703 Time in epoch: 5307.2260\n",
      "TP: 52093.0 TN: 151216.0 FP: 8138.0 FN: 7392.0\n",
      "val Loss: 0.0944 Acc: 0.9761 Pre: 0.9610 Rec: 0.9565 F1: 0.9587 Time in epoch: 5391.6360\n",
      "TP: 2638.0 TN: 6614.0 FP: 107.0 FN: 120.0\n",
      "test Loss: 0.1318 Acc: 0.9589 Pre: 0.9418 Rec: 0.9275 F1: 0.9346 Time in epoch: 5458.9603\n",
      "TP: 2199.0 TN: 4989.0 FP: 136.0 FN: 172.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1959 Acc: 0.9296 Pre: 0.8667 Rec: 0.8759 F1: 0.8713 Time in epoch: 5329.5475\n",
      "TP: 52102.0 TN: 151341.0 FP: 8013.0 FN: 7383.0\n",
      "val Loss: 0.1009 Acc: 0.9734 Pre: 0.9478 Rec: 0.9616 F1: 0.9546 Time in epoch: 5414.3284\n",
      "TP: 2652.0 TN: 6575.0 FP: 146.0 FN: 106.0\n",
      "test Loss: 0.1325 Acc: 0.9585 Pre: 0.9299 Rec: 0.9397 F1: 0.9348 Time in epoch: 5481.4585\n",
      "TP: 2228.0 TN: 4957.0 FP: 168.0 FN: 143.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1950 Acc: 0.9300 Pre: 0.8678 Rec: 0.8758 F1: 0.8718 Time in epoch: 5316.0925\n",
      "TP: 52097.0 TN: 151419.0 FP: 7935.0 FN: 7388.0\n",
      "val Loss: 0.0926 Acc: 0.9762 Pre: 0.9661 Rec: 0.9514 F1: 0.9587 Time in epoch: 5402.0434\n",
      "TP: 2624.0 TN: 6629.0 FP: 92.0 FN: 134.0\n",
      "test Loss: 0.1306 Acc: 0.9590 Pre: 0.9495 Rec: 0.9194 F1: 0.9342 Time in epoch: 5469.5392\n",
      "TP: 2180.0 TN: 5009.0 FP: 116.0 FN: 191.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1926 Acc: 0.9310 Pre: 0.8696 Rec: 0.8779 F1: 0.8737 Time in epoch: 5324.9437\n",
      "TP: 52220.0 TN: 151520.0 FP: 7834.0 FN: 7265.0\n",
      "val Loss: 0.0988 Acc: 0.9739 Pre: 0.9482 Rec: 0.9630 F1: 0.9556 Time in epoch: 5409.7048\n",
      "TP: 2656.0 TN: 6576.0 FP: 145.0 FN: 102.0\n",
      "test Loss: 0.1280 Acc: 0.9602 Pre: 0.9357 Rec: 0.9388 F1: 0.9373 Time in epoch: 5476.9957\n",
      "TP: 2226.0 TN: 4972.0 FP: 153.0 FN: 145.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1925 Acc: 0.9306 Pre: 0.8680 Rec: 0.8781 F1: 0.8730 Time in epoch: 5314.7271\n",
      "TP: 52236.0 TN: 151407.0 FP: 7947.0 FN: 7249.0\n",
      "val Loss: 0.0984 Acc: 0.9748 Pre: 0.9542 Rec: 0.9594 F1: 0.9568 Time in epoch: 5400.3977\n",
      "TP: 2646.0 TN: 6594.0 FP: 127.0 FN: 112.0\n",
      "test Loss: 0.1296 Acc: 0.9596 Pre: 0.9393 Rec: 0.9325 F1: 0.9359 Time in epoch: 5468.1659\n",
      "TP: 2211.0 TN: 4982.0 FP: 143.0 FN: 160.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1889 Acc: 0.9320 Pre: 0.8700 Rec: 0.8814 F1: 0.8757 Time in epoch: 5333.6255\n",
      "TP: 52430.0 TN: 151521.0 FP: 7833.0 FN: 7055.0\n",
      "val Loss: 0.0997 Acc: 0.9735 Pre: 0.9498 Rec: 0.9598 F1: 0.9547 Time in epoch: 5417.0390\n",
      "TP: 2647.0 TN: 6581.0 FP: 140.0 FN: 111.0\n",
      "test Loss: 0.1310 Acc: 0.9586 Pre: 0.9365 Rec: 0.9325 F1: 0.9345 Time in epoch: 5483.9162\n",
      "TP: 2211.0 TN: 4975.0 FP: 150.0 FN: 160.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1893 Acc: 0.9321 Pre: 0.8706 Rec: 0.8811 F1: 0.8758 Time in epoch: 5314.4890\n",
      "TP: 52414.0 TN: 151563.0 FP: 7791.0 FN: 7071.0\n",
      "val Loss: 0.0950 Acc: 0.9756 Pre: 0.9590 Rec: 0.9572 F1: 0.9581 Time in epoch: 5399.8463\n",
      "TP: 2640.0 TN: 6608.0 FP: 113.0 FN: 118.0\n",
      "test Loss: 0.1288 Acc: 0.9592 Pre: 0.9407 Rec: 0.9296 F1: 0.9351 Time in epoch: 5466.7247\n",
      "TP: 2204.0 TN: 4986.0 FP: 139.0 FN: 167.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1880 Acc: 0.9323 Pre: 0.8712 Rec: 0.8811 F1: 0.8762 Time in epoch: 5322.6485\n",
      "TP: 52414.0 TN: 151607.0 FP: 7747.0 FN: 7071.0\n",
      "val Loss: 0.0996 Acc: 0.9725 Pre: 0.9426 Rec: 0.9641 F1: 0.9532 Time in epoch: 5408.3820\n",
      "TP: 2659.0 TN: 6559.0 FP: 162.0 FN: 99.0\n",
      "test Loss: 0.1296 Acc: 0.9600 Pre: 0.9324 Rec: 0.9418 F1: 0.9371 Time in epoch: 5475.7689\n",
      "TP: 2233.0 TN: 4963.0 FP: 162.0 FN: 138.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1887 Acc: 0.9317 Pre: 0.8702 Rec: 0.8799 F1: 0.8750 Time in epoch: 5310.8188\n",
      "TP: 52343.0 TN: 151547.0 FP: 7807.0 FN: 7142.0\n",
      "val Loss: 0.0978 Acc: 0.9746 Pre: 0.9561 Rec: 0.9565 F1: 0.9563 Time in epoch: 5396.0647\n",
      "TP: 2638.0 TN: 6600.0 FP: 121.0 FN: 120.0\n",
      "test Loss: 0.1291 Acc: 0.9581 Pre: 0.9390 Rec: 0.9279 F1: 0.9334 Time in epoch: 5463.5609\n",
      "TP: 2200.0 TN: 4982.0 FP: 143.0 FN: 171.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1890 Acc: 0.9315 Pre: 0.8699 Rec: 0.8796 F1: 0.8748 Time in epoch: 5339.1315\n",
      "TP: 52324.0 TN: 151532.0 FP: 7822.0 FN: 7161.0\n",
      "val Loss: 0.0973 Acc: 0.9747 Pre: 0.9542 Rec: 0.9590 F1: 0.9566 Time in epoch: 5424.3112\n",
      "TP: 2645.0 TN: 6594.0 FP: 127.0 FN: 113.0\n",
      "test Loss: 0.1291 Acc: 0.9597 Pre: 0.9397 Rec: 0.9325 F1: 0.9361 Time in epoch: 5491.4460\n",
      "TP: 2211.0 TN: 4983.0 FP: 142.0 FN: 160.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1891 Acc: 0.9318 Pre: 0.8702 Rec: 0.8806 F1: 0.8754 Time in epoch: 5327.4464\n",
      "TP: 52382.0 TN: 151539.0 FP: 7815.0 FN: 7103.0\n",
      "val Loss: 0.0987 Acc: 0.9737 Pre: 0.9495 Rec: 0.9608 F1: 0.9551 Time in epoch: 5413.5235\n",
      "TP: 2650.0 TN: 6580.0 FP: 141.0 FN: 108.0\n",
      "test Loss: 0.1286 Acc: 0.9598 Pre: 0.9378 Rec: 0.9350 F1: 0.9364 Time in epoch: 5480.8006\n",
      "TP: 2217.0 TN: 4978.0 FP: 147.0 FN: 154.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1882 Acc: 0.9318 Pre: 0.8707 Rec: 0.8797 F1: 0.8752 Time in epoch: 5321.7663\n",
      "TP: 52330.0 TN: 151582.0 FP: 7772.0 FN: 7155.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1011 Acc: 0.9727 Pre: 0.9461 Rec: 0.9608 F1: 0.9534 Time in epoch: 5406.5720\n",
      "TP: 2650.0 TN: 6570.0 FP: 151.0 FN: 108.0\n",
      "test Loss: 0.1305 Acc: 0.9584 Pre: 0.9324 Rec: 0.9363 F1: 0.9343 Time in epoch: 5473.6115\n",
      "TP: 2220.0 TN: 4964.0 FP: 161.0 FN: 151.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1875 Acc: 0.9320 Pre: 0.8709 Rec: 0.8804 F1: 0.8756 Time in epoch: 5324.7874\n",
      "TP: 52370.0 TN: 151592.0 FP: 7762.0 FN: 7115.0\n",
      "val Loss: 0.0995 Acc: 0.9740 Pre: 0.9524 Rec: 0.9587 F1: 0.9555 Time in epoch: 5410.5831\n",
      "TP: 2644.0 TN: 6589.0 FP: 132.0 FN: 114.0\n",
      "test Loss: 0.1292 Acc: 0.9589 Pre: 0.9391 Rec: 0.9304 F1: 0.9347 Time in epoch: 5478.7329\n",
      "TP: 2206.0 TN: 4982.0 FP: 143.0 FN: 165.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9320 Pre: 0.8704 Rec: 0.8810 F1: 0.8757 Time in epoch: 5338.6316\n",
      "TP: 52404.0 TN: 151553.0 FP: 7801.0 FN: 7081.0\n",
      "val Loss: 0.0981 Acc: 0.9737 Pre: 0.9488 Rec: 0.9616 F1: 0.9552 Time in epoch: 5423.7101\n",
      "TP: 2652.0 TN: 6578.0 FP: 143.0 FN: 106.0\n",
      "test Loss: 0.1288 Acc: 0.9593 Pre: 0.9366 Rec: 0.9346 F1: 0.9356 Time in epoch: 5491.1209\n",
      "TP: 2216.0 TN: 4975.0 FP: 150.0 FN: 155.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1881 Acc: 0.9316 Pre: 0.8705 Rec: 0.8791 F1: 0.8748 Time in epoch: 5329.6457\n",
      "TP: 52291.0 TN: 151578.0 FP: 7776.0 FN: 7194.0\n",
      "val Loss: 0.0980 Acc: 0.9742 Pre: 0.9541 Rec: 0.9572 F1: 0.9557 Time in epoch: 5416.7087\n",
      "TP: 2640.0 TN: 6594.0 FP: 127.0 FN: 118.0\n",
      "test Loss: 0.1284 Acc: 0.9586 Pre: 0.9402 Rec: 0.9283 F1: 0.9342 Time in epoch: 5484.6195\n",
      "TP: 2201.0 TN: 4985.0 FP: 140.0 FN: 170.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1875 Acc: 0.9322 Pre: 0.8709 Rec: 0.8811 F1: 0.8760 Time in epoch: 5326.5563\n",
      "TP: 52413.0 TN: 151581.0 FP: 7773.0 FN: 7072.0\n",
      "val Loss: 0.0968 Acc: 0.9735 Pre: 0.9491 Rec: 0.9605 F1: 0.9548 Time in epoch: 5412.0273\n",
      "TP: 2649.0 TN: 6579.0 FP: 142.0 FN: 109.0\n",
      "test Loss: 0.1283 Acc: 0.9608 Pre: 0.9384 Rec: 0.9376 F1: 0.9380 Time in epoch: 5479.1218\n",
      "TP: 2223.0 TN: 4979.0 FP: 146.0 FN: 148.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9325 Pre: 0.8719 Rec: 0.8810 F1: 0.8764 Time in epoch: 5304.1959\n",
      "TP: 52405.0 TN: 151653.0 FP: 7701.0 FN: 7080.0\n",
      "val Loss: 0.0991 Acc: 0.9731 Pre: 0.9468 Rec: 0.9616 F1: 0.9541 Time in epoch: 5393.6364\n",
      "TP: 2652.0 TN: 6572.0 FP: 149.0 FN: 106.0\n",
      "test Loss: 0.1293 Acc: 0.9585 Pre: 0.9342 Rec: 0.9346 F1: 0.9344 Time in epoch: 5463.8728\n",
      "TP: 2216.0 TN: 4969.0 FP: 156.0 FN: 155.0\n",
      "\n",
      "Training complete in 2281m 7s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_300/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
