{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "data_root = '/home/rsundar/cs229/commercials_big/'\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = 1.5     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/rekall_train.txt'\n",
    "train_file_new_points = 'commercials/data/rekall_big_train_new.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, filename_new_points=None, load_percentage = 1):\n",
    "    # Assumes that there is no overlap in datapoints between filename and filename_new_points!\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    num_total_videos = 0\n",
    "    \n",
    "    with open(data_root + filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = sorted(list(set(videos))) # set of all videos\n",
    "        num_total_videos = len(videos)\n",
    "        num_videos = int(len(videos) * load_percentage) # number of videos to use\n",
    "        videos = videos[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "                \n",
    "    if filename_new_points is not None and load_percentage > 1:\n",
    "        print(\"Fetching points from new data file\")\n",
    "        with open(data_root + filename_new_points, 'r') as f:\n",
    "\n",
    "            # find set of unique videos on file\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                videos.append(video)\n",
    "            videos = sorted(list(set(videos))) # set of all videos\n",
    "            num_videos_to_fetch = int(num_total_videos * (load_percentage - 1))\n",
    "            if num_videos_to_fetch > len(videos):\n",
    "                print(\"Trying to fetch a larger data_percentage than is available\")\n",
    "                num_videos_to_fetch = len(videos)\n",
    "            videos = videos[:num_videos_to_fetch] # take first 'num_videos'\n",
    "            f.seek(0) # go back to beginning of file\n",
    "\n",
    "            # read in data only using videos in possibly reduced set from above\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                if video in videos: # load it up only if it's in the list of videos to use\n",
    "                    paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                    labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching points from new data file\n"
     ]
    }
   ],
   "source": [
    "train_paths, Y_train = read_file(train_file, train_file_new_points, load_percentage=data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = 4,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 95814, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2590 Acc: 0.9046 Pre: 0.8439 Rec: 0.8370 F1: 0.8404 Time in epoch: 2326.8564\n",
      "TP: 24060.0 TN: 62617.0 FP: 4452.0 FN: 4685.0\n",
      "val Loss: 0.1112 Acc: 0.9695 Pre: 0.9458 Rec: 0.9496 F1: 0.9477 Time in epoch: 2406.1127\n",
      "TP: 2619.0 TN: 6571.0 FP: 150.0 FN: 139.0\n",
      "test Loss: 0.1469 Acc: 0.9538 Pre: 0.9329 Rec: 0.9203 F1: 0.9265 Time in epoch: 2471.5907\n",
      "TP: 2182.0 TN: 4968.0 FP: 157.0 FN: 189.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2198 Acc: 0.9223 Pre: 0.8747 Rec: 0.8647 F1: 0.8697 Time in epoch: 2326.3537\n",
      "TP: 24856.0 TN: 63509.0 FP: 3560.0 FN: 3889.0\n",
      "val Loss: 0.0840 Acc: 0.9759 Pre: 0.9567 Rec: 0.9608 F1: 0.9588 Time in epoch: 2405.1968\n",
      "TP: 2650.0 TN: 6601.0 FP: 120.0 FN: 108.0\n",
      "test Loss: 0.1263 Acc: 0.9613 Pre: 0.9344 Rec: 0.9439 F1: 0.9392 Time in epoch: 2468.3542\n",
      "TP: 2238.0 TN: 4968.0 FP: 157.0 FN: 133.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2067 Acc: 0.9279 Pre: 0.8851 Rec: 0.8730 F1: 0.8790 Time in epoch: 2326.0364\n",
      "TP: 25093.0 TN: 63810.0 FP: 3259.0 FN: 3652.0\n",
      "val Loss: 0.0862 Acc: 0.9742 Pre: 0.9551 Rec: 0.9561 F1: 0.9556 Time in epoch: 2405.9908\n",
      "TP: 2637.0 TN: 6597.0 FP: 124.0 FN: 121.0\n",
      "test Loss: 0.1306 Acc: 0.9588 Pre: 0.9321 Rec: 0.9380 F1: 0.9350 Time in epoch: 2469.4763\n",
      "TP: 2224.0 TN: 4963.0 FP: 162.0 FN: 147.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.1978 Acc: 0.9310 Pre: 0.8906 Rec: 0.8780 F1: 0.8843 Time in epoch: 2324.9165\n",
      "TP: 25238.0 TN: 63969.0 FP: 3100.0 FN: 3507.0\n",
      "val Loss: 0.0959 Acc: 0.9672 Pre: 0.9384 Rec: 0.9496 F1: 0.9440 Time in epoch: 2403.9945\n",
      "TP: 2619.0 TN: 6549.0 FP: 172.0 FN: 139.0\n",
      "test Loss: 0.1299 Acc: 0.9572 Pre: 0.9392 Rec: 0.9245 F1: 0.9318 Time in epoch: 2467.0147\n",
      "TP: 2192.0 TN: 4983.0 FP: 142.0 FN: 179.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1921 Acc: 0.9335 Pre: 0.8945 Rec: 0.8826 F1: 0.8885 Time in epoch: 2325.5540\n",
      "TP: 25369.0 TN: 64078.0 FP: 2991.0 FN: 3376.0\n",
      "val Loss: 0.0958 Acc: 0.9718 Pre: 0.9488 Rec: 0.9547 F1: 0.9517 Time in epoch: 2404.7403\n",
      "TP: 2633.0 TN: 6579.0 FP: 142.0 FN: 125.0\n",
      "test Loss: 0.1297 Acc: 0.9605 Pre: 0.9354 Rec: 0.9401 F1: 0.9377 Time in epoch: 2467.7803\n",
      "TP: 2229.0 TN: 4971.0 FP: 154.0 FN: 142.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1889 Acc: 0.9343 Pre: 0.8971 Rec: 0.8823 F1: 0.8896 Time in epoch: 2325.5445\n",
      "TP: 25361.0 TN: 64160.0 FP: 2909.0 FN: 3384.0\n",
      "val Loss: 0.0785 Acc: 0.9767 Pre: 0.9638 Rec: 0.9558 F1: 0.9598 Time in epoch: 2405.9258\n",
      "TP: 2636.0 TN: 6622.0 FP: 99.0 FN: 122.0\n",
      "test Loss: 0.1320 Acc: 0.9613 Pre: 0.9422 Rec: 0.9350 F1: 0.9386 Time in epoch: 2470.1265\n",
      "TP: 2217.0 TN: 4989.0 FP: 136.0 FN: 154.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1722 Acc: 0.9394 Pre: 0.9054 Rec: 0.8911 F1: 0.8982 Time in epoch: 2322.5337\n",
      "TP: 25615.0 TN: 64393.0 FP: 2676.0 FN: 3130.0\n",
      "val Loss: 0.0866 Acc: 0.9732 Pre: 0.9484 Rec: 0.9601 F1: 0.9542 Time in epoch: 2401.1657\n",
      "TP: 2648.0 TN: 6577.0 FP: 144.0 FN: 110.0\n",
      "test Loss: 0.1339 Acc: 0.9564 Pre: 0.9209 Rec: 0.9431 F1: 0.9319 Time in epoch: 2464.2817\n",
      "TP: 2236.0 TN: 4933.0 FP: 192.0 FN: 135.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "val Loss: 0.0847 Acc: 0.9749 Pre: 0.9552 Rec: 0.9587 F1: 0.9569 Time in epoch: 2404.9080\n",
      "TP: 2644.0 TN: 6597.0 FP: 124.0 FN: 114.0\n",
      "test Loss: 0.1313 Acc: 0.9574 Pre: 0.9282 Rec: 0.9380 F1: 0.9331 Time in epoch: 2468.7127\n",
      "TP: 2224.0 TN: 4953.0 FP: 172.0 FN: 147.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1653 Acc: 0.9418 Pre: 0.9098 Rec: 0.8948 F1: 0.9022 Time in epoch: 2326.0760\n",
      "TP: 25721.0 TN: 64519.0 FP: 2550.0 FN: 3024.0\n",
      "val Loss: 0.0907 Acc: 0.9729 Pre: 0.9458 Rec: 0.9619 F1: 0.9538 Time in epoch: 2406.2627\n",
      "TP: 2653.0 TN: 6569.0 FP: 152.0 FN: 105.0\n",
      "test Loss: 0.1346 Acc: 0.9576 Pre: 0.9243 Rec: 0.9431 F1: 0.9336 Time in epoch: 2470.5827\n",
      "TP: 2236.0 TN: 4942.0 FP: 183.0 FN: 135.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1643 Acc: 0.9421 Pre: 0.9104 Rec: 0.8953 F1: 0.9028 Time in epoch: 2326.3382\n",
      "TP: 25734.0 TN: 64537.0 FP: 2532.0 FN: 3011.0\n",
      "val Loss: 0.0889 Acc: 0.9726 Pre: 0.9467 Rec: 0.9598 F1: 0.9532 Time in epoch: 2406.0748\n",
      "TP: 2647.0 TN: 6572.0 FP: 149.0 FN: 111.0\n",
      "test Loss: 0.1300 Acc: 0.9586 Pre: 0.9281 Rec: 0.9422 F1: 0.9351 Time in epoch: 2469.7823\n",
      "TP: 2234.0 TN: 4952.0 FP: 173.0 FN: 137.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1631 Acc: 0.9424 Pre: 0.9102 Rec: 0.8966 F1: 0.9033 Time in epoch: 2326.0005\n",
      "TP: 25772.0 TN: 64526.0 FP: 2543.0 FN: 2973.0\n",
      "val Loss: 0.0839 Acc: 0.9751 Pre: 0.9622 Rec: 0.9518 F1: 0.9570 Time in epoch: 2405.9524\n",
      "TP: 2625.0 TN: 6618.0 FP: 103.0 FN: 133.0\n",
      "test Loss: 0.1319 Acc: 0.9593 Pre: 0.9396 Rec: 0.9313 F1: 0.9354 Time in epoch: 2469.6335\n",
      "TP: 2208.0 TN: 4983.0 FP: 142.0 FN: 163.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1604 Acc: 0.9437 Pre: 0.9144 Rec: 0.8962 F1: 0.9052 Time in epoch: 2326.6954\n",
      "TP: 25761.0 TN: 64656.0 FP: 2413.0 FN: 2984.0\n",
      "val Loss: 0.0861 Acc: 0.9748 Pre: 0.9585 Rec: 0.9547 F1: 0.9566 Time in epoch: 2406.8179\n",
      "TP: 2633.0 TN: 6607.0 FP: 114.0 FN: 125.0\n",
      "test Loss: 0.1322 Acc: 0.9577 Pre: 0.9333 Rec: 0.9329 F1: 0.9331 Time in epoch: 2470.6278\n",
      "TP: 2212.0 TN: 4967.0 FP: 158.0 FN: 159.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1597 Acc: 0.9438 Pre: 0.9128 Rec: 0.8986 F1: 0.9056 Time in epoch: 2325.4738\n",
      "TP: 25830.0 TN: 64601.0 FP: 2468.0 FN: 2915.0\n",
      "val Loss: 0.0808 Acc: 0.9753 Pre: 0.9613 Rec: 0.9536 F1: 0.9574 Time in epoch: 2405.5991\n",
      "TP: 2630.0 TN: 6615.0 FP: 106.0 FN: 128.0\n",
      "test Loss: 0.1295 Acc: 0.9608 Pre: 0.9399 Rec: 0.9359 F1: 0.9379 Time in epoch: 2469.3910\n",
      "TP: 2219.0 TN: 4983.0 FP: 142.0 FN: 152.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1556 Acc: 0.9447 Pre: 0.9147 Rec: 0.8996 F1: 0.9071 Time in epoch: 2324.4230\n",
      "TP: 25858.0 TN: 64657.0 FP: 2412.0 FN: 2887.0\n",
      "val Loss: 0.0908 Acc: 0.9723 Pre: 0.9444 Rec: 0.9612 F1: 0.9527 Time in epoch: 2404.2330\n",
      "TP: 2651.0 TN: 6565.0 FP: 156.0 FN: 107.0\n",
      "test Loss: 0.1332 Acc: 0.9574 Pre: 0.9233 Rec: 0.9439 F1: 0.9335 Time in epoch: 2468.1029\n",
      "TP: 2238.0 TN: 4939.0 FP: 186.0 FN: 133.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1569 Acc: 0.9438 Pre: 0.9116 Rec: 0.9001 F1: 0.9058 Time in epoch: 2324.6154\n",
      "TP: 25872.0 TN: 64560.0 FP: 2509.0 FN: 2873.0\n",
      "val Loss: 0.0870 Acc: 0.9742 Pre: 0.9538 Rec: 0.9576 F1: 0.9557 Time in epoch: 2403.2515\n",
      "TP: 2641.0 TN: 6593.0 FP: 128.0 FN: 117.0\n",
      "test Loss: 0.1298 Acc: 0.9590 Pre: 0.9325 Rec: 0.9384 F1: 0.9355 Time in epoch: 2466.2124\n",
      "TP: 2225.0 TN: 4964.0 FP: 161.0 FN: 146.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1565 Acc: 0.9451 Pre: 0.9147 Rec: 0.9012 F1: 0.9079 Time in epoch: 2324.7819\n",
      "TP: 25906.0 TN: 64652.0 FP: 2417.0 FN: 2839.0\n",
      "val Loss: 0.0904 Acc: 0.9727 Pre: 0.9490 Rec: 0.9576 F1: 0.9533 Time in epoch: 2404.7214\n",
      "TP: 2641.0 TN: 6579.0 FP: 142.0 FN: 117.0\n",
      "test Loss: 0.1311 Acc: 0.9582 Pre: 0.9298 Rec: 0.9388 F1: 0.9343 Time in epoch: 2468.3320\n",
      "TP: 2226.0 TN: 4957.0 FP: 168.0 FN: 145.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1554 Acc: 0.9454 Pre: 0.9155 Rec: 0.9011 F1: 0.9082 Time in epoch: 2324.2686\n",
      "TP: 25901.0 TN: 64678.0 FP: 2391.0 FN: 2844.0\n",
      "val Loss: 0.0933 Acc: 0.9710 Pre: 0.9404 Rec: 0.9612 F1: 0.9507 Time in epoch: 2404.1391\n",
      "TP: 2651.0 TN: 6553.0 FP: 168.0 FN: 107.0\n",
      "test Loss: 0.1340 Acc: 0.9566 Pre: 0.9203 Rec: 0.9447 F1: 0.9324 Time in epoch: 2472.8162\n",
      "TP: 2240.0 TN: 4931.0 FP: 194.0 FN: 131.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1550 Acc: 0.9455 Pre: 0.9166 Rec: 0.9002 F1: 0.9083 Time in epoch: 2325.7211\n",
      "TP: 25876.0 TN: 64715.0 FP: 2354.0 FN: 2869.0\n",
      "val Loss: 0.0921 Acc: 0.9717 Pre: 0.9440 Rec: 0.9598 F1: 0.9518 Time in epoch: 2405.2978\n",
      "TP: 2647.0 TN: 6564.0 FP: 157.0 FN: 111.0\n",
      "test Loss: 0.1330 Acc: 0.9576 Pre: 0.9265 Rec: 0.9405 F1: 0.9334 Time in epoch: 2468.8713\n",
      "TP: 2230.0 TN: 4948.0 FP: 177.0 FN: 141.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1557 Acc: 0.9450 Pre: 0.9153 Rec: 0.8999 F1: 0.9076 Time in epoch: 2322.4321\n",
      "TP: 25869.0 TN: 64676.0 FP: 2393.0 FN: 2876.0\n",
      "val Loss: 0.0881 Acc: 0.9733 Pre: 0.9501 Rec: 0.9587 F1: 0.9543 Time in epoch: 2401.8288\n",
      "TP: 2644.0 TN: 6582.0 FP: 139.0 FN: 114.0\n",
      "test Loss: 0.1308 Acc: 0.9593 Pre: 0.9333 Rec: 0.9384 F1: 0.9359 Time in epoch: 2465.1778\n",
      "TP: 2225.0 TN: 4966.0 FP: 159.0 FN: 146.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9454 Pre: 0.9161 Rec: 0.9005 F1: 0.9082 Time in epoch: 2320.8924\n",
      "TP: 25886.0 TN: 64698.0 FP: 2371.0 FN: 2859.0\n",
      "val Loss: 0.0900 Acc: 0.9734 Pre: 0.9556 Rec: 0.9529 F1: 0.9542 Time in epoch: 2400.3860\n",
      "TP: 2628.0 TN: 6599.0 FP: 122.0 FN: 130.0\n",
      "test Loss: 0.1309 Acc: 0.9596 Pre: 0.9396 Rec: 0.9321 F1: 0.9358 Time in epoch: 2463.9467\n",
      "TP: 2210.0 TN: 4983.0 FP: 142.0 FN: 161.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1534 Acc: 0.9461 Pre: 0.9190 Rec: 0.8998 F1: 0.9093 Time in epoch: 2324.0715\n",
      "TP: 25866.0 TN: 64788.0 FP: 2281.0 FN: 2879.0\n",
      "val Loss: 0.0938 Acc: 0.9710 Pre: 0.9417 Rec: 0.9598 F1: 0.9506 Time in epoch: 2403.3902\n",
      "TP: 2647.0 TN: 6557.0 FP: 164.0 FN: 111.0\n",
      "test Loss: 0.1329 Acc: 0.9585 Pre: 0.9274 Rec: 0.9426 F1: 0.9350 Time in epoch: 2466.8238\n",
      "TP: 2235.0 TN: 4950.0 FP: 175.0 FN: 136.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1553 Acc: 0.9454 Pre: 0.9151 Rec: 0.9016 F1: 0.9083 Time in epoch: 2326.8197\n",
      "TP: 25917.0 TN: 64665.0 FP: 2404.0 FN: 2828.0\n",
      "val Loss: 0.0896 Acc: 0.9726 Pre: 0.9490 Rec: 0.9572 F1: 0.9531 Time in epoch: 2406.9553\n",
      "TP: 2640.0 TN: 6579.0 FP: 142.0 FN: 118.0\n",
      "test Loss: 0.1298 Acc: 0.9594 Pre: 0.9341 Rec: 0.9380 F1: 0.9360 Time in epoch: 2470.7653\n",
      "TP: 2224.0 TN: 4968.0 FP: 157.0 FN: 147.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9446 Pre: 0.9143 Rec: 0.8996 F1: 0.9069 Time in epoch: 2327.5051\n",
      "TP: 25859.0 TN: 64645.0 FP: 2424.0 FN: 2886.0\n",
      "val Loss: 0.0913 Acc: 0.9731 Pre: 0.9497 Rec: 0.9583 F1: 0.9540 Time in epoch: 2407.6027\n",
      "TP: 2643.0 TN: 6581.0 FP: 140.0 FN: 115.0\n",
      "test Loss: 0.1324 Acc: 0.9581 Pre: 0.9298 Rec: 0.9384 F1: 0.9341 Time in epoch: 2471.5939\n",
      "TP: 2225.0 TN: 4957.0 FP: 168.0 FN: 146.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1553 Acc: 0.9450 Pre: 0.9168 Rec: 0.8981 F1: 0.9074 Time in epoch: 2327.0979\n",
      "TP: 25816.0 TN: 64727.0 FP: 2342.0 FN: 2929.0\n",
      "val Loss: 0.0893 Acc: 0.9734 Pre: 0.9514 Rec: 0.9576 F1: 0.9545 Time in epoch: 2406.9960\n",
      "TP: 2641.0 TN: 6586.0 FP: 135.0 FN: 117.0\n",
      "test Loss: 0.1308 Acc: 0.9596 Pre: 0.9334 Rec: 0.9393 F1: 0.9363 Time in epoch: 2470.9670\n",
      "TP: 2227.0 TN: 4966.0 FP: 159.0 FN: 144.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1545 Acc: 0.9454 Pre: 0.9155 Rec: 0.9014 F1: 0.9084 Time in epoch: 2321.2351\n",
      "TP: 25910.0 TN: 64676.0 FP: 2393.0 FN: 2835.0\n",
      "val Loss: 0.0901 Acc: 0.9726 Pre: 0.9473 Rec: 0.9590 F1: 0.9532 Time in epoch: 2402.9339\n",
      "TP: 2645.0 TN: 6574.0 FP: 147.0 FN: 113.0\n",
      "test Loss: 0.1315 Acc: 0.9582 Pre: 0.9291 Rec: 0.9397 F1: 0.9344 Time in epoch: 2468.1261\n",
      "TP: 2228.0 TN: 4955.0 FP: 170.0 FN: 143.0\n",
      "\n",
      "Training complete in 1028m 53s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_150/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
