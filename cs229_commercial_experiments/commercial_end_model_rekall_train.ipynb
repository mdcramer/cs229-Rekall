{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rekall_train_file = 'commercials/data/rekall_train.txt'\n",
    "rekall_val_file = 'commercials/data/rekall_val.txt'\n",
    "train_file = 'commercials/data/train.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rekall_train_paths, rekall_Y_train = read_file(rekall_train_file)\n",
    "train_paths, Y_train = read_file(train_file)\n",
    "rekall_val_paths, rekall_Y_val = read_file(rekall_val_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'rekall_train': ImageDataset(rekall_train_paths, rekall_Y_train, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'rekall_val_train': ImageDataset(rekall_val_paths, rekall_Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'rekall_val': ImageDataset(rekall_val_paths, rekall_Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=32,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 64130,\n",
       " 'rekall_train': 64130,\n",
       " 'val_train': 9479,\n",
       " 'rekall_val_train': 9479,\n",
       " 'val': 9479,\n",
       " 'rekall_val': 9479,\n",
       " 'test': 7496}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rekall_train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2549 Acc: 0.9051 Pre: 0.8513 Rec: 0.8192 F1: 0.8349 Time in epoch: 1399.9408\n",
      "TP: 15391.0 TN: 42654.0 FP: 2689.0 FN: 3396.0\n",
      "val Loss: 0.1110 Acc: 0.9637 Pre: 0.9412 Rec: 0.9336 F1: 0.9374 Time in epoch: 1463.3095\n",
      "TP: 2575.0 TN: 6560.0 FP: 161.0 FN: 183.0\n",
      "test Loss: 0.1449 Acc: 0.9546 Pre: 0.9390 Rec: 0.9161 F1: 0.9274 Time in epoch: 1513.9953\n",
      "TP: 2172.0 TN: 4984.0 FP: 141.0 FN: 199.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2117 Acc: 0.9266 Pre: 0.8833 Rec: 0.8637 F1: 0.8734 Time in epoch: 1409.3713\n",
      "TP: 16226.0 TN: 43200.0 FP: 2143.0 FN: 2561.0\n",
      "val Loss: 0.0996 Acc: 0.9680 Pre: 0.9398 Rec: 0.9511 F1: 0.9454 Time in epoch: 1472.1405\n",
      "TP: 2623.0 TN: 6553.0 FP: 168.0 FN: 135.0\n",
      "test Loss: 0.1355 Acc: 0.9565 Pre: 0.9309 Rec: 0.9317 F1: 0.9313 Time in epoch: 1522.4477\n",
      "TP: 2209.0 TN: 4961.0 FP: 164.0 FN: 162.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.1989 Acc: 0.9307 Pre: 0.8901 Rec: 0.8709 F1: 0.8804 Time in epoch: 1400.2645\n",
      "TP: 16362.0 TN: 43322.0 FP: 2021.0 FN: 2425.0\n",
      "val Loss: 0.0966 Acc: 0.9717 Pre: 0.9504 Rec: 0.9525 F1: 0.9515 Time in epoch: 1463.0645\n",
      "TP: 2627.0 TN: 6584.0 FP: 137.0 FN: 131.0\n",
      "test Loss: 0.1344 Acc: 0.9598 Pre: 0.9484 Rec: 0.9232 F1: 0.9357 Time in epoch: 1513.2811\n",
      "TP: 2189.0 TN: 5006.0 FP: 119.0 FN: 182.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.1913 Acc: 0.9339 Pre: 0.8957 Rec: 0.8764 F1: 0.8859 Time in epoch: 1398.2962\n",
      "TP: 16464.0 TN: 43426.0 FP: 1917.0 FN: 2323.0\n",
      "val Loss: 0.1218 Acc: 0.9573 Pre: 0.9044 Rec: 0.9540 F1: 0.9285 Time in epoch: 1461.0848\n",
      "TP: 2631.0 TN: 6443.0 FP: 278.0 FN: 127.0\n",
      "test Loss: 0.1360 Acc: 0.9565 Pre: 0.9379 Rec: 0.9237 F1: 0.9307 Time in epoch: 1511.2552\n",
      "TP: 2190.0 TN: 4980.0 FP: 145.0 FN: 181.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1845 Acc: 0.9355 Pre: 0.9000 Rec: 0.8771 F1: 0.8884 Time in epoch: 1404.1116\n",
      "TP: 16479.0 TN: 43512.0 FP: 1831.0 FN: 2308.0\n",
      "val Loss: 0.1136 Acc: 0.9621 Pre: 0.9193 Rec: 0.9536 F1: 0.9361 Time in epoch: 1466.9247\n",
      "TP: 2630.0 TN: 6490.0 FP: 231.0 FN: 128.0\n",
      "test Loss: 0.1448 Acc: 0.9492 Pre: 0.9135 Rec: 0.9270 F1: 0.9202 Time in epoch: 1517.2189\n",
      "TP: 2198.0 TN: 4917.0 FP: 208.0 FN: 173.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1783 Acc: 0.9382 Pre: 0.9035 Rec: 0.8833 F1: 0.8933 Time in epoch: 1405.7099\n",
      "TP: 16594.0 TN: 43570.0 FP: 1773.0 FN: 2193.0\n",
      "val Loss: 0.1399 Acc: 0.9495 Pre: 0.8764 Rec: 0.9619 F1: 0.9172 Time in epoch: 1468.5245\n",
      "TP: 2653.0 TN: 6347.0 FP: 374.0 FN: 105.0\n",
      "test Loss: 0.1577 Acc: 0.9470 Pre: 0.8977 Rec: 0.9397 F1: 0.9182 Time in epoch: 1518.7741\n",
      "TP: 2228.0 TN: 4871.0 FP: 254.0 FN: 143.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1655 Acc: 0.9432 Pre: 0.9142 Rec: 0.8894 F1: 0.9017 Time in epoch: 1396.4202\n",
      "TP: 16710.0 TN: 43775.0 FP: 1568.0 FN: 2077.0\n",
      "val Loss: 0.1066 Acc: 0.9633 Pre: 0.9170 Rec: 0.9608 F1: 0.9384 Time in epoch: 1459.2489\n",
      "TP: 2650.0 TN: 6481.0 FP: 240.0 FN: 108.0\n",
      "test Loss: 0.1345 Acc: 0.9562 Pre: 0.9254 Rec: 0.9372 F1: 0.9313 Time in epoch: 1509.5729\n",
      "TP: 2222.0 TN: 4946.0 FP: 179.0 FN: 149.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9440 Pre: 0.9145 Rec: 0.8921 F1: 0.9032 Time in epoch: 1400.4687\n",
      "TP: 16760.0 TN: 43777.0 FP: 1566.0 FN: 2027.0\n",
      "val Loss: 0.1047 Acc: 0.9643 Pre: 0.9216 Rec: 0.9590 F1: 0.9399 Time in epoch: 1463.2729\n",
      "TP: 2645.0 TN: 6496.0 FP: 225.0 FN: 113.0\n",
      "test Loss: 0.1341 Acc: 0.9558 Pre: 0.9225 Rec: 0.9393 F1: 0.9308 Time in epoch: 1513.5534\n",
      "TP: 2227.0 TN: 4938.0 FP: 187.0 FN: 144.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1586 Acc: 0.9447 Pre: 0.9150 Rec: 0.8942 F1: 0.9045 Time in epoch: 1399.9833\n",
      "TP: 16800.0 TN: 43782.0 FP: 1561.0 FN: 1987.0\n",
      "val Loss: 0.1070 Acc: 0.9633 Pre: 0.9249 Rec: 0.9511 F1: 0.9378 Time in epoch: 1462.7888\n",
      "TP: 2623.0 TN: 6508.0 FP: 213.0 FN: 135.0\n",
      "test Loss: 0.1340 Acc: 0.9566 Pre: 0.9364 Rec: 0.9258 F1: 0.9311 Time in epoch: 1512.9944\n",
      "TP: 2195.0 TN: 4976.0 FP: 149.0 FN: 176.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1553 Acc: 0.9458 Pre: 0.9171 Rec: 0.8959 F1: 0.9064 Time in epoch: 1410.0115\n",
      "TP: 16832.0 TN: 43822.0 FP: 1521.0 FN: 1955.0\n",
      "val Loss: 0.1024 Acc: 0.9652 Pre: 0.9278 Rec: 0.9547 F1: 0.9410 Time in epoch: 1472.8428\n",
      "TP: 2633.0 TN: 6516.0 FP: 205.0 FN: 125.0\n",
      "test Loss: 0.1360 Acc: 0.9561 Pre: 0.9301 Rec: 0.9313 F1: 0.9307 Time in epoch: 1523.0430\n",
      "TP: 2208.0 TN: 4959.0 FP: 166.0 FN: 163.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1557 Acc: 0.9453 Pre: 0.9162 Rec: 0.8951 F1: 0.9055 Time in epoch: 1399.6265\n",
      "TP: 16817.0 TN: 43804.0 FP: 1539.0 FN: 1970.0\n",
      "val Loss: 0.1172 Acc: 0.9572 Pre: 0.8965 Rec: 0.9641 F1: 0.9291 Time in epoch: 1462.4631\n",
      "TP: 2659.0 TN: 6414.0 FP: 307.0 FN: 99.0\n",
      "test Loss: 0.1361 Acc: 0.9542 Pre: 0.9139 Rec: 0.9443 F1: 0.9289 Time in epoch: 1512.8329\n",
      "TP: 2239.0 TN: 4914.0 FP: 211.0 FN: 132.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1527 Acc: 0.9469 Pre: 0.9179 Rec: 0.8991 F1: 0.9084 Time in epoch: 1398.6119\n",
      "TP: 16892.0 TN: 43833.0 FP: 1510.0 FN: 1895.0\n",
      "val Loss: 0.1087 Acc: 0.9618 Pre: 0.9183 Rec: 0.9536 F1: 0.9356 Time in epoch: 1461.4760\n",
      "TP: 2630.0 TN: 6487.0 FP: 234.0 FN: 128.0\n",
      "test Loss: 0.1353 Acc: 0.9562 Pre: 0.9312 Rec: 0.9304 F1: 0.9308 Time in epoch: 1511.7175\n",
      "TP: 2206.0 TN: 4962.0 FP: 163.0 FN: 165.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1543 Acc: 0.9456 Pre: 0.9148 Rec: 0.8981 F1: 0.9064 Time in epoch: 1401.5158\n",
      "TP: 16873.0 TN: 43771.0 FP: 1572.0 FN: 1914.0\n",
      "val Loss: 0.1253 Acc: 0.9524 Pre: 0.8849 Rec: 0.9616 F1: 0.9216 Time in epoch: 1464.3763\n",
      "TP: 2652.0 TN: 6376.0 FP: 345.0 FN: 106.0\n",
      "test Loss: 0.1414 Acc: 0.9522 Pre: 0.9093 Rec: 0.9431 F1: 0.9259 Time in epoch: 1514.6084\n",
      "TP: 2236.0 TN: 4902.0 FP: 223.0 FN: 135.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1514 Acc: 0.9459 Pre: 0.9162 Rec: 0.8975 F1: 0.9067 Time in epoch: 1402.9938\n",
      "TP: 16861.0 TN: 43800.0 FP: 1543.0 FN: 1926.0\n",
      "val Loss: 0.1214 Acc: 0.9556 Pre: 0.8944 Rec: 0.9608 F1: 0.9264 Time in epoch: 1465.7511\n",
      "TP: 2650.0 TN: 6408.0 FP: 313.0 FN: 108.0\n",
      "test Loss: 0.1397 Acc: 0.9525 Pre: 0.9127 Rec: 0.9397 F1: 0.9260 Time in epoch: 1515.9841\n",
      "TP: 2228.0 TN: 4912.0 FP: 213.0 FN: 143.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9472 Pre: 0.9183 Rec: 0.8998 F1: 0.9090 Time in epoch: 1393.2100\n",
      "TP: 16904.0 TN: 43840.0 FP: 1503.0 FN: 1883.0\n",
      "val Loss: 0.1176 Acc: 0.9577 Pre: 0.9018 Rec: 0.9590 F1: 0.9295 Time in epoch: 1456.0310\n",
      "TP: 2645.0 TN: 6433.0 FP: 288.0 FN: 113.0\n",
      "test Loss: 0.1397 Acc: 0.9534 Pre: 0.9157 Rec: 0.9393 F1: 0.9273 Time in epoch: 1506.2794\n",
      "TP: 2227.0 TN: 4920.0 FP: 205.0 FN: 144.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9472 Pre: 0.9190 Rec: 0.8991 F1: 0.9090 Time in epoch: 1397.2442\n",
      "TP: 16892.0 TN: 43855.0 FP: 1488.0 FN: 1895.0\n",
      "val Loss: 0.1098 Acc: 0.9616 Pre: 0.9162 Rec: 0.9554 F1: 0.9354 Time in epoch: 1460.1565\n",
      "TP: 2635.0 TN: 6480.0 FP: 241.0 FN: 123.0\n",
      "test Loss: 0.1366 Acc: 0.9564 Pre: 0.9298 Rec: 0.9325 F1: 0.9311 Time in epoch: 1510.3926\n",
      "TP: 2211.0 TN: 4958.0 FP: 167.0 FN: 160.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1501 Acc: 0.9471 Pre: 0.9180 Rec: 0.8999 F1: 0.9089 Time in epoch: 1397.5299\n",
      "TP: 16907.0 TN: 43832.0 FP: 1511.0 FN: 1880.0\n",
      "val Loss: 0.1257 Acc: 0.9528 Pre: 0.8871 Rec: 0.9601 F1: 0.9222 Time in epoch: 1460.3060\n",
      "TP: 2648.0 TN: 6384.0 FP: 337.0 FN: 110.0\n",
      "test Loss: 0.1427 Acc: 0.9509 Pre: 0.9093 Rec: 0.9384 F1: 0.9236 Time in epoch: 1510.6243\n",
      "TP: 2225.0 TN: 4903.0 FP: 222.0 FN: 146.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1490 Acc: 0.9484 Pre: 0.9222 Rec: 0.8996 F1: 0.9108 Time in epoch: 1408.5855\n",
      "TP: 16900.0 TN: 43918.0 FP: 1425.0 FN: 1887.0\n",
      "val Loss: 0.1065 Acc: 0.9636 Pre: 0.9238 Rec: 0.9536 F1: 0.9384 Time in epoch: 1471.3628\n",
      "TP: 2630.0 TN: 6504.0 FP: 217.0 FN: 128.0\n",
      "test Loss: 0.1369 Acc: 0.9565 Pre: 0.9331 Rec: 0.9291 F1: 0.9311 Time in epoch: 1521.6496\n",
      "TP: 2203.0 TN: 4967.0 FP: 158.0 FN: 168.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9472 Pre: 0.9177 Rec: 0.9007 F1: 0.9091 Time in epoch: 1401.2061\n",
      "TP: 16922.0 TN: 43825.0 FP: 1518.0 FN: 1865.0\n",
      "val Loss: 0.0996 Acc: 0.9675 Pre: 0.9410 Rec: 0.9478 F1: 0.9444 Time in epoch: 1464.0425\n",
      "TP: 2614.0 TN: 6557.0 FP: 164.0 FN: 144.0\n",
      "train Loss: 0.1487 Acc: 0.9481 Pre: 0.9203 Rec: 0.9007 F1: 0.9104 Time in epoch: 1400.4744\n",
      "TP: 16921.0 TN: 43878.0 FP: 1465.0 FN: 1866.0\n",
      "val Loss: 0.1245 Acc: 0.9531 Pre: 0.8901 Rec: 0.9569 F1: 0.9222 Time in epoch: 1463.3158\n",
      "TP: 2639.0 TN: 6395.0 FP: 326.0 FN: 119.0\n",
      "test Loss: 0.1385 Acc: 0.9537 Pre: 0.9217 Rec: 0.9329 F1: 0.9273 Time in epoch: 1513.7043\n",
      "TP: 2212.0 TN: 4937.0 FP: 188.0 FN: 159.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9472 Pre: 0.9172 Rec: 0.9013 F1: 0.9092 Time in epoch: 1407.4269\n",
      "TP: 16933.0 TN: 43814.0 FP: 1529.0 FN: 1854.0\n",
      "val Loss: 0.1102 Acc: 0.9630 Pre: 0.9230 Rec: 0.9521 F1: 0.9374 Time in epoch: 1470.3679\n",
      "TP: 2626.0 TN: 6502.0 FP: 219.0 FN: 132.0\n",
      "test Loss: 0.1378 Acc: 0.9557 Pre: 0.9355 Rec: 0.9237 F1: 0.9295 Time in epoch: 1520.6985\n",
      "TP: 2190.0 TN: 4974.0 FP: 151.0 FN: 181.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1496 Acc: 0.9468 Pre: 0.9174 Rec: 0.8994 F1: 0.9083 Time in epoch: 1409.4961\n",
      "TP: 16897.0 TN: 43821.0 FP: 1522.0 FN: 1890.0\n",
      "val Loss: 0.1043 Acc: 0.9642 Pre: 0.9254 Rec: 0.9540 F1: 0.9395 Time in epoch: 1472.2977\n",
      "TP: 2631.0 TN: 6509.0 FP: 212.0 FN: 127.0\n",
      "test Loss: 0.1350 Acc: 0.9561 Pre: 0.9348 Rec: 0.9258 F1: 0.9303 Time in epoch: 1522.5819\n",
      "TP: 2195.0 TN: 4972.0 FP: 153.0 FN: 176.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9485 Pre: 0.9210 Rec: 0.9016 F1: 0.9112 Time in epoch: 1399.1830\n",
      "TP: 16939.0 TN: 43890.0 FP: 1453.0 FN: 1848.0\n",
      "val Loss: 0.1250 Acc: 0.9523 Pre: 0.8856 Rec: 0.9601 F1: 0.9214 Time in epoch: 1462.1301\n",
      "TP: 2648.0 TN: 6379.0 FP: 342.0 FN: 110.0\n",
      "test Loss: 0.1403 Acc: 0.9525 Pre: 0.9111 Rec: 0.9418 F1: 0.9262 Time in epoch: 1512.3892\n",
      "TP: 2233.0 TN: 4907.0 FP: 218.0 FN: 138.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1479 Acc: 0.9477 Pre: 0.9173 Rec: 0.9031 F1: 0.9101 Time in epoch: 1403.5268\n",
      "TP: 16966.0 TN: 43813.0 FP: 1530.0 FN: 1821.0\n",
      "val Loss: 0.1030 Acc: 0.9650 Pre: 0.9280 Rec: 0.9536 F1: 0.9406 Time in epoch: 1466.4599\n",
      "TP: 2630.0 TN: 6517.0 FP: 204.0 FN: 128.0\n",
      "test Loss: 0.1362 Acc: 0.9566 Pre: 0.9342 Rec: 0.9283 F1: 0.9312 Time in epoch: 1516.7259\n",
      "TP: 2201.0 TN: 4970.0 FP: 155.0 FN: 170.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1471 Acc: 0.9481 Pre: 0.9202 Rec: 0.9008 F1: 0.9104 Time in epoch: 1405.1139\n",
      "TP: 16924.0 TN: 43876.0 FP: 1467.0 FN: 1863.0\n",
      "val Loss: 0.1086 Acc: 0.9623 Pre: 0.9181 Rec: 0.9558 F1: 0.9366 Time in epoch: 1467.9179\n",
      "TP: 2636.0 TN: 6486.0 FP: 235.0 FN: 122.0\n",
      "test Loss: 0.1361 Acc: 0.9557 Pre: 0.9271 Rec: 0.9334 F1: 0.9302 Time in epoch: 1518.2509\n",
      "TP: 2213.0 TN: 4951.0 FP: 174.0 FN: 158.0\n",
      "\n",
      "Training complete in 631m 32s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_bbatch_rekall_train/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'rekall_train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
