{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning only the last layer\n",
    "F1 with Rekall labels (1 seed, 25 epochs, 16 batch size):\n",
    "\n",
    "* 0.8410 @ 20\\% {'train': 13115, 'val_train': 9479, 'val': 9479, 'test': 7496}\n",
    "* 0.8647 @ 40\\% {'train': 25552, 'val_train': 9479, 'val': 9479, 'test': 7496}\n",
    "* 0.8788 @ 100\\% {'train': 64130, 'val_train': 9479, 'val': 9479, 'test': 7496}\n",
    "* 0.xxxx @ 500\\% {'train': 344594, 'val_train': 9479, 'val': 9479, 'test': 7496}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "data_root = '/home/rsundar/cs229/commercials_big/'\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = 5     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/rekall_train.txt'\n",
    "train_file_new_points = 'commercials/data/rekall_big_train_new.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, filename_new_points=None, load_percentage = 1):\n",
    "    # Assumes that there is no overlap in datapoints between filename and filename_new_points!\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    num_total_videos = 0\n",
    "    \n",
    "    with open(data_root + filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = sorted(list(set(videos))) # set of all videos\n",
    "        num_total_videos = len(videos)\n",
    "        num_videos = int(len(videos) * load_percentage) # number of videos to use\n",
    "        videos = videos[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "    \n",
    "    videos = []\n",
    "    if filename_new_points is not None and load_percentage > 1:\n",
    "        print(\"Fetching points from new data file\")\n",
    "        with open(data_root + filename_new_points, 'r') as f:\n",
    "\n",
    "            # find set of unique videos on file\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                videos.append(video)\n",
    "            videos = sorted(list(set(videos))) # set of all videos\n",
    "            num_videos_to_fetch = int(num_total_videos * (load_percentage - 1))\n",
    "            if num_videos_to_fetch > len(videos):\n",
    "                print(\"Trying to fetch a larger data_percentage than is available\")\n",
    "                num_videos_to_fetch = len(videos)\n",
    "            videos = videos[:num_videos_to_fetch] # take first 'num_videos'\n",
    "            f.seek(0) # go back to beginning of file\n",
    "\n",
    "            # read in data only using videos in possibly reduced set from above\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                if video in videos: # load it up only if it's in the list of videos to use\n",
    "                    paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                    labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching points from new data file\n"
     ]
    }
   ],
   "source": [
    "train_paths, Y_train = read_file(train_file, train_file_new_points, load_percentage=data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = 4,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 344594, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frozen_model():\n",
    "    # Useful links: \n",
    "    #   * https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "    #   * https://stackoverflow.com/questions/42480111/model-summary-in-pytorch\n",
    "    #   * https://discuss.pytorch.org/t/how-the-pytorch-freeze-network-in-some-layers-only-the-rest-of-the-training/7088/2\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    \n",
    "    for param in model_ts.parameters():\n",
    "        param.requires_grad = False\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    return model_ts\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 6.6970e-03, -6.0678e-03,  1.8278e-02,  ...,  1.2842e-02,\n",
      "         -2.0258e-02,  9.5235e-05]], requires_grad=True) torch.Size([1, 2048])\n",
      "Parameter containing:\n",
      "tensor([-0.0207], requires_grad=True) torch.Size([1])\n",
      "23510081\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = get_frozen_model()\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        print(param, param.shape)\n",
    "print(get_n_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3721 Acc: 0.8347 Pre: 0.7311 Rec: 0.6439 F1: 0.6847 Time in epoch: 3955.3333\n",
      "TP: 61859.0 TN: 225774.0 FP: 22757.0 FN: 34204.0\n",
      "val Loss: 0.2368 Acc: 0.9003 Pre: 0.9490 Rec: 0.6947 F1: 0.8022 Time in epoch: 4044.7881\n",
      "TP: 1916.0 TN: 6618.0 FP: 103.0 FN: 842.0\n",
      "test Loss: 0.2728 Acc: 0.8778 Pre: 0.9318 Rec: 0.6622 F1: 0.7742 Time in epoch: 4114.5748\n",
      "TP: 1570.0 TN: 5010.0 FP: 115.0 FN: 801.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.3564 Acc: 0.8451 Pre: 0.7450 Rec: 0.6758 F1: 0.7087 Time in epoch: 3759.3200\n",
      "TP: 64924.0 TN: 226303.0 FP: 22228.0 FN: 31139.0\n",
      "val Loss: 0.1957 Acc: 0.9358 Pre: 0.8779 Rec: 0.9050 F1: 0.8913 Time in epoch: 3844.3713\n",
      "TP: 2496.0 TN: 6374.0 FP: 347.0 FN: 262.0\n",
      "test Loss: 0.2102 Acc: 0.9253 Pre: 0.8832 Rec: 0.8802 F1: 0.8817 Time in epoch: 3911.5451\n",
      "TP: 2087.0 TN: 4849.0 FP: 276.0 FN: 284.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.3522 Acc: 0.8476 Pre: 0.7491 Rec: 0.6818 F1: 0.7139 Time in epoch: 3776.3461\n",
      "TP: 65499.0 TN: 226589.0 FP: 21942.0 FN: 30564.0\n",
      "val Loss: 0.1903 Acc: 0.9359 Pre: 0.9138 Rec: 0.8608 F1: 0.8865 Time in epoch: 3862.7855\n",
      "TP: 2374.0 TN: 6497.0 FP: 224.0 FN: 384.0\n",
      "test Loss: 0.2163 Acc: 0.9208 Pre: 0.9055 Rec: 0.8368 F1: 0.8698 Time in epoch: 3930.6696\n",
      "TP: 1984.0 TN: 4918.0 FP: 207.0 FN: 387.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3503 Acc: 0.8490 Pre: 0.7510 Rec: 0.6856 F1: 0.7168 Time in epoch: 4623.2007\n",
      "TP: 65861.0 TN: 226698.0 FP: 21833.0 FN: 30202.0\n",
      "val Loss: 0.2453 Acc: 0.8865 Pre: 0.9631 Rec: 0.6342 F1: 0.7648 Time in epoch: 4725.4323\n",
      "TP: 1749.0 TN: 6654.0 FP: 67.0 FN: 1009.0\n",
      "test Loss: 0.2961 Acc: 0.8635 Pre: 0.9417 Rec: 0.6061 F1: 0.7375 Time in epoch: 4795.5059\n",
      "TP: 1437.0 TN: 5036.0 FP: 89.0 FN: 934.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_last_layer_500/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    # model_ts = models.resnet50(pretrained=True)\n",
    "    # num_ftrs = model_ts.fc.in_features\n",
    "    # model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts = get_frozen_model()\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3458 Acc: 0.8558 Pre: 0.7837 Rec: 0.7014 F1: 0.7403 Time in epoch: 580.2464\n",
      "TP: 13178.0 TN: 41706.0 FP: 3637.0 FN: 5609.0\n",
      "val Loss: 0.2278 Acc: 0.9142 Pre: 0.8505 Rec: 0.8557 F1: 0.8531 Time in epoch: 659.5008\n",
      "TP: 2360.0 TN: 6306.0 FP: 415.0 FN: 398.0\n",
      "test Loss: 0.2241 Acc: 0.9177 Pre: 0.8994 Rec: 0.8330 F1: 0.8649 Time in epoch: 722.8421\n",
      "TP: 1975.0 TN: 4904.0 FP: 221.0 FN: 396.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.3197 Acc: 0.8692 Pre: 0.7981 Rec: 0.7412 F1: 0.7686 Time in epoch: 508.4394\n",
      "TP: 13924.0 TN: 41820.0 FP: 3523.0 FN: 4863.0\n",
      "val Loss: 0.2058 Acc: 0.9249 Pre: 0.8855 Rec: 0.8521 F1: 0.8684 Time in epoch: 588.0026\n",
      "TP: 2350.0 TN: 6417.0 FP: 304.0 FN: 408.0\n",
      "test Loss: 0.2149 Acc: 0.9192 Pre: 0.9099 Rec: 0.8262 F1: 0.8660 Time in epoch: 651.7489\n",
      "TP: 1959.0 TN: 4931.0 FP: 194.0 FN: 412.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.3128 Acc: 0.8735 Pre: 0.8056 Rec: 0.7487 F1: 0.7761 Time in epoch: 508.1709\n",
      "TP: 14066.0 TN: 41949.0 FP: 3394.0 FN: 4721.0\n",
      "val Loss: 0.2041 Acc: 0.9221 Pre: 0.9066 Rec: 0.8165 F1: 0.8592 Time in epoch: 588.0195\n",
      "TP: 2252.0 TN: 6489.0 FP: 232.0 FN: 506.0\n",
      "test Loss: 0.2244 Acc: 0.9128 Pre: 0.9210 Rec: 0.7921 F1: 0.8517 Time in epoch: 651.6115\n",
      "TP: 1878.0 TN: 4964.0 FP: 161.0 FN: 493.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3051 Acc: 0.8799 Pre: 0.8144 Rec: 0.7641 F1: 0.7884 Time in epoch: 508.7929\n",
      "TP: 14355.0 TN: 42071.0 FP: 3272.0 FN: 4432.0\n",
      "val Loss: 0.2021 Acc: 0.9266 Pre: 0.9059 Rec: 0.8343 F1: 0.8686 Time in epoch: 589.0323\n",
      "TP: 2301.0 TN: 6482.0 FP: 239.0 FN: 457.0\n",
      "test Loss: 0.2188 Acc: 0.9148 Pre: 0.9220 Rec: 0.7980 F1: 0.8555 Time in epoch: 652.9732\n",
      "TP: 1892.0 TN: 4965.0 FP: 160.0 FN: 479.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3020 Acc: 0.8808 Pre: 0.8163 Rec: 0.7651 F1: 0.7899 Time in epoch: 509.3087\n",
      "TP: 14374.0 TN: 42109.0 FP: 3234.0 FN: 4413.0\n",
      "val Loss: 0.2030 Acc: 0.9246 Pre: 0.8528 Rec: 0.8952 F1: 0.8735 Time in epoch: 589.4046\n",
      "TP: 2469.0 TN: 6295.0 FP: 426.0 FN: 289.0\n",
      "test Loss: 0.2055 Acc: 0.9237 Pre: 0.8862 Rec: 0.8705 F1: 0.8783 Time in epoch: 653.5707\n",
      "TP: 2064.0 TN: 4860.0 FP: 265.0 FN: 307.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2986 Acc: 0.8799 Pre: 0.8129 Rec: 0.7666 F1: 0.7891 Time in epoch: 509.0137\n",
      "TP: 14403.0 TN: 42028.0 FP: 3315.0 FN: 4384.0\n",
      "val Loss: 0.2108 Acc: 0.9178 Pre: 0.9349 Rec: 0.7712 F1: 0.8452 Time in epoch: 589.0116\n",
      "TP: 2127.0 TN: 6573.0 FP: 148.0 FN: 631.0\n",
      "test Loss: 0.2384 Acc: 0.9039 Pre: 0.9352 Rec: 0.7482 F1: 0.8313 Time in epoch: 653.0423\n",
      "TP: 1774.0 TN: 5002.0 FP: 123.0 FN: 597.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2877 Acc: 0.8873 Pre: 0.8269 Rec: 0.7781 F1: 0.8017 Time in epoch: 509.4635\n",
      "TP: 14618.0 TN: 42282.0 FP: 3061.0 FN: 4169.0\n",
      "val Loss: 0.1895 Acc: 0.9313 Pre: 0.9098 Rec: 0.8481 F1: 0.8778 Time in epoch: 589.3915\n",
      "TP: 2339.0 TN: 6489.0 FP: 232.0 FN: 419.0\n",
      "test Loss: 0.2084 Acc: 0.9190 Pre: 0.9196 Rec: 0.8153 F1: 0.8643 Time in epoch: 653.3596\n",
      "TP: 1933.0 TN: 4956.0 FP: 169.0 FN: 438.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2874 Acc: 0.8885 Pre: 0.8293 Rec: 0.7801 F1: 0.8039 Time in epoch: 509.2371\n",
      "TP: 14655.0 TN: 42327.0 FP: 3016.0 FN: 4132.0\n",
      "val Loss: 0.1915 Acc: 0.9306 Pre: 0.9070 Rec: 0.8484 F1: 0.8767 Time in epoch: 589.1728\n",
      "TP: 2340.0 TN: 6481.0 FP: 240.0 FN: 418.0\n",
      "test Loss: 0.2090 Acc: 0.9208 Pre: 0.9189 Rec: 0.8220 F1: 0.8678 Time in epoch: 652.9275\n",
      "TP: 1949.0 TN: 4953.0 FP: 172.0 FN: 422.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2865 Acc: 0.8881 Pre: 0.8290 Rec: 0.7789 F1: 0.8032 Time in epoch: 508.9196\n",
      "TP: 14633.0 TN: 42324.0 FP: 3019.0 FN: 4154.0\n",
      "val Loss: 0.1905 Acc: 0.9321 Pre: 0.8858 Rec: 0.8800 F1: 0.8829 Time in epoch: 588.8098\n",
      "TP: 2427.0 TN: 6408.0 FP: 313.0 FN: 331.0\n",
      "test Loss: 0.1996 Acc: 0.9258 Pre: 0.9068 Rec: 0.8532 F1: 0.8792 Time in epoch: 653.0786\n",
      "TP: 2023.0 TN: 4917.0 FP: 208.0 FN: 348.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.2853 Acc: 0.8889 Pre: 0.8305 Rec: 0.7801 F1: 0.8045 Time in epoch: 508.8146\n",
      "TP: 14656.0 TN: 42351.0 FP: 2992.0 FN: 4131.0\n",
      "val Loss: 0.1862 Acc: 0.9346 Pre: 0.8977 Rec: 0.8749 F1: 0.8862 Time in epoch: 589.4837\n",
      "TP: 2413.0 TN: 6446.0 FP: 275.0 FN: 345.0\n",
      "test Loss: 0.2020 Acc: 0.9241 Pre: 0.9103 Rec: 0.8431 F1: 0.8754 Time in epoch: 653.4646\n",
      "TP: 1999.0 TN: 4928.0 FP: 197.0 FN: 372.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.2847 Acc: 0.8889 Pre: 0.8313 Rec: 0.7786 F1: 0.8041 Time in epoch: 509.1155\n",
      "TP: 14628.0 TN: 42374.0 FP: 2969.0 FN: 4159.0\n",
      "val Loss: 0.1945 Acc: 0.9314 Pre: 0.8629 Rec: 0.9086 F1: 0.8852 Time in epoch: 588.9513\n",
      "TP: 2506.0 TN: 6323.0 FP: 398.0 FN: 252.0\n",
      "test Loss: 0.1944 Acc: 0.9313 Pre: 0.8939 Rec: 0.8882 F1: 0.8911 Time in epoch: 652.9799\n",
      "TP: 2106.0 TN: 4875.0 FP: 250.0 FN: 265.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.2875 Acc: 0.8888 Pre: 0.8307 Rec: 0.7794 F1: 0.8042 Time in epoch: 508.4949\n",
      "TP: 14643.0 TN: 42358.0 FP: 2985.0 FN: 4144.0\n",
      "val Loss: 0.1861 Acc: 0.9340 Pre: 0.8896 Rec: 0.8825 F1: 0.8861 Time in epoch: 587.7734\n",
      "TP: 2434.0 TN: 6419.0 FP: 302.0 FN: 324.0\n",
      "test Loss: 0.1979 Acc: 0.9266 Pre: 0.9088 Rec: 0.8536 F1: 0.8804 Time in epoch: 651.4877\n",
      "TP: 2024.0 TN: 4922.0 FP: 203.0 FN: 347.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.2849 Acc: 0.8882 Pre: 0.8283 Rec: 0.7801 F1: 0.8035 Time in epoch: 509.3637\n",
      "TP: 14656.0 TN: 42304.0 FP: 3039.0 FN: 4131.0\n",
      "val Loss: 0.1861 Acc: 0.9350 Pre: 0.8861 Rec: 0.8912 F1: 0.8886 Time in epoch: 589.1784\n",
      "TP: 2458.0 TN: 6405.0 FP: 316.0 FN: 300.0\n",
      "test Loss: 0.1969 Acc: 0.9286 Pre: 0.9080 Rec: 0.8617 F1: 0.8842 Time in epoch: 653.0392\n",
      "TP: 2043.0 TN: 4918.0 FP: 207.0 FN: 328.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2834 Acc: 0.8907 Pre: 0.8350 Rec: 0.7814 F1: 0.8073 Time in epoch: 508.7617\n",
      "TP: 14680.0 TN: 42443.0 FP: 2900.0 FN: 4107.0\n",
      "val Loss: 0.1869 Acc: 0.9341 Pre: 0.8990 Rec: 0.8713 F1: 0.8849 Time in epoch: 589.0145\n",
      "TP: 2403.0 TN: 6451.0 FP: 270.0 FN: 355.0\n",
      "test Loss: 0.1992 Acc: 0.9256 Pre: 0.9134 Rec: 0.8448 F1: 0.8777 Time in epoch: 652.7261\n",
      "TP: 2003.0 TN: 4935.0 FP: 190.0 FN: 368.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2860 Acc: 0.8900 Pre: 0.8324 Rec: 0.7821 F1: 0.8065 Time in epoch: 508.9203\n",
      "TP: 14693.0 TN: 42385.0 FP: 2958.0 FN: 4094.0\n",
      "val Loss: 0.1933 Acc: 0.9318 Pre: 0.8780 Rec: 0.8894 F1: 0.8836 Time in epoch: 588.7646\n",
      "TP: 2453.0 TN: 6380.0 FP: 341.0 FN: 305.0\n",
      "test Loss: 0.2022 Acc: 0.9270 Pre: 0.9046 Rec: 0.8600 F1: 0.8817 Time in epoch: 652.6315\n",
      "TP: 2039.0 TN: 4910.0 FP: 215.0 FN: 332.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2828 Acc: 0.8900 Pre: 0.8326 Rec: 0.7817 F1: 0.8063 Time in epoch: 509.0827\n",
      "TP: 14686.0 TN: 42390.0 FP: 2953.0 FN: 4101.0\n",
      "val Loss: 0.1847 Acc: 0.9355 Pre: 0.9102 Rec: 0.8637 F1: 0.8863 Time in epoch: 589.0598\n",
      "TP: 2382.0 TN: 6486.0 FP: 235.0 FN: 376.0\n",
      "test Loss: 0.2038 Acc: 0.9228 Pre: 0.9191 Rec: 0.8288 F1: 0.8716 Time in epoch: 652.9456\n",
      "TP: 1965.0 TN: 4952.0 FP: 173.0 FN: 406.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2852 Acc: 0.8909 Pre: 0.8339 Rec: 0.7837 F1: 0.8081 Time in epoch: 508.8441\n",
      "TP: 14724.0 TN: 42411.0 FP: 2932.0 FN: 4063.0\n",
      "val Loss: 0.1867 Acc: 0.9336 Pre: 0.8941 Rec: 0.8756 F1: 0.8848 Time in epoch: 588.6981\n",
      "TP: 2415.0 TN: 6435.0 FP: 286.0 FN: 343.0\n",
      "test Loss: 0.2027 Acc: 0.9249 Pre: 0.9128 Rec: 0.8431 F1: 0.8766 Time in epoch: 652.5008\n",
      "TP: 1999.0 TN: 4934.0 FP: 191.0 FN: 372.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2816 Acc: 0.8927 Pre: 0.8367 Rec: 0.7874 F1: 0.8113 Time in epoch: 508.7916\n",
      "TP: 14792.0 TN: 42456.0 FP: 2887.0 FN: 3995.0\n",
      "val Loss: 0.1872 Acc: 0.9342 Pre: 0.9069 Rec: 0.8622 F1: 0.8840 Time in epoch: 588.8482\n",
      "TP: 2378.0 TN: 6477.0 FP: 244.0 FN: 380.0\n",
      "test Loss: 0.2043 Acc: 0.9236 Pre: 0.9197 Rec: 0.8309 F1: 0.8730 Time in epoch: 652.6724\n",
      "TP: 1970.0 TN: 4953.0 FP: 172.0 FN: 401.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2858 Acc: 0.8889 Pre: 0.8292 Rec: 0.7816 F1: 0.8047 Time in epoch: 508.9482\n",
      "TP: 14684.0 TN: 42319.0 FP: 3024.0 FN: 4103.0\n",
      "val Loss: 0.1842 Acc: 0.9351 Pre: 0.9018 Rec: 0.8720 F1: 0.8866 Time in epoch: 588.5829\n",
      "TP: 2405.0 TN: 6459.0 FP: 262.0 FN: 353.0\n",
      "test Loss: 0.2000 Acc: 0.9245 Pre: 0.9123 Rec: 0.8423 F1: 0.8759 Time in epoch: 652.3789\n",
      "TP: 1997.0 TN: 4933.0 FP: 192.0 FN: 374.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2865 Acc: 0.8902 Pre: 0.8324 Rec: 0.7827 F1: 0.8068 Time in epoch: 509.0388\n",
      "TP: 14705.0 TN: 42382.0 FP: 2961.0 FN: 4082.0\n",
      "val Loss: 0.1900 Acc: 0.9324 Pre: 0.9039 Rec: 0.8590 F1: 0.8808 Time in epoch: 588.8203\n",
      "TP: 2369.0 TN: 6469.0 FP: 252.0 FN: 389.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2061 Acc: 0.9221 Pre: 0.9146 Rec: 0.8313 F1: 0.8710 Time in epoch: 652.6959\n",
      "TP: 1971.0 TN: 4941.0 FP: 184.0 FN: 400.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2852 Acc: 0.8903 Pre: 0.8309 Rec: 0.7853 F1: 0.8075 Time in epoch: 509.3391\n",
      "TP: 14754.0 TN: 42340.0 FP: 3003.0 FN: 4033.0\n",
      "val Loss: 0.1853 Acc: 0.9356 Pre: 0.9022 Rec: 0.8735 F1: 0.8876 Time in epoch: 589.0807\n",
      "TP: 2409.0 TN: 6460.0 FP: 261.0 FN: 349.0\n",
      "test Loss: 0.2015 Acc: 0.9254 Pre: 0.9148 Rec: 0.8427 F1: 0.8773 Time in epoch: 652.8833\n",
      "TP: 1998.0 TN: 4939.0 FP: 186.0 FN: 373.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2864 Acc: 0.8893 Pre: 0.8298 Rec: 0.7825 F1: 0.8055 Time in epoch: 509.2605\n",
      "TP: 14701.0 TN: 42328.0 FP: 3015.0 FN: 4086.0\n",
      "val Loss: 0.1891 Acc: 0.9316 Pre: 0.9086 Rec: 0.8506 F1: 0.8787 Time in epoch: 589.1116\n",
      "TP: 2346.0 TN: 6485.0 FP: 236.0 FN: 412.0\n",
      "test Loss: 0.2055 Acc: 0.9206 Pre: 0.9181 Rec: 0.8224 F1: 0.8676 Time in epoch: 652.6662\n",
      "TP: 1950.0 TN: 4951.0 FP: 174.0 FN: 421.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2838 Acc: 0.8891 Pre: 0.8314 Rec: 0.7796 F1: 0.8047 Time in epoch: 508.7422\n",
      "TP: 14647.0 TN: 42372.0 FP: 2971.0 FN: 4140.0\n",
      "val Loss: 0.1954 Acc: 0.9297 Pre: 0.8701 Rec: 0.8916 F1: 0.8807 Time in epoch: 588.8755\n",
      "TP: 2459.0 TN: 6354.0 FP: 367.0 FN: 299.0\n",
      "test Loss: 0.2026 Acc: 0.9268 Pre: 0.8978 Rec: 0.8671 F1: 0.8822 Time in epoch: 652.4493\n",
      "TP: 2056.0 TN: 4891.0 FP: 234.0 FN: 315.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2834 Acc: 0.8906 Pre: 0.8332 Rec: 0.7836 F1: 0.8076 Time in epoch: 512.8455\n",
      "TP: 14721.0 TN: 42395.0 FP: 2948.0 FN: 4066.0\n",
      "val Loss: 0.1899 Acc: 0.9330 Pre: 0.8820 Rec: 0.8887 F1: 0.8853 Time in epoch: 592.8724\n",
      "TP: 2451.0 TN: 6393.0 FP: 328.0 FN: 307.0\n",
      "test Loss: 0.1985 Acc: 0.9264 Pre: 0.9001 Rec: 0.8629 F1: 0.8811 Time in epoch: 656.7734\n",
      "TP: 2046.0 TN: 4898.0 FP: 227.0 FN: 325.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2831 Acc: 0.8905 Pre: 0.8332 Rec: 0.7831 F1: 0.8074 Time in epoch: 510.0379\n",
      "TP: 14713.0 TN: 42397.0 FP: 2946.0 FN: 4074.0\n",
      "val Loss: 0.1860 Acc: 0.9344 Pre: 0.8938 Rec: 0.8789 F1: 0.8863 Time in epoch: 589.8885\n",
      "TP: 2424.0 TN: 6433.0 FP: 288.0 FN: 334.0\n",
      "test Loss: 0.1992 Acc: 0.9257 Pre: 0.9078 Rec: 0.8515 F1: 0.8788 Time in epoch: 653.7889\n",
      "TP: 2019.0 TN: 4920.0 FP: 205.0 FN: 352.0\n",
      "\n",
      "Training complete in 273m 28s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_last_layer_100/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    # model_ts = models.resnet50(pretrained=True)\n",
    "    # num_ftrs = model_ts.fc.in_features\n",
    "    # model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts = get_frozen_model()\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3751 Acc: 0.8365 Pre: 0.7662 Rec: 0.6658 F1: 0.7125 Time in epoch: 205.8512\n",
      "TP: 5175.0 TN: 16200.0 FP: 1579.0 FN: 2598.0\n",
      "val Loss: 0.2419 Acc: 0.9095 Pre: 0.9123 Rec: 0.7621 F1: 0.8305 Time in epoch: 284.4778\n",
      "TP: 2102.0 TN: 6519.0 FP: 202.0 FN: 656.0\n",
      "test Loss: 0.2656 Acc: 0.8925 Pre: 0.9187 Rec: 0.7242 F1: 0.8099 Time in epoch: 347.3604\n",
      "TP: 1717.0 TN: 4973.0 FP: 152.0 FN: 654.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.3402 Acc: 0.8574 Pre: 0.7872 Rec: 0.7282 F1: 0.7565 Time in epoch: 202.9342\n",
      "TP: 5660.0 TN: 16249.0 FP: 1530.0 FN: 2113.0\n",
      "val Loss: 0.2281 Acc: 0.9161 Pre: 0.8532 Rec: 0.8597 F1: 0.8564 Time in epoch: 281.6697\n",
      "TP: 2371.0 TN: 6313.0 FP: 408.0 FN: 387.0\n",
      "test Loss: 0.2321 Acc: 0.9144 Pre: 0.8889 Rec: 0.8334 F1: 0.8603 Time in epoch: 344.5407\n",
      "TP: 1976.0 TN: 4878.0 FP: 247.0 FN: 395.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.3219 Acc: 0.8682 Pre: 0.8052 Rec: 0.7475 F1: 0.7752 Time in epoch: 202.9447\n",
      "TP: 5810.0 TN: 16373.0 FP: 1406.0 FN: 1963.0\n",
      "val Loss: 0.2276 Acc: 0.9114 Pre: 0.9270 Rec: 0.7549 F1: 0.8321 Time in epoch: 282.3632\n",
      "TP: 2082.0 TN: 6557.0 FP: 164.0 FN: 676.0\n",
      "test Loss: 0.2618 Acc: 0.8921 Pre: 0.9282 Rec: 0.7140 F1: 0.8072 Time in epoch: 345.6421\n",
      "TP: 1693.0 TN: 4994.0 FP: 131.0 FN: 678.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3214 Acc: 0.8676 Pre: 0.8010 Rec: 0.7516 F1: 0.7755 Time in epoch: 203.3240\n",
      "TP: 5842.0 TN: 16328.0 FP: 1451.0 FN: 1931.0\n",
      "val Loss: 0.2182 Acc: 0.9170 Pre: 0.8624 Rec: 0.8503 F1: 0.8563 Time in epoch: 283.1122\n",
      "TP: 2345.0 TN: 6347.0 FP: 374.0 FN: 413.0\n",
      "test Loss: 0.2254 Acc: 0.9150 Pre: 0.8952 Rec: 0.8283 F1: 0.8605 Time in epoch: 346.5956\n",
      "TP: 1964.0 TN: 4895.0 FP: 230.0 FN: 407.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3152 Acc: 0.8724 Pre: 0.8083 Rec: 0.7610 F1: 0.7839 Time in epoch: 202.8577\n",
      "TP: 5915.0 TN: 16376.0 FP: 1403.0 FN: 1858.0\n",
      "val Loss: 0.2260 Acc: 0.9143 Pre: 0.8186 Rec: 0.9065 F1: 0.8603 Time in epoch: 282.4293\n",
      "TP: 2500.0 TN: 6167.0 FP: 554.0 FN: 258.0\n",
      "test Loss: 0.2185 Acc: 0.9228 Pre: 0.8724 Rec: 0.8853 F1: 0.8788 Time in epoch: 345.9717\n",
      "TP: 2099.0 TN: 4818.0 FP: 307.0 FN: 272.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3125 Acc: 0.8746 Pre: 0.8143 Rec: 0.7614 F1: 0.7869 Time in epoch: 202.8683\n",
      "TP: 5918.0 TN: 16429.0 FP: 1350.0 FN: 1855.0\n",
      "val Loss: 0.2068 Acc: 0.9239 Pre: 0.8735 Rec: 0.8637 F1: 0.8686 Time in epoch: 282.3759\n",
      "TP: 2382.0 TN: 6376.0 FP: 345.0 FN: 376.0\n",
      "test Loss: 0.2179 Acc: 0.9193 Pre: 0.8977 Rec: 0.8406 F1: 0.8682 Time in epoch: 345.9331\n",
      "TP: 1993.0 TN: 4898.0 FP: 227.0 FN: 378.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2971 Acc: 0.8842 Pre: 0.8302 Rec: 0.7783 F1: 0.8035 Time in epoch: 203.0029\n",
      "TP: 6050.0 TN: 16542.0 FP: 1237.0 FN: 1723.0\n",
      "val Loss: 0.2036 Acc: 0.9256 Pre: 0.8852 Rec: 0.8553 F1: 0.8700 Time in epoch: 282.9067\n",
      "TP: 2359.0 TN: 6415.0 FP: 306.0 FN: 399.0\n",
      "test Loss: 0.2172 Acc: 0.9177 Pre: 0.9019 Rec: 0.8300 F1: 0.8645 Time in epoch: 346.6509\n",
      "TP: 1968.0 TN: 4911.0 FP: 214.0 FN: 403.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3012 Acc: 0.8817 Pre: 0.8266 Rec: 0.7734 F1: 0.7991 Time in epoch: 203.1432\n",
      "TP: 6012.0 TN: 16518.0 FP: 1261.0 FN: 1761.0\n",
      "val Loss: 0.2050 Acc: 0.9259 Pre: 0.8735 Rec: 0.8716 F1: 0.8726 Time in epoch: 283.1199\n",
      "TP: 2404.0 TN: 6373.0 FP: 348.0 FN: 354.0\n",
      "test Loss: 0.2165 Acc: 0.9189 Pre: 0.8955 Rec: 0.8418 F1: 0.8678 Time in epoch: 346.7920\n",
      "TP: 1996.0 TN: 4892.0 FP: 233.0 FN: 375.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3013 Acc: 0.8804 Pre: 0.8236 Rec: 0.7724 F1: 0.7972 Time in epoch: 203.1566\n",
      "TP: 6004.0 TN: 16493.0 FP: 1286.0 FN: 1769.0\n",
      "val Loss: 0.2024 Acc: 0.9271 Pre: 0.8866 Rec: 0.8593 F1: 0.8728 Time in epoch: 283.0181\n",
      "TP: 2370.0 TN: 6418.0 FP: 303.0 FN: 388.0\n",
      "test Loss: 0.2167 Acc: 0.9181 Pre: 0.9021 Rec: 0.8313 F1: 0.8652 Time in epoch: 346.7069\n",
      "TP: 1971.0 TN: 4911.0 FP: 214.0 FN: 400.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.2999 Acc: 0.8813 Pre: 0.8276 Rec: 0.7704 F1: 0.7980 Time in epoch: 203.2603\n",
      "TP: 5988.0 TN: 16532.0 FP: 1247.0 FN: 1785.0\n",
      "val Loss: 0.2069 Acc: 0.9241 Pre: 0.8783 Rec: 0.8582 F1: 0.8681 Time in epoch: 283.1511\n",
      "TP: 2367.0 TN: 6393.0 FP: 328.0 FN: 391.0\n",
      "test Loss: 0.2179 Acc: 0.9181 Pre: 0.9013 Rec: 0.8321 F1: 0.8654 Time in epoch: 347.0181\n",
      "TP: 1973.0 TN: 4909.0 FP: 216.0 FN: 398.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3032 Acc: 0.8785 Pre: 0.8232 Rec: 0.7648 F1: 0.7929 Time in epoch: 203.1611\n",
      "TP: 5945.0 TN: 16502.0 FP: 1277.0 FN: 1828.0\n",
      "val Loss: 0.2001 Acc: 0.9264 Pre: 0.9042 Rec: 0.8354 F1: 0.8685 Time in epoch: 282.9337\n",
      "TP: 2304.0 TN: 6477.0 FP: 244.0 FN: 454.0\n",
      "test Loss: 0.2233 Acc: 0.9154 Pre: 0.9142 Rec: 0.8085 F1: 0.8581 Time in epoch: 346.5457\n",
      "TP: 1917.0 TN: 4945.0 FP: 180.0 FN: 454.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3010 Acc: 0.8808 Pre: 0.8245 Rec: 0.7725 F1: 0.7977 Time in epoch: 202.9969\n",
      "TP: 6005.0 TN: 16501.0 FP: 1278.0 FN: 1768.0\n",
      "val Loss: 0.2086 Acc: 0.9249 Pre: 0.8669 Rec: 0.8764 F1: 0.8716 Time in epoch: 282.3266\n",
      "TP: 2417.0 TN: 6350.0 FP: 371.0 FN: 341.0\n",
      "test Loss: 0.2149 Acc: 0.9208 Pre: 0.8947 Rec: 0.8494 F1: 0.8715 Time in epoch: 345.8141\n",
      "TP: 2014.0 TN: 4888.0 FP: 237.0 FN: 357.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3018 Acc: 0.8809 Pre: 0.8242 Rec: 0.7736 F1: 0.7981 Time in epoch: 203.0701\n",
      "TP: 6013.0 TN: 16496.0 FP: 1283.0 FN: 1760.0\n",
      "val Loss: 0.2084 Acc: 0.9248 Pre: 0.8653 Rec: 0.8782 F1: 0.8717 Time in epoch: 283.0883\n",
      "TP: 2422.0 TN: 6344.0 FP: 377.0 FN: 336.0\n",
      "test Loss: 0.2151 Acc: 0.9200 Pre: 0.8927 Rec: 0.8490 F1: 0.8703 Time in epoch: 346.7095\n",
      "TP: 2013.0 TN: 4883.0 FP: 242.0 FN: 358.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2997 Acc: 0.8822 Pre: 0.8285 Rec: 0.7729 F1: 0.7997 Time in epoch: 202.8682\n",
      "TP: 6008.0 TN: 16535.0 FP: 1244.0 FN: 1765.0\n",
      "val Loss: 0.2061 Acc: 0.9257 Pre: 0.8815 Rec: 0.8604 F1: 0.8708 Time in epoch: 282.1529\n",
      "TP: 2373.0 TN: 6402.0 FP: 319.0 FN: 385.0\n",
      "test Loss: 0.2169 Acc: 0.9172 Pre: 0.8981 Rec: 0.8326 F1: 0.8641 Time in epoch: 345.6947\n",
      "TP: 1974.0 TN: 4901.0 FP: 224.0 FN: 397.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2992 Acc: 0.8833 Pre: 0.8277 Rec: 0.7782 F1: 0.8022 Time in epoch: 202.6174\n",
      "TP: 6049.0 TN: 16520.0 FP: 1259.0 FN: 1724.0\n",
      "val Loss: 0.2045 Acc: 0.9246 Pre: 0.8891 Rec: 0.8463 F1: 0.8672 Time in epoch: 281.8753\n",
      "TP: 2334.0 TN: 6430.0 FP: 291.0 FN: 424.0\n",
      "test Loss: 0.2193 Acc: 0.9170 Pre: 0.9081 Rec: 0.8208 F1: 0.8622 Time in epoch: 345.2036\n",
      "TP: 1946.0 TN: 4928.0 FP: 197.0 FN: 425.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2973 Acc: 0.8824 Pre: 0.8299 Rec: 0.7718 F1: 0.7998 Time in epoch: 202.4336\n",
      "TP: 5999.0 TN: 16549.0 FP: 1230.0 FN: 1774.0\n",
      "val Loss: 0.2016 Acc: 0.9262 Pre: 0.8874 Rec: 0.8546 F1: 0.8707 Time in epoch: 281.8360\n",
      "TP: 2357.0 TN: 6422.0 FP: 299.0 FN: 401.0\n",
      "test Loss: 0.2183 Acc: 0.9173 Pre: 0.9078 Rec: 0.8220 F1: 0.8628 Time in epoch: 345.1235\n",
      "TP: 1949.0 TN: 4927.0 FP: 198.0 FN: 422.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2984 Acc: 0.8816 Pre: 0.8221 Rec: 0.7794 F1: 0.8002 Time in epoch: 202.8116\n",
      "TP: 6058.0 TN: 16468.0 FP: 1311.0 FN: 1715.0\n",
      "val Loss: 0.2078 Acc: 0.9250 Pre: 0.8691 Rec: 0.8738 F1: 0.8715 Time in epoch: 282.2842\n",
      "TP: 2410.0 TN: 6358.0 FP: 363.0 FN: 348.0\n",
      "test Loss: 0.2154 Acc: 0.9193 Pre: 0.8935 Rec: 0.8456 F1: 0.8689 Time in epoch: 345.7184\n",
      "TP: 2005.0 TN: 4886.0 FP: 239.0 FN: 366.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2989 Acc: 0.8829 Pre: 0.8280 Rec: 0.7761 F1: 0.8012 Time in epoch: 203.2009\n",
      "TP: 6033.0 TN: 16526.0 FP: 1253.0 FN: 1740.0\n",
      "val Loss: 0.2067 Acc: 0.9246 Pre: 0.8883 Rec: 0.8474 F1: 0.8673 Time in epoch: 282.6030\n",
      "TP: 2337.0 TN: 6427.0 FP: 294.0 FN: 421.0\n",
      "test Loss: 0.2204 Acc: 0.9164 Pre: 0.9048 Rec: 0.8220 F1: 0.8614 Time in epoch: 346.0419\n",
      "TP: 1949.0 TN: 4920.0 FP: 205.0 FN: 422.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2950 Acc: 0.8835 Pre: 0.8308 Rec: 0.7750 F1: 0.8019 Time in epoch: 202.6597\n",
      "TP: 6024.0 TN: 16552.0 FP: 1227.0 FN: 1749.0\n",
      "val Loss: 0.2117 Acc: 0.9257 Pre: 0.8614 Rec: 0.8876 F1: 0.8743 Time in epoch: 282.1552\n",
      "TP: 2448.0 TN: 6327.0 FP: 394.0 FN: 310.0\n",
      "test Loss: 0.2130 Acc: 0.9208 Pre: 0.8875 Rec: 0.8583 F1: 0.8726 Time in epoch: 345.7035\n",
      "TP: 2035.0 TN: 4867.0 FP: 258.0 FN: 336.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2954 Acc: 0.8821 Pre: 0.8237 Rec: 0.7791 F1: 0.8008 Time in epoch: 202.7727\n",
      "TP: 6056.0 TN: 16483.0 FP: 1296.0 FN: 1717.0\n",
      "val Loss: 0.2038 Acc: 0.9260 Pre: 0.8819 Rec: 0.8611 F1: 0.8714 Time in epoch: 282.5246\n",
      "TP: 2375.0 TN: 6403.0 FP: 318.0 FN: 383.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2161 Acc: 0.9185 Pre: 0.9044 Rec: 0.8300 F1: 0.8656 Time in epoch: 345.8309\n",
      "TP: 1968.0 TN: 4917.0 FP: 208.0 FN: 403.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2947 Acc: 0.8845 Pre: 0.8337 Rec: 0.7747 F1: 0.8031 Time in epoch: 202.9522\n",
      "TP: 6022.0 TN: 16578.0 FP: 1201.0 FN: 1751.0\n",
      "val Loss: 0.2068 Acc: 0.9265 Pre: 0.8730 Rec: 0.8745 F1: 0.8738 Time in epoch: 282.3615\n",
      "TP: 2412.0 TN: 6370.0 FP: 351.0 FN: 346.0\n",
      "test Loss: 0.2143 Acc: 0.9200 Pre: 0.8948 Rec: 0.8465 F1: 0.8700 Time in epoch: 345.9156\n",
      "TP: 2007.0 TN: 4889.0 FP: 236.0 FN: 364.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2970 Acc: 0.8815 Pre: 0.8295 Rec: 0.7682 F1: 0.7977 Time in epoch: 203.3916\n",
      "TP: 5971.0 TN: 16552.0 FP: 1227.0 FN: 1802.0\n",
      "val Loss: 0.2100 Acc: 0.9243 Pre: 0.8539 Rec: 0.8923 F1: 0.8727 Time in epoch: 283.0435\n",
      "TP: 2461.0 TN: 6300.0 FP: 421.0 FN: 297.0\n",
      "test Loss: 0.2134 Acc: 0.9225 Pre: 0.8881 Rec: 0.8638 F1: 0.8758 Time in epoch: 346.7855\n",
      "TP: 2048.0 TN: 4867.0 FP: 258.0 FN: 323.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2945 Acc: 0.8864 Pre: 0.8331 Rec: 0.7835 F1: 0.8075 Time in epoch: 202.8921\n",
      "TP: 6090.0 TN: 16559.0 FP: 1220.0 FN: 1683.0\n",
      "val Loss: 0.2087 Acc: 0.9252 Pre: 0.8684 Rec: 0.8756 F1: 0.8720 Time in epoch: 282.5531\n",
      "TP: 2415.0 TN: 6355.0 FP: 366.0 FN: 343.0\n",
      "test Loss: 0.2142 Acc: 0.9204 Pre: 0.8946 Rec: 0.8482 F1: 0.8708 Time in epoch: 345.9805\n",
      "TP: 2011.0 TN: 4888.0 FP: 237.0 FN: 360.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2934 Acc: 0.8850 Pre: 0.8340 Rec: 0.7767 F1: 0.8043 Time in epoch: 203.4337\n",
      "TP: 6037.0 TN: 16577.0 FP: 1202.0 FN: 1736.0\n",
      "val Loss: 0.2085 Acc: 0.9267 Pre: 0.8696 Rec: 0.8800 F1: 0.8748 Time in epoch: 283.3471\n",
      "TP: 2427.0 TN: 6357.0 FP: 364.0 FN: 331.0\n",
      "test Loss: 0.2145 Acc: 0.9213 Pre: 0.8946 Rec: 0.8515 F1: 0.8725 Time in epoch: 347.0655\n",
      "TP: 2019.0 TN: 4887.0 FP: 238.0 FN: 352.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2956 Acc: 0.8845 Pre: 0.8313 Rec: 0.7781 F1: 0.8038 Time in epoch: 203.3383\n",
      "TP: 6048.0 TN: 16552.0 FP: 1227.0 FN: 1725.0\n",
      "val Loss: 0.2008 Acc: 0.9259 Pre: 0.8879 Rec: 0.8532 F1: 0.8702 Time in epoch: 283.5404\n",
      "TP: 2353.0 TN: 6424.0 FP: 297.0 FN: 405.0\n",
      "test Loss: 0.2163 Acc: 0.9181 Pre: 0.9054 Rec: 0.8275 F1: 0.8647 Time in epoch: 347.2095\n",
      "TP: 1962.0 TN: 4920.0 FP: 205.0 FN: 409.0\n",
      "\n",
      "Training complete in 144m 29s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_last_layer_40/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    # model_ts = models.resnet50(pretrained=True)\n",
    "    # num_ftrs = model_ts.fc.in_features\n",
    "    # model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts = get_frozen_model()\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4016 Acc: 0.8237 Pre: 0.7560 Rec: 0.6251 F1: 0.6843 Time in epoch: 115.3591\n",
      "TP: 2506.0 TN: 8297.0 FP: 809.0 FN: 1503.0\n",
      "val Loss: 0.2578 Acc: 0.9045 Pre: 0.8802 Rec: 0.7777 F1: 0.8258 Time in epoch: 194.9282\n",
      "TP: 2145.0 TN: 6429.0 FP: 292.0 FN: 613.0\n",
      "test Loss: 0.2722 Acc: 0.8922 Pre: 0.8993 Rec: 0.7423 F1: 0.8133 Time in epoch: 258.4828\n",
      "TP: 1760.0 TN: 4928.0 FP: 197.0 FN: 611.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.3543 Acc: 0.8515 Pre: 0.7824 Rec: 0.7121 F1: 0.7456 Time in epoch: 104.8160\n",
      "TP: 2855.0 TN: 8312.0 FP: 794.0 FN: 1154.0\n",
      "val Loss: 0.2505 Acc: 0.9049 Pre: 0.8500 Rec: 0.8176 F1: 0.8335 Time in epoch: 183.9567\n",
      "TP: 2255.0 TN: 6323.0 FP: 398.0 FN: 503.0\n",
      "test Loss: 0.2563 Acc: 0.8999 Pre: 0.8850 Rec: 0.7857 F1: 0.8324 Time in epoch: 247.0571\n",
      "TP: 1863.0 TN: 4883.0 FP: 242.0 FN: 508.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.3507 Acc: 0.8512 Pre: 0.7782 Rec: 0.7176 F1: 0.7467 Time in epoch: 104.5226\n",
      "TP: 2877.0 TN: 8286.0 FP: 820.0 FN: 1132.0\n",
      "val Loss: 0.2416 Acc: 0.9124 Pre: 0.8359 Rec: 0.8698 F1: 0.8525 Time in epoch: 184.4451\n",
      "TP: 2399.0 TN: 6250.0 FP: 471.0 FN: 359.0\n",
      "test Loss: 0.2420 Acc: 0.9093 Pre: 0.8694 Rec: 0.8393 F1: 0.8541 Time in epoch: 247.6370\n",
      "TP: 1990.0 TN: 4826.0 FP: 299.0 FN: 381.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3358 Acc: 0.8592 Pre: 0.7896 Rec: 0.7356 F1: 0.7616 Time in epoch: 104.6522\n",
      "TP: 2949.0 TN: 8320.0 FP: 786.0 FN: 1060.0\n",
      "val Loss: 0.2350 Acc: 0.9074 Pre: 0.9031 Rec: 0.7636 F1: 0.8275 Time in epoch: 184.3357\n",
      "TP: 2106.0 TN: 6495.0 FP: 226.0 FN: 652.0\n",
      "test Loss: 0.2591 Acc: 0.8963 Pre: 0.9173 Rec: 0.7389 F1: 0.8185 Time in epoch: 247.9622\n",
      "TP: 1752.0 TN: 4967.0 FP: 158.0 FN: 619.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3407 Acc: 0.8634 Pre: 0.7990 Rec: 0.7388 F1: 0.7678 Time in epoch: 104.6244\n",
      "TP: 2962.0 TN: 8361.0 FP: 745.0 FN: 1047.0\n",
      "val Loss: 0.2459 Acc: 0.9104 Pre: 0.8084 Rec: 0.9072 F1: 0.8549 Time in epoch: 184.3466\n",
      "TP: 2502.0 TN: 6128.0 FP: 593.0 FN: 256.0\n",
      "test Loss: 0.2358 Acc: 0.9112 Pre: 0.8495 Rec: 0.8739 F1: 0.8615 Time in epoch: 247.9091\n",
      "TP: 2072.0 TN: 4758.0 FP: 367.0 FN: 299.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3350 Acc: 0.8614 Pre: 0.7922 Rec: 0.7408 F1: 0.7657 Time in epoch: 104.2226\n",
      "TP: 2970.0 TN: 8327.0 FP: 779.0 FN: 1039.0\n",
      "val Loss: 0.2540 Acc: 0.9046 Pre: 0.7958 Rec: 0.9043 F1: 0.8466 Time in epoch: 183.1390\n",
      "TP: 2494.0 TN: 6081.0 FP: 640.0 FN: 264.0\n",
      "test Loss: 0.2377 Acc: 0.9114 Pre: 0.8499 Rec: 0.8743 F1: 0.8620 Time in epoch: 246.8671\n",
      "TP: 2073.0 TN: 4759.0 FP: 366.0 FN: 298.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3248 Acc: 0.8705 Pre: 0.8052 Rec: 0.7600 F1: 0.7820 Time in epoch: 104.5378\n",
      "TP: 3047.0 TN: 8369.0 FP: 737.0 FN: 962.0\n",
      "val Loss: 0.2256 Acc: 0.9153 Pre: 0.8770 Rec: 0.8245 F1: 0.8499 Time in epoch: 183.6249\n",
      "TP: 2274.0 TN: 6402.0 FP: 319.0 FN: 484.0\n",
      "test Loss: 0.2380 Acc: 0.9076 Pre: 0.8973 Rec: 0.7992 F1: 0.8454 Time in epoch: 247.1027\n",
      "TP: 1895.0 TN: 4908.0 FP: 217.0 FN: 476.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3178 Acc: 0.8715 Pre: 0.8120 Rec: 0.7543 F1: 0.7821 Time in epoch: 104.5388\n",
      "TP: 3024.0 TN: 8406.0 FP: 700.0 FN: 985.0\n",
      "val Loss: 0.2285 Acc: 0.9180 Pre: 0.8482 Rec: 0.8749 F1: 0.8613 Time in epoch: 183.5608\n",
      "TP: 2413.0 TN: 6289.0 FP: 432.0 FN: 345.0\n",
      "test Loss: 0.2302 Acc: 0.9129 Pre: 0.8777 Rec: 0.8418 F1: 0.8594 Time in epoch: 246.6605\n",
      "TP: 1996.0 TN: 4847.0 FP: 278.0 FN: 375.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3189 Acc: 0.8724 Pre: 0.8095 Rec: 0.7620 F1: 0.7850 Time in epoch: 104.4732\n",
      "TP: 3055.0 TN: 8387.0 FP: 719.0 FN: 954.0\n",
      "val Loss: 0.2279 Acc: 0.9163 Pre: 0.8523 Rec: 0.8619 F1: 0.8570 Time in epoch: 183.2316\n",
      "TP: 2377.0 TN: 6309.0 FP: 412.0 FN: 381.0\n",
      "test Loss: 0.2314 Acc: 0.9122 Pre: 0.8836 Rec: 0.8321 F1: 0.8571 Time in epoch: 246.2814\n",
      "TP: 1973.0 TN: 4865.0 FP: 260.0 FN: 398.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3157 Acc: 0.8753 Pre: 0.8172 Rec: 0.7625 F1: 0.7889 Time in epoch: 104.1370\n",
      "TP: 3057.0 TN: 8422.0 FP: 684.0 FN: 952.0\n",
      "val Loss: 0.2254 Acc: 0.9174 Pre: 0.8608 Rec: 0.8542 F1: 0.8575 Time in epoch: 182.6796\n",
      "TP: 2356.0 TN: 6340.0 FP: 381.0 FN: 402.0\n",
      "test Loss: 0.2306 Acc: 0.9116 Pre: 0.8878 Rec: 0.8245 F1: 0.8550 Time in epoch: 245.8657\n",
      "TP: 1955.0 TN: 4878.0 FP: 247.0 FN: 416.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3161 Acc: 0.8767 Pre: 0.8183 Rec: 0.7670 F1: 0.7918 Time in epoch: 104.1924\n",
      "TP: 3075.0 TN: 8423.0 FP: 683.0 FN: 934.0\n",
      "val Loss: 0.2303 Acc: 0.9135 Pre: 0.8498 Rec: 0.8535 F1: 0.8517 Time in epoch: 183.2073\n",
      "TP: 2354.0 TN: 6305.0 FP: 416.0 FN: 404.0\n",
      "test Loss: 0.2339 Acc: 0.9097 Pre: 0.8815 Rec: 0.8254 F1: 0.8525 Time in epoch: 246.4917\n",
      "TP: 1957.0 TN: 4862.0 FP: 263.0 FN: 414.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3148 Acc: 0.8759 Pre: 0.8186 Rec: 0.7633 F1: 0.7900 Time in epoch: 104.4702\n",
      "TP: 3060.0 TN: 8428.0 FP: 678.0 FN: 949.0\n",
      "val Loss: 0.2243 Acc: 0.9172 Pre: 0.8713 Rec: 0.8394 F1: 0.8550 Time in epoch: 183.7403\n",
      "TP: 2315.0 TN: 6379.0 FP: 342.0 FN: 443.0\n",
      "test Loss: 0.2355 Acc: 0.9093 Pre: 0.8934 Rec: 0.8098 F1: 0.8496 Time in epoch: 246.9403\n",
      "TP: 1920.0 TN: 4896.0 FP: 229.0 FN: 451.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3156 Acc: 0.8760 Pre: 0.8158 Rec: 0.7678 F1: 0.7911 Time in epoch: 104.4019\n",
      "TP: 3078.0 TN: 8411.0 FP: 695.0 FN: 931.0\n",
      "val Loss: 0.2287 Acc: 0.9168 Pre: 0.8427 Rec: 0.8778 F1: 0.8599 Time in epoch: 183.3811\n",
      "TP: 2421.0 TN: 6269.0 FP: 452.0 FN: 337.0\n",
      "test Loss: 0.2288 Acc: 0.9149 Pre: 0.8779 Rec: 0.8490 F1: 0.8632 Time in epoch: 246.4500\n",
      "TP: 2013.0 TN: 4845.0 FP: 280.0 FN: 358.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3147 Acc: 0.8745 Pre: 0.8179 Rec: 0.7583 F1: 0.7870 Time in epoch: 104.4485\n",
      "TP: 3040.0 TN: 8429.0 FP: 677.0 FN: 969.0\n",
      "val Loss: 0.2198 Acc: 0.9199 Pre: 0.8816 Rec: 0.8372 F1: 0.8588 Time in epoch: 183.4475\n",
      "TP: 2309.0 TN: 6411.0 FP: 310.0 FN: 449.0\n",
      "test Loss: 0.2338 Acc: 0.9081 Pre: 0.8967 Rec: 0.8018 F1: 0.8466 Time in epoch: 246.8446\n",
      "TP: 1901.0 TN: 4906.0 FP: 219.0 FN: 470.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3136 Acc: 0.8769 Pre: 0.8180 Rec: 0.7680 F1: 0.7922 Time in epoch: 104.4654\n",
      "TP: 3079.0 TN: 8421.0 FP: 685.0 FN: 930.0\n",
      "val Loss: 0.2314 Acc: 0.9173 Pre: 0.8429 Rec: 0.8796 F1: 0.8609 Time in epoch: 183.3527\n",
      "TP: 2426.0 TN: 6269.0 FP: 452.0 FN: 332.0\n",
      "test Loss: 0.2315 Acc: 0.9138 Pre: 0.8768 Rec: 0.8465 F1: 0.8614 Time in epoch: 246.8335\n",
      "TP: 2007.0 TN: 4843.0 FP: 282.0 FN: 364.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3168 Acc: 0.8740 Pre: 0.8167 Rec: 0.7580 F1: 0.7863 Time in epoch: 104.5524\n",
      "TP: 3039.0 TN: 8424.0 FP: 682.0 FN: 970.0\n",
      "val Loss: 0.2223 Acc: 0.9185 Pre: 0.8666 Rec: 0.8506 F1: 0.8586 Time in epoch: 183.5436\n",
      "TP: 2346.0 TN: 6360.0 FP: 361.0 FN: 412.0\n",
      "test Loss: 0.2309 Acc: 0.9110 Pre: 0.8869 Rec: 0.8237 F1: 0.8541 Time in epoch: 246.9143\n",
      "TP: 1953.0 TN: 4876.0 FP: 249.0 FN: 418.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3161 Acc: 0.8727 Pre: 0.8090 Rec: 0.7640 F1: 0.7859 Time in epoch: 104.4000\n",
      "TP: 3063.0 TN: 8383.0 FP: 723.0 FN: 946.0\n",
      "val Loss: 0.2212 Acc: 0.9189 Pre: 0.8693 Rec: 0.8488 F1: 0.8589 Time in epoch: 183.7781\n",
      "TP: 2341.0 TN: 6369.0 FP: 352.0 FN: 417.0\n",
      "test Loss: 0.2306 Acc: 0.9113 Pre: 0.8899 Rec: 0.8212 F1: 0.8541 Time in epoch: 247.2869\n",
      "TP: 1947.0 TN: 4884.0 FP: 241.0 FN: 424.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.3098 Acc: 0.8750 Pre: 0.8177 Rec: 0.7608 F1: 0.7882 Time in epoch: 104.2794\n",
      "TP: 3050.0 TN: 8426.0 FP: 680.0 FN: 959.0\n",
      "val Loss: 0.2243 Acc: 0.9183 Pre: 0.8528 Rec: 0.8695 F1: 0.8610 Time in epoch: 183.4398\n",
      "TP: 2398.0 TN: 6307.0 FP: 414.0 FN: 360.0\n",
      "test Loss: 0.2275 Acc: 0.9160 Pre: 0.8853 Rec: 0.8435 F1: 0.8639 Time in epoch: 246.4024\n",
      "TP: 2000.0 TN: 4866.0 FP: 259.0 FN: 371.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3141 Acc: 0.8727 Pre: 0.8115 Rec: 0.7600 F1: 0.7849 Time in epoch: 104.3493\n",
      "TP: 3047.0 TN: 8398.0 FP: 708.0 FN: 962.0\n",
      "val Loss: 0.2251 Acc: 0.9182 Pre: 0.8591 Rec: 0.8600 F1: 0.8596 Time in epoch: 183.0823\n",
      "TP: 2372.0 TN: 6332.0 FP: 389.0 FN: 386.0\n",
      "test Loss: 0.2311 Acc: 0.9116 Pre: 0.8864 Rec: 0.8262 F1: 0.8553 Time in epoch: 245.8995\n",
      "TP: 1959.0 TN: 4874.0 FP: 251.0 FN: 412.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3130 Acc: 0.8753 Pre: 0.8182 Rec: 0.7610 F1: 0.7886 Time in epoch: 104.4854\n",
      "TP: 3051.0 TN: 8428.0 FP: 678.0 FN: 958.0\n",
      "val Loss: 0.2351 Acc: 0.9142 Pre: 0.8311 Rec: 0.8851 F1: 0.8572 Time in epoch: 183.3320\n",
      "TP: 2441.0 TN: 6225.0 FP: 496.0 FN: 317.0\n",
      "test Loss: 0.2309 Acc: 0.9144 Pre: 0.8725 Rec: 0.8541 F1: 0.8632 Time in epoch: 246.3575\n",
      "TP: 2025.0 TN: 4829.0 FP: 296.0 FN: 346.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3194 Acc: 0.8691 Pre: 0.8037 Rec: 0.7565 F1: 0.7794 Time in epoch: 104.1547\n",
      "TP: 3033.0 TN: 8365.0 FP: 741.0 FN: 976.0\n",
      "val Loss: 0.2197 Acc: 0.9182 Pre: 0.8850 Rec: 0.8263 F1: 0.8547 Time in epoch: 182.8159\n",
      "TP: 2279.0 TN: 6425.0 FP: 296.0 FN: 479.0\n",
      "test Loss: 0.2351 Acc: 0.9072 Pre: 0.9001 Rec: 0.7946 F1: 0.8441 Time in epoch: 245.6677\n",
      "TP: 1884.0 TN: 4916.0 FP: 209.0 FN: 487.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3116 Acc: 0.8771 Pre: 0.8173 Rec: 0.7700 F1: 0.7930 Time in epoch: 103.9824\n",
      "TP: 3087.0 TN: 8416.0 FP: 690.0 FN: 922.0\n",
      "val Loss: 0.2332 Acc: 0.9175 Pre: 0.8452 Rec: 0.8771 F1: 0.8609 Time in epoch: 182.5882\n",
      "TP: 2419.0 TN: 6278.0 FP: 443.0 FN: 339.0\n",
      "test Loss: 0.2324 Acc: 0.9150 Pre: 0.8799 Rec: 0.8469 F1: 0.8631 Time in epoch: 245.4208\n",
      "TP: 2008.0 TN: 4851.0 FP: 274.0 FN: 363.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.3204 Acc: 0.8721 Pre: 0.8127 Rec: 0.7556 F1: 0.7831 Time in epoch: 104.0362\n",
      "TP: 3029.0 TN: 8408.0 FP: 698.0 FN: 980.0\n",
      "val Loss: 0.2183 Acc: 0.9206 Pre: 0.8709 Rec: 0.8535 F1: 0.8621 Time in epoch: 182.2131\n",
      "TP: 2354.0 TN: 6372.0 FP: 349.0 FN: 404.0\n",
      "test Loss: 0.2290 Acc: 0.9134 Pre: 0.8921 Rec: 0.8262 F1: 0.8579 Time in epoch: 244.5807\n",
      "TP: 1959.0 TN: 4888.0 FP: 237.0 FN: 412.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.3139 Acc: 0.8753 Pre: 0.8179 Rec: 0.7618 F1: 0.7888 Time in epoch: 104.1041\n",
      "TP: 3054.0 TN: 8426.0 FP: 680.0 FN: 955.0\n",
      "val Loss: 0.2307 Acc: 0.9174 Pre: 0.8473 Rec: 0.8735 F1: 0.8602 Time in epoch: 182.2626\n",
      "TP: 2409.0 TN: 6287.0 FP: 434.0 FN: 349.0\n",
      "test Loss: 0.2296 Acc: 0.9144 Pre: 0.8810 Rec: 0.8431 F1: 0.8616 Time in epoch: 244.8076\n",
      "TP: 1999.0 TN: 4855.0 FP: 270.0 FN: 372.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3198 Acc: 0.8740 Pre: 0.8152 Rec: 0.7603 F1: 0.7868 Time in epoch: 104.2294\n",
      "TP: 3048.0 TN: 8415.0 FP: 691.0 FN: 961.0\n",
      "val Loss: 0.2229 Acc: 0.9157 Pre: 0.8858 Rec: 0.8154 F1: 0.8492 Time in epoch: 182.6571\n",
      "TP: 2249.0 TN: 6431.0 FP: 290.0 FN: 509.0\n",
      "test Loss: 0.2396 Acc: 0.9059 Pre: 0.9036 Rec: 0.7866 F1: 0.8410 Time in epoch: 245.3137\n",
      "TP: 1865.0 TN: 4926.0 FP: 199.0 FN: 506.0\n",
      "\n",
      "Training complete in 103m 8s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_last_layer_20/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    # model_ts = models.resnet50(pretrained=True)\n",
    "    # num_ftrs = model_ts.fc.in_features\n",
    "    # model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts = get_frozen_model()\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
