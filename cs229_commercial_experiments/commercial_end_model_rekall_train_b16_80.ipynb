{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = 0.8     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/rekall_train.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, load_percentage = 1):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = sorted(list(set(videos))) # set of all videos\n",
    "        num_videos = int(len(videos) * load_percentage) # number of videos to use\n",
    "        videos = videos[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append('commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file, data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = 4,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 50981, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.2639 Acc: 0.9003 Pre: 0.8395 Rec: 0.8184 F1: 0.8288 Time in epoch: 1210.9920\n",
      "TP: 12303.0 TN: 33596.0 FP: 2352.0 FN: 2730.0\n",
      "val Loss: 0.1305 Acc: 0.9523 Pre: 0.8890 Rec: 0.9554 F1: 0.9210 Time in epoch: 1282.8914\n",
      "TP: 2635.0 TN: 6392.0 FP: 329.0 FN: 123.0\n",
      "test Loss: 0.1459 Acc: 0.9512 Pre: 0.9031 Rec: 0.9473 F1: 0.9247 Time in epoch: 1340.3333\n",
      "TP: 2246.0 TN: 4884.0 FP: 241.0 FN: 125.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2234 Acc: 0.9217 Pre: 0.8738 Rec: 0.8583 F1: 0.8660 Time in epoch: 1211.4747\n",
      "TP: 12903.0 TN: 34085.0 FP: 1863.0 FN: 2130.0\n",
      "val Loss: 0.1342 Acc: 0.9507 Pre: 0.8882 Rec: 0.9503 F1: 0.9182 Time in epoch: 1283.4544\n",
      "TP: 2621.0 TN: 6391.0 FP: 330.0 FN: 137.0\n",
      "test Loss: 0.1346 Acc: 0.9572 Pre: 0.9332 Rec: 0.9313 F1: 0.9322 Time in epoch: 1340.8980\n",
      "TP: 2208.0 TN: 4967.0 FP: 158.0 FN: 163.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2117 Acc: 0.9273 Pre: 0.8848 Rec: 0.8662 F1: 0.8754 Time in epoch: 1210.0729\n",
      "TP: 13022.0 TN: 34252.0 FP: 1696.0 FN: 2011.0\n",
      "val Loss: 0.1142 Acc: 0.9635 Pre: 0.9497 Rec: 0.9235 F1: 0.9364 Time in epoch: 1282.0080\n",
      "TP: 2547.0 TN: 6586.0 FP: 135.0 FN: 211.0\n",
      "test Loss: 0.1594 Acc: 0.9488 Pre: 0.9498 Rec: 0.8849 F1: 0.9162 Time in epoch: 1339.5349\n",
      "TP: 2098.0 TN: 5014.0 FP: 111.0 FN: 273.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2036 Acc: 0.9296 Pre: 0.8883 Rec: 0.8709 F1: 0.8795 Time in epoch: 1211.1367\n",
      "TP: 13092.0 TN: 34301.0 FP: 1647.0 FN: 1941.0\n",
      "val Loss: 0.1192 Acc: 0.9632 Pre: 0.9152 Rec: 0.9627 F1: 0.9383 Time in epoch: 1283.1206\n",
      "TP: 2655.0 TN: 6475.0 FP: 246.0 FN: 103.0\n",
      "test Loss: 0.1509 Acc: 0.9525 Pre: 0.9121 Rec: 0.9405 F1: 0.9261 Time in epoch: 1340.5689\n",
      "TP: 2230.0 TN: 4910.0 FP: 215.0 FN: 141.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1929 Acc: 0.9329 Pre: 0.8924 Rec: 0.8782 F1: 0.8852 Time in epoch: 1210.6866\n",
      "TP: 13202.0 TN: 34356.0 FP: 1592.0 FN: 1831.0\n",
      "val Loss: 0.1066 Acc: 0.9673 Pre: 0.9406 Rec: 0.9474 F1: 0.9440 Time in epoch: 1282.6220\n",
      "TP: 2613.0 TN: 6556.0 FP: 165.0 FN: 145.0\n",
      "test Loss: 0.1479 Acc: 0.9538 Pre: 0.9385 Rec: 0.9140 F1: 0.9261 Time in epoch: 1340.1164\n",
      "TP: 2167.0 TN: 4983.0 FP: 142.0 FN: 204.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1883 Acc: 0.9344 Pre: 0.8962 Rec: 0.8796 F1: 0.8878 Time in epoch: 1212.2936\n",
      "TP: 13223.0 TN: 34416.0 FP: 1532.0 FN: 1810.0\n",
      "val Loss: 0.1299 Acc: 0.9546 Pre: 0.8978 Rec: 0.9525 F1: 0.9243 Time in epoch: 1284.2436\n",
      "TP: 2627.0 TN: 6422.0 FP: 299.0 FN: 131.0\n",
      "test Loss: 0.1619 Acc: 0.9448 Pre: 0.9045 Rec: 0.9228 F1: 0.9136 Time in epoch: 1341.6949\n",
      "TP: 2188.0 TN: 4894.0 FP: 231.0 FN: 183.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1695 Acc: 0.9397 Pre: 0.9063 Rec: 0.8872 F1: 0.8967 Time in epoch: 1211.2055\n",
      "TP: 13338.0 TN: 34569.0 FP: 1379.0 FN: 1695.0\n",
      "val Loss: 0.1043 Acc: 0.9675 Pre: 0.9329 Rec: 0.9572 F1: 0.9449 Time in epoch: 1283.1863\n",
      "TP: 2640.0 TN: 6531.0 FP: 190.0 FN: 118.0\n",
      "test Loss: 0.1414 Acc: 0.9514 Pre: 0.9173 Rec: 0.9304 F1: 0.9238 Time in epoch: 1340.6832\n",
      "TP: 2206.0 TN: 4926.0 FP: 199.0 FN: 165.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1646 Acc: 0.9422 Pre: 0.9112 Rec: 0.8908 F1: 0.9009 Time in epoch: 1212.6029\n",
      "TP: 13392.0 TN: 34643.0 FP: 1305.0 FN: 1641.0\n",
      "val Loss: 0.1142 Acc: 0.9612 Pre: 0.9118 Rec: 0.9594 F1: 0.9350 Time in epoch: 1284.5302\n",
      "TP: 2646.0 TN: 6465.0 FP: 256.0 FN: 112.0\n",
      "test Loss: 0.1481 Acc: 0.9498 Pre: 0.9080 Rec: 0.9363 F1: 0.9219 Time in epoch: 1341.9388\n",
      "TP: 2220.0 TN: 4900.0 FP: 225.0 FN: 151.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1623 Acc: 0.9431 Pre: 0.9110 Rec: 0.8944 F1: 0.9026 Time in epoch: 1211.4704\n",
      "TP: 13446.0 TN: 34634.0 FP: 1314.0 FN: 1587.0\n",
      "val Loss: 0.1054 Acc: 0.9663 Pre: 0.9296 Rec: 0.9569 F1: 0.9430 Time in epoch: 1283.4462\n",
      "TP: 2639.0 TN: 6521.0 FP: 200.0 FN: 119.0\n",
      "test Loss: 0.1433 Acc: 0.9540 Pre: 0.9224 Rec: 0.9329 F1: 0.9277 Time in epoch: 1340.9321\n",
      "TP: 2212.0 TN: 4939.0 FP: 186.0 FN: 159.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1606 Acc: 0.9429 Pre: 0.9115 Rec: 0.8931 F1: 0.9022 Time in epoch: 1210.6332\n",
      "TP: 13426.0 TN: 34644.0 FP: 1304.0 FN: 1607.0\n",
      "val Loss: 0.1280 Acc: 0.9565 Pre: 0.8952 Rec: 0.9634 F1: 0.9280 Time in epoch: 1282.6097\n",
      "TP: 2657.0 TN: 6410.0 FP: 311.0 FN: 101.0\n",
      "test Loss: 0.1563 Acc: 0.9450 Pre: 0.8910 Rec: 0.9414 F1: 0.9155 Time in epoch: 1340.2169\n",
      "TP: 2232.0 TN: 4852.0 FP: 273.0 FN: 139.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1588 Acc: 0.9439 Pre: 0.9127 Rec: 0.8952 F1: 0.9039 Time in epoch: 1210.0816\n",
      "TP: 13458.0 TN: 34661.0 FP: 1287.0 FN: 1575.0\n",
      "val Loss: 0.1069 Acc: 0.9665 Pre: 0.9329 Rec: 0.9532 F1: 0.9430 Time in epoch: 1282.0311\n",
      "TP: 2629.0 TN: 6532.0 FP: 189.0 FN: 129.0\n",
      "test Loss: 0.1435 Acc: 0.9528 Pre: 0.9290 Rec: 0.9211 F1: 0.9250 Time in epoch: 1339.5587\n",
      "TP: 2184.0 TN: 4958.0 FP: 167.0 FN: 187.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1559 Acc: 0.9451 Pre: 0.9156 Rec: 0.8965 F1: 0.9060 Time in epoch: 1210.1982\n",
      "TP: 13477.0 TN: 34706.0 FP: 1242.0 FN: 1556.0\n",
      "val Loss: 0.1199 Acc: 0.9599 Pre: 0.9078 Rec: 0.9598 F1: 0.9330 Time in epoch: 1282.1622\n",
      "TP: 2647.0 TN: 6452.0 FP: 269.0 FN: 111.0\n",
      "test Loss: 0.1499 Acc: 0.9476 Pre: 0.9053 Rec: 0.9317 F1: 0.9183 Time in epoch: 1339.6963\n",
      "TP: 2209.0 TN: 4894.0 FP: 231.0 FN: 162.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1528 Acc: 0.9456 Pre: 0.9154 Rec: 0.8985 F1: 0.9069 Time in epoch: 1210.4347\n",
      "TP: 13507.0 TN: 34700.0 FP: 1248.0 FN: 1526.0\n",
      "val Loss: 0.1104 Acc: 0.9642 Pre: 0.9266 Rec: 0.9525 F1: 0.9394 Time in epoch: 1282.3400\n",
      "TP: 2627.0 TN: 6513.0 FP: 208.0 FN: 131.0\n",
      "test Loss: 0.1483 Acc: 0.9492 Pre: 0.9181 Rec: 0.9216 F1: 0.9198 Time in epoch: 1339.9125\n",
      "TP: 2185.0 TN: 4930.0 FP: 195.0 FN: 186.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1521 Acc: 0.9463 Pre: 0.9185 Rec: 0.8977 F1: 0.9080 Time in epoch: 1211.5537\n",
      "TP: 13495.0 TN: 34750.0 FP: 1198.0 FN: 1538.0\n",
      "val Loss: 0.1169 Acc: 0.9605 Pre: 0.9108 Rec: 0.9583 F1: 0.9339 Time in epoch: 1283.5110\n",
      "TP: 2643.0 TN: 6462.0 FP: 259.0 FN: 115.0\n",
      "test Loss: 0.1510 Acc: 0.9462 Pre: 0.8990 Rec: 0.9350 F1: 0.9167 Time in epoch: 1340.8993\n",
      "TP: 2217.0 TN: 4876.0 FP: 249.0 FN: 154.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 0.9471 Pre: 0.9181 Rec: 0.9010 F1: 0.9095 Time in epoch: 1211.0736\n",
      "TP: 13545.0 TN: 34740.0 FP: 1208.0 FN: 1488.0\n",
      "val Loss: 0.1159 Acc: 0.9606 Pre: 0.9139 Rec: 0.9547 F1: 0.9339 Time in epoch: 1283.0594\n",
      "TP: 2633.0 TN: 6473.0 FP: 248.0 FN: 125.0\n",
      "test Loss: 0.1496 Acc: 0.9488 Pre: 0.9134 Rec: 0.9258 F1: 0.9196 Time in epoch: 1340.5170\n",
      "TP: 2195.0 TN: 4917.0 FP: 208.0 FN: 176.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1537 Acc: 0.9453 Pre: 0.9142 Rec: 0.8990 F1: 0.9065 Time in epoch: 1211.0192\n",
      "TP: 13514.0 TN: 34680.0 FP: 1268.0 FN: 1519.0\n",
      "val Loss: 0.1116 Acc: 0.9632 Pre: 0.9195 Rec: 0.9572 F1: 0.9380 Time in epoch: 1283.0115\n",
      "TP: 2640.0 TN: 6490.0 FP: 231.0 FN: 118.0\n",
      "test Loss: 0.1484 Acc: 0.9493 Pre: 0.9132 Rec: 0.9279 F1: 0.9205 Time in epoch: 1340.4649\n",
      "TP: 2200.0 TN: 4916.0 FP: 209.0 FN: 171.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1503 Acc: 0.9465 Pre: 0.9174 Rec: 0.8996 F1: 0.9084 Time in epoch: 1211.7504\n",
      "TP: 13524.0 TN: 34730.0 FP: 1218.0 FN: 1509.0\n",
      "val Loss: 0.1116 Acc: 0.9631 Pre: 0.9222 Rec: 0.9536 F1: 0.9376 Time in epoch: 1283.7330\n",
      "TP: 2630.0 TN: 6499.0 FP: 222.0 FN: 128.0\n",
      "test Loss: 0.1465 Acc: 0.9514 Pre: 0.9204 Rec: 0.9266 F1: 0.9235 Time in epoch: 1341.2450\n",
      "TP: 2197.0 TN: 4935.0 FP: 190.0 FN: 174.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1518 Acc: 0.9455 Pre: 0.9165 Rec: 0.8970 F1: 0.9067 Time in epoch: 1213.2185\n",
      "TP: 13485.0 TN: 34720.0 FP: 1228.0 FN: 1548.0\n",
      "val Loss: 0.1095 Acc: 0.9637 Pre: 0.9223 Rec: 0.9558 F1: 0.9387 Time in epoch: 1285.2810\n",
      "TP: 2636.0 TN: 6499.0 FP: 222.0 FN: 122.0\n",
      "test Loss: 0.1482 Acc: 0.9498 Pre: 0.9137 Rec: 0.9291 F1: 0.9214 Time in epoch: 1342.7316\n",
      "TP: 2203.0 TN: 4917.0 FP: 208.0 FN: 168.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1517 Acc: 0.9470 Pre: 0.9188 Rec: 0.8997 F1: 0.9091 Time in epoch: 1212.3233\n",
      "TP: 13525.0 TN: 34752.0 FP: 1196.0 FN: 1508.0\n",
      "val Loss: 0.1140 Acc: 0.9615 Pre: 0.9119 Rec: 0.9605 F1: 0.9355 Time in epoch: 1284.3468\n",
      "TP: 2649.0 TN: 6465.0 FP: 256.0 FN: 109.0\n",
      "test Loss: 0.1485 Acc: 0.9489 Pre: 0.9084 Rec: 0.9325 F1: 0.9203 Time in epoch: 1341.8497\n",
      "TP: 2211.0 TN: 4902.0 FP: 223.0 FN: 160.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9475 Pre: 0.9200 Rec: 0.9003 F1: 0.9100 Time in epoch: 1216.4762\n",
      "TP: 13534.0 TN: 34771.0 FP: 1177.0 FN: 1499.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1065 Acc: 0.9652 Pre: 0.9302 Rec: 0.9518 F1: 0.9409 Time in epoch: 1288.4147\n",
      "TP: 2625.0 TN: 6524.0 FP: 197.0 FN: 133.0\n",
      "test Loss: 0.1446 Acc: 0.9528 Pre: 0.9315 Rec: 0.9182 F1: 0.9248 Time in epoch: 1345.9466\n",
      "TP: 2177.0 TN: 4965.0 FP: 160.0 FN: 194.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9469 Pre: 0.9176 Rec: 0.9007 F1: 0.9091 Time in epoch: 1215.3344\n",
      "TP: 13540.0 TN: 34732.0 FP: 1216.0 FN: 1493.0\n",
      "val Loss: 0.1171 Acc: 0.9605 Pre: 0.9110 Rec: 0.9579 F1: 0.9339 Time in epoch: 1287.3714\n",
      "TP: 2642.0 TN: 6463.0 FP: 258.0 FN: 116.0\n",
      "test Loss: 0.1499 Acc: 0.9486 Pre: 0.9080 Rec: 0.9321 F1: 0.9199 Time in epoch: 1344.8263\n",
      "TP: 2210.0 TN: 4901.0 FP: 224.0 FN: 161.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1525 Acc: 0.9466 Pre: 0.9169 Rec: 0.9004 F1: 0.9086 Time in epoch: 1211.8709\n",
      "TP: 13536.0 TN: 34721.0 FP: 1227.0 FN: 1497.0\n",
      "val Loss: 0.1146 Acc: 0.9610 Pre: 0.9146 Rec: 0.9550 F1: 0.9344 Time in epoch: 1283.8832\n",
      "TP: 2634.0 TN: 6475.0 FP: 246.0 FN: 124.0\n",
      "test Loss: 0.1478 Acc: 0.9505 Pre: 0.9184 Rec: 0.9258 F1: 0.9221 Time in epoch: 1341.3658\n",
      "TP: 2195.0 TN: 4930.0 FP: 195.0 FN: 176.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9464 Pre: 0.9161 Rec: 0.9008 F1: 0.9084 Time in epoch: 1210.0848\n",
      "TP: 13542.0 TN: 34707.0 FP: 1241.0 FN: 1491.0\n",
      "val Loss: 0.1194 Acc: 0.9590 Pre: 0.9058 Rec: 0.9587 F1: 0.9315 Time in epoch: 1282.0507\n",
      "TP: 2644.0 TN: 6446.0 FP: 275.0 FN: 114.0\n",
      "test Loss: 0.1515 Acc: 0.9466 Pre: 0.9008 Rec: 0.9342 F1: 0.9172 Time in epoch: 1339.4155\n",
      "TP: 2215.0 TN: 4881.0 FP: 244.0 FN: 156.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "test Loss: 0.1448 Acc: 0.9513 Pre: 0.9228 Rec: 0.9232 F1: 0.9230 Time in epoch: 1340.9850\n",
      "TP: 2189.0 TN: 4942.0 FP: 183.0 FN: 182.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1502 Acc: 0.9467 Pre: 0.9187 Rec: 0.8988 F1: 0.9086 Time in epoch: 1210.5440\n",
      "TP: 13511.0 TN: 34753.0 FP: 1195.0 FN: 1522.0\n",
      "val Loss: 0.1129 Acc: 0.9614 Pre: 0.9176 Rec: 0.9529 F1: 0.9349 Time in epoch: 1282.5914\n",
      "TP: 2628.0 TN: 6485.0 FP: 236.0 FN: 130.0\n",
      "test Loss: 0.1457 Acc: 0.9521 Pre: 0.9245 Rec: 0.9241 F1: 0.9243 Time in epoch: 1339.9588\n",
      "TP: 2191.0 TN: 4946.0 FP: 179.0 FN: 180.0\n",
      "\n",
      "Training complete in 559m 0s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_80/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
