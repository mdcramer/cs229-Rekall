{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "data_root = '/home/rsundar/cs229/commercials_big/'\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = 5     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/rekall_train.txt'\n",
    "train_file_new_points = 'commercials/data/rekall_big_train_new.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, filename_new_points=None, load_percentage = 1):\n",
    "    # Assumes that there is no overlap in datapoints between filename and filename_new_points!\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    num_total_videos = 0\n",
    "    \n",
    "    with open(data_root + filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = sorted(list(set(videos))) # set of all videos\n",
    "        num_total_videos = len(videos)\n",
    "        num_videos = int(len(videos) * load_percentage) # number of videos to use\n",
    "        videos = videos[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "    \n",
    "    videos = []\n",
    "    if filename_new_points is not None and load_percentage > 1:\n",
    "        print(\"Fetching points from new data file\")\n",
    "        with open(data_root + filename_new_points, 'r') as f:\n",
    "\n",
    "            # find set of unique videos on file\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                videos.append(video)\n",
    "            videos = sorted(list(set(videos))) # set of all videos\n",
    "            num_videos_to_fetch = int(num_total_videos * (load_percentage - 1))\n",
    "            if num_videos_to_fetch > len(videos):\n",
    "                print(\"Trying to fetch a larger data_percentage than is available\")\n",
    "                num_videos_to_fetch = len(videos)\n",
    "            videos = videos[:num_videos_to_fetch] # take first 'num_videos'\n",
    "            f.seek(0) # go back to beginning of file\n",
    "\n",
    "            # read in data only using videos in possibly reduced set from above\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                if video in videos: # load it up only if it's in the list of videos to use\n",
    "                    paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                    labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching points from new data file\n"
     ]
    }
   ],
   "source": [
    "train_paths, Y_train = read_file(train_file, train_file_new_points, load_percentage=data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = 4,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 344594, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2854 Acc: 0.8902 Pre: 0.8050 Rec: 0.7998 F1: 0.8024 Time in epoch: 7974.0338\n",
      "TP: 76832.0 TN: 229919.0 FP: 18612.0 FN: 19231.0\n",
      "val Loss: 0.1059 Acc: 0.9729 Pre: 0.9735 Rec: 0.9322 F1: 0.9524 Time in epoch: 8058.9665\n",
      "TP: 2571.0 TN: 6651.0 FP: 70.0 FN: 187.0\n",
      "test Loss: 0.1473 Acc: 0.9552 Pre: 0.9532 Rec: 0.9026 F1: 0.9272 Time in epoch: 8127.3976\n",
      "TP: 2140.0 TN: 5020.0 FP: 105.0 FN: 231.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2548 Acc: 0.9057 Pre: 0.8303 Rec: 0.8320 F1: 0.8311 Time in epoch: 8001.5599\n",
      "TP: 79921.0 TN: 232191.0 FP: 16340.0 FN: 16142.0\n",
      "val Loss: 0.0956 Acc: 0.9733 Pre: 0.9603 Rec: 0.9474 F1: 0.9538 Time in epoch: 8086.2788\n",
      "TP: 2613.0 TN: 6613.0 FP: 108.0 FN: 145.0\n",
      "test Loss: 0.1367 Acc: 0.9570 Pre: 0.9317 Rec: 0.9325 F1: 0.9321 Time in epoch: 8153.3366\n",
      "TP: 2211.0 TN: 4963.0 FP: 162.0 FN: 160.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2452 Acc: 0.9100 Pre: 0.8380 Rec: 0.8396 F1: 0.8388 Time in epoch: 7986.4419\n",
      "TP: 80650.0 TN: 232939.0 FP: 15592.0 FN: 15413.0\n",
      "val Loss: 0.0925 Acc: 0.9772 Pre: 0.9803 Rec: 0.9405 F1: 0.9600 Time in epoch: 8071.3469\n",
      "TP: 2594.0 TN: 6669.0 FP: 52.0 FN: 164.0\n",
      "test Loss: 0.1380 Acc: 0.9600 Pre: 0.9548 Rec: 0.9169 F1: 0.9355 Time in epoch: 8137.8110\n",
      "TP: 2174.0 TN: 5022.0 FP: 103.0 FN: 197.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2393 Acc: 0.9127 Pre: 0.8424 Rec: 0.8448 F1: 0.8436 Time in epoch: 7978.8076\n",
      "TP: 81150.0 TN: 233348.0 FP: 15183.0 FN: 14913.0\n",
      "val Loss: 0.0996 Acc: 0.9735 Pre: 0.9721 Rec: 0.9358 F1: 0.9536 Time in epoch: 8062.7992\n",
      "TP: 2581.0 TN: 6647.0 FP: 74.0 FN: 177.0\n",
      "test Loss: 0.1421 Acc: 0.9566 Pre: 0.9503 Rec: 0.9106 F1: 0.9300 Time in epoch: 8129.7313\n",
      "TP: 2159.0 TN: 5012.0 FP: 113.0 FN: 212.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2350 Acc: 0.9142 Pre: 0.8460 Rec: 0.8462 F1: 0.8461 Time in epoch: 7970.3174\n",
      "TP: 81284.0 TN: 233729.0 FP: 14802.0 FN: 14779.0\n",
      "val Loss: 0.0944 Acc: 0.9755 Pre: 0.9699 Rec: 0.9453 F1: 0.9574 Time in epoch: 8055.9766\n",
      "TP: 2607.0 TN: 6640.0 FP: 81.0 FN: 151.0\n",
      "test Loss: 0.1407 Acc: 0.9566 Pre: 0.9398 Rec: 0.9220 F1: 0.9308 Time in epoch: 8123.7620\n",
      "TP: 2186.0 TN: 4985.0 FP: 140.0 FN: 185.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2313 Acc: 0.9152 Pre: 0.8472 Rec: 0.8490 F1: 0.8481 Time in epoch: 8025.9048\n",
      "TP: 81556.0 TN: 233822.0 FP: 14709.0 FN: 14507.0\n",
      "val Loss: 0.1044 Acc: 0.9728 Pre: 0.9735 Rec: 0.9318 F1: 0.9522 Time in epoch: 8110.5544\n",
      "TP: 2570.0 TN: 6651.0 FP: 70.0 FN: 188.0\n",
      "test Loss: 0.1457 Acc: 0.9566 Pre: 0.9563 Rec: 0.9043 F1: 0.9295 Time in epoch: 8178.3622\n",
      "TP: 2144.0 TN: 5027.0 FP: 98.0 FN: 227.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2168 Acc: 0.9212 Pre: 0.8575 Rec: 0.8602 F1: 0.8588 Time in epoch: 7998.0652\n",
      "TP: 82637.0 TN: 234793.0 FP: 13738.0 FN: 13426.0\n",
      "val Loss: 0.0897 Acc: 0.9773 Pre: 0.9729 Rec: 0.9485 F1: 0.9605 Time in epoch: 8083.0877\n",
      "TP: 2616.0 TN: 6648.0 FP: 73.0 FN: 142.0\n",
      "test Loss: 0.1305 Acc: 0.9609 Pre: 0.9490 Rec: 0.9262 F1: 0.9375 Time in epoch: 8150.6077\n",
      "TP: 2196.0 TN: 5007.0 FP: 118.0 FN: 175.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2121 Acc: 0.9229 Pre: 0.8615 Rec: 0.8622 F1: 0.8618 Time in epoch: 8002.2090\n",
      "TP: 82828.0 TN: 235212.0 FP: 13319.0 FN: 13235.0\n",
      "val Loss: 0.0879 Acc: 0.9766 Pre: 0.9714 Rec: 0.9474 F1: 0.9593 Time in epoch: 8087.5022\n",
      "TP: 2613.0 TN: 6644.0 FP: 77.0 FN: 145.0\n",
      "test Loss: 0.1312 Acc: 0.9609 Pre: 0.9494 Rec: 0.9258 F1: 0.9374 Time in epoch: 8155.1349\n",
      "TP: 2195.0 TN: 5008.0 FP: 117.0 FN: 176.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2105 Acc: 0.9234 Pre: 0.8616 Rec: 0.8641 F1: 0.8629 Time in epoch: 7994.5988\n",
      "TP: 83010.0 TN: 235201.0 FP: 13330.0 FN: 13053.0\n",
      "val Loss: 0.0887 Acc: 0.9771 Pre: 0.9739 Rec: 0.9467 F1: 0.9601 Time in epoch: 8079.0815\n",
      "TP: 2611.0 TN: 6651.0 FP: 70.0 FN: 147.0\n",
      "test Loss: 0.1326 Acc: 0.9606 Pre: 0.9501 Rec: 0.9241 F1: 0.9369 Time in epoch: 8144.8440\n",
      "TP: 2191.0 TN: 5010.0 FP: 115.0 FN: 180.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.2099 Acc: 0.9233 Pre: 0.8620 Rec: 0.8630 F1: 0.8625 Time in epoch: 8030.6800\n",
      "TP: 82907.0 TN: 235255.0 FP: 13276.0 FN: 13156.0\n",
      "val Loss: 0.0859 Acc: 0.9784 Pre: 0.9695 Rec: 0.9558 F1: 0.9626 Time in epoch: 8115.5356\n",
      "TP: 2636.0 TN: 6638.0 FP: 83.0 FN: 122.0\n",
      "test Loss: 0.1298 Acc: 0.9605 Pre: 0.9409 Rec: 0.9338 F1: 0.9373 Time in epoch: 8182.5335\n",
      "TP: 2214.0 TN: 4986.0 FP: 139.0 FN: 157.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.2086 Acc: 0.9245 Pre: 0.8646 Rec: 0.8645 F1: 0.8646 Time in epoch: 7989.3425\n",
      "TP: 83051.0 TN: 235520.0 FP: 13011.0 FN: 13012.0\n",
      "val Loss: 0.0922 Acc: 0.9772 Pre: 0.9739 Rec: 0.9471 F1: 0.9603 Time in epoch: 8074.3309\n",
      "TP: 2612.0 TN: 6651.0 FP: 70.0 FN: 146.0\n",
      "test Loss: 0.1331 Acc: 0.9612 Pre: 0.9538 Rec: 0.9220 F1: 0.9376 Time in epoch: 8141.8367\n",
      "TP: 2186.0 TN: 5019.0 FP: 106.0 FN: 185.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.2062 Acc: 0.9252 Pre: 0.8658 Rec: 0.8658 F1: 0.8658 Time in epoch: 8005.5461\n",
      "TP: 83168.0 TN: 235638.0 FP: 12893.0 FN: 12895.0\n",
      "val Loss: 0.0874 Acc: 0.9769 Pre: 0.9669 Rec: 0.9532 F1: 0.9600 Time in epoch: 8091.0573\n",
      "TP: 2629.0 TN: 6631.0 FP: 90.0 FN: 129.0\n",
      "test Loss: 0.1285 Acc: 0.9624 Pre: 0.9516 Rec: 0.9283 F1: 0.9398 Time in epoch: 8157.5577\n",
      "TP: 2201.0 TN: 5013.0 FP: 112.0 FN: 170.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.2058 Acc: 0.9248 Pre: 0.8654 Rec: 0.8647 F1: 0.8650 Time in epoch: 7990.7326\n",
      "TP: 83065.0 TN: 235612.0 FP: 12919.0 FN: 12998.0\n",
      "val Loss: 0.0917 Acc: 0.9775 Pre: 0.9704 Rec: 0.9518 F1: 0.9610 Time in epoch: 8075.8818\n",
      "TP: 2625.0 TN: 6641.0 FP: 80.0 FN: 133.0\n",
      "test Loss: 0.1340 Acc: 0.9602 Pre: 0.9458 Rec: 0.9275 F1: 0.9365 Time in epoch: 8143.2531\n",
      "TP: 2199.0 TN: 4999.0 FP: 126.0 FN: 172.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2043 Acc: 0.9254 Pre: 0.8667 Rec: 0.8655 F1: 0.8661 Time in epoch: 8020.1144\n",
      "TP: 83140.0 TN: 235742.0 FP: 12789.0 FN: 12923.0\n",
      "val Loss: 0.0885 Acc: 0.9773 Pre: 0.9694 Rec: 0.9521 F1: 0.9607 Time in epoch: 8106.4653\n",
      "TP: 2626.0 TN: 6638.0 FP: 83.0 FN: 132.0\n",
      "test Loss: 0.1311 Acc: 0.9604 Pre: 0.9470 Rec: 0.9266 F1: 0.9367 Time in epoch: 8174.7845\n",
      "TP: 2197.0 TN: 5002.0 FP: 123.0 FN: 174.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2028 Acc: 0.9263 Pre: 0.8676 Rec: 0.8682 F1: 0.8679 Time in epoch: 7994.0609\n",
      "TP: 83405.0 TN: 235798.0 FP: 12733.0 FN: 12658.0\n",
      "val Loss: 0.0878 Acc: 0.9766 Pre: 0.9763 Rec: 0.9423 F1: 0.9590 Time in epoch: 8079.5530\n",
      "TP: 2599.0 TN: 6658.0 FP: 63.0 FN: 159.0\n",
      "test Loss: 0.1327 Acc: 0.9614 Pre: 0.9574 Rec: 0.9190 F1: 0.9378 Time in epoch: 8147.3042\n",
      "TP: 2179.0 TN: 5028.0 FP: 97.0 FN: 192.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2030 Acc: 0.9261 Pre: 0.8677 Rec: 0.8669 F1: 0.8673 Time in epoch: 7992.9597\n",
      "TP: 83280.0 TN: 235834.0 FP: 12697.0 FN: 12783.0\n",
      "val Loss: 0.0881 Acc: 0.9769 Pre: 0.9686 Rec: 0.9514 F1: 0.9599 Time in epoch: 8078.0825\n",
      "TP: 2624.0 TN: 6636.0 FP: 85.0 FN: 134.0\n",
      "test Loss: 0.1307 Acc: 0.9605 Pre: 0.9470 Rec: 0.9270 F1: 0.9369 Time in epoch: 8145.6058\n",
      "TP: 2198.0 TN: 5002.0 FP: 123.0 FN: 173.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2025 Acc: 0.9261 Pre: 0.8675 Rec: 0.8675 F1: 0.8675 Time in epoch: 7987.6649\n",
      "TP: 83334.0 TN: 235804.0 FP: 12727.0 FN: 12729.0\n",
      "val Loss: 0.0900 Acc: 0.9766 Pre: 0.9689 Rec: 0.9500 F1: 0.9594 Time in epoch: 8072.9116\n",
      "TP: 2620.0 TN: 6637.0 FP: 84.0 FN: 138.0\n",
      "test Loss: 0.1306 Acc: 0.9609 Pre: 0.9459 Rec: 0.9296 F1: 0.9377 Time in epoch: 8140.2724\n",
      "TP: 2204.0 TN: 4999.0 FP: 126.0 FN: 167.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2025 Acc: 0.9262 Pre: 0.8677 Rec: 0.8675 F1: 0.8676 Time in epoch: 8015.4905\n",
      "TP: 83337.0 TN: 235826.0 FP: 12705.0 FN: 12726.0\n",
      "val Loss: 0.0889 Acc: 0.9770 Pre: 0.9718 Rec: 0.9485 F1: 0.9600 Time in epoch: 8101.3256\n",
      "TP: 2616.0 TN: 6645.0 FP: 76.0 FN: 142.0\n",
      "test Loss: 0.1314 Acc: 0.9612 Pre: 0.9483 Rec: 0.9279 F1: 0.9380 Time in epoch: 8169.0838\n",
      "TP: 2200.0 TN: 5005.0 FP: 120.0 FN: 171.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "val Loss: 0.0905 Acc: 0.9759 Pre: 0.9710 Rec: 0.9456 F1: 0.9581 Time in epoch: 8080.7780\n",
      "TP: 2608.0 TN: 6643.0 FP: 78.0 FN: 150.0\n",
      "test Loss: 0.1328 Acc: 0.9606 Pre: 0.9517 Rec: 0.9224 F1: 0.9368 Time in epoch: 8149.1997\n",
      "TP: 2187.0 TN: 5014.0 FP: 111.0 FN: 184.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2017 Acc: 0.9270 Pre: 0.8694 Rec: 0.8687 F1: 0.8690 Time in epoch: 7995.9209\n",
      "TP: 83448.0 TN: 235995.0 FP: 12536.0 FN: 12615.0\n",
      "val Loss: 0.0939 Acc: 0.9761 Pre: 0.9634 Rec: 0.9540 F1: 0.9586 Time in epoch: 8081.9828\n",
      "TP: 2631.0 TN: 6621.0 FP: 100.0 FN: 127.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1338 Acc: 0.9605 Pre: 0.9421 Rec: 0.9325 F1: 0.9373 Time in epoch: 8150.1175\n",
      "TP: 2211.0 TN: 4989.0 FP: 136.0 FN: 160.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9268 Pre: 0.8684 Rec: 0.8692 F1: 0.8688 Time in epoch: 7983.3207\n",
      "TP: 83495.0 TN: 235879.0 FP: 12652.0 FN: 12568.0\n",
      "val Loss: 0.0875 Acc: 0.9781 Pre: 0.9701 Rec: 0.9540 F1: 0.9620 Time in epoch: 8068.9142\n",
      "TP: 2631.0 TN: 6640.0 FP: 81.0 FN: 127.0\n",
      "test Loss: 0.1302 Acc: 0.9609 Pre: 0.9444 Rec: 0.9313 F1: 0.9378 Time in epoch: 8136.7217\n",
      "TP: 2208.0 TN: 4995.0 FP: 130.0 FN: 163.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2020 Acc: 0.9261 Pre: 0.8667 Rec: 0.8685 F1: 0.8676 Time in epoch: 8022.6894\n",
      "TP: 83427.0 TN: 235697.0 FP: 12834.0 FN: 12636.0\n",
      "val Loss: 0.0903 Acc: 0.9761 Pre: 0.9654 Rec: 0.9518 F1: 0.9586 Time in epoch: 8108.1309\n",
      "TP: 2625.0 TN: 6627.0 FP: 94.0 FN: 133.0\n",
      "test Loss: 0.1309 Acc: 0.9618 Pre: 0.9449 Rec: 0.9338 F1: 0.9393 Time in epoch: 8175.7703\n",
      "TP: 2214.0 TN: 4996.0 FP: 129.0 FN: 157.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2012 Acc: 0.9267 Pre: 0.8685 Rec: 0.8687 F1: 0.8686 Time in epoch: 7992.9903\n",
      "TP: 83447.0 TN: 235899.0 FP: 12632.0 FN: 12616.0\n",
      "val Loss: 0.0876 Acc: 0.9763 Pre: 0.9710 Rec: 0.9467 F1: 0.9587 Time in epoch: 8078.9424\n",
      "TP: 2611.0 TN: 6643.0 FP: 78.0 FN: 147.0\n",
      "test Loss: 0.1326 Acc: 0.9606 Pre: 0.9490 Rec: 0.9253 F1: 0.9370 Time in epoch: 8147.0943\n",
      "TP: 2194.0 TN: 5007.0 FP: 118.0 FN: 177.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2014 Acc: 0.9264 Pre: 0.8679 Rec: 0.8682 F1: 0.8681 Time in epoch: 7998.7113\n",
      "TP: 83406.0 TN: 235841.0 FP: 12690.0 FN: 12657.0\n",
      "val Loss: 0.0868 Acc: 0.9766 Pre: 0.9665 Rec: 0.9525 F1: 0.9595 Time in epoch: 8084.5120\n",
      "TP: 2627.0 TN: 6630.0 FP: 91.0 FN: 131.0\n",
      "test Loss: 0.1290 Acc: 0.9608 Pre: 0.9440 Rec: 0.9313 F1: 0.9376 Time in epoch: 8152.7803\n",
      "TP: 2208.0 TN: 4994.0 FP: 131.0 FN: 163.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9262 Pre: 0.8671 Rec: 0.8682 F1: 0.8676 Time in epoch: 7987.7600\n",
      "TP: 83398.0 TN: 235753.0 FP: 12778.0 FN: 12665.0\n",
      "val Loss: 0.0924 Acc: 0.9749 Pre: 0.9694 Rec: 0.9434 F1: 0.9563 Time in epoch: 8071.6758\n",
      "TP: 2602.0 TN: 6639.0 FP: 82.0 FN: 156.0\n",
      "test Loss: 0.1320 Acc: 0.9604 Pre: 0.9509 Rec: 0.9224 F1: 0.9364 Time in epoch: 8138.7145\n",
      "TP: 2187.0 TN: 5012.0 FP: 113.0 FN: 184.0\n",
      "\n",
      "Training complete in 3396m 8s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_500/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
