{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "data_root = '/home/rsundar/cs229/commercials_big/'\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = 4     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/rekall_train.txt'\n",
    "train_file_new_points = 'commercials/data/rekall_big_train_new.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, filename_new_points=None, load_percentage = 1):\n",
    "    # Assumes that there is no overlap in datapoints between filename and filename_new_points!\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    num_total_videos = 0\n",
    "    \n",
    "    with open(data_root + filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = sorted(list(set(videos))) # set of all videos\n",
    "        num_total_videos = len(videos)\n",
    "        num_videos = int(len(videos) * load_percentage) # number of videos to use\n",
    "        videos = videos[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "    \n",
    "    videos = []\n",
    "    if filename_new_points is not None and load_percentage > 1:\n",
    "        print(\"Fetching points from new data file\")\n",
    "        with open(data_root + filename_new_points, 'r') as f:\n",
    "\n",
    "            # find set of unique videos on file\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                videos.append(video)\n",
    "            videos = sorted(list(set(videos))) # set of all videos\n",
    "            num_videos_to_fetch = int(num_total_videos * (load_percentage - 1))\n",
    "            if num_videos_to_fetch > len(videos):\n",
    "                print(\"Trying to fetch a larger data_percentage than is available\")\n",
    "                num_videos_to_fetch = len(videos)\n",
    "            videos = videos[:num_videos_to_fetch] # take first 'num_videos'\n",
    "            f.seek(0) # go back to beginning of file\n",
    "\n",
    "            # read in data only using videos in possibly reduced set from above\n",
    "            for line in f.readlines():\n",
    "                video, image, label = line.split(' ')\n",
    "                if video in videos: # load it up only if it's in the list of videos to use\n",
    "                    paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                    labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching points from new data file\n"
     ]
    }
   ],
   "source": [
    "train_paths, Y_train = read_file(train_file, train_file_new_points, load_percentage=data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = 4,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 283982, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2667 Acc: 0.9030 Pre: 0.8237 Rec: 0.8218 F1: 0.8228 Time in epoch: 6603.7043\n",
      "TP: 63925.0 TN: 192516.0 FP: 13678.0 FN: 13863.0\n",
      "val Loss: 0.1075 Acc: 0.9682 Pre: 0.9421 Rec: 0.9492 F1: 0.9456 Time in epoch: 6684.4509\n",
      "TP: 2618.0 TN: 6560.0 FP: 161.0 FN: 140.0\n",
      "test Loss: 0.1436 Acc: 0.9541 Pre: 0.9246 Rec: 0.9308 F1: 0.9277 Time in epoch: 6748.4793\n",
      "TP: 2207.0 TN: 4945.0 FP: 180.0 FN: 164.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2385 Acc: 0.9162 Pre: 0.8474 Rec: 0.8467 F1: 0.8470 Time in epoch: 6598.0745\n",
      "TP: 65862.0 TN: 194329.0 FP: 11865.0 FN: 11926.0\n",
      "val Loss: 0.1116 Acc: 0.9667 Pre: 0.9266 Rec: 0.9616 F1: 0.9438 Time in epoch: 6678.7611\n",
      "TP: 2652.0 TN: 6511.0 FP: 210.0 FN: 106.0\n",
      "test Loss: 0.1420 Acc: 0.9530 Pre: 0.9099 Rec: 0.9452 F1: 0.9272 Time in epoch: 6743.5920\n",
      "TP: 2241.0 TN: 4903.0 FP: 222.0 FN: 130.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2293 Acc: 0.9197 Pre: 0.8529 Rec: 0.8543 F1: 0.8536 Time in epoch: 6596.5561\n",
      "TP: 66458.0 TN: 194733.0 FP: 11461.0 FN: 11330.0\n",
      "val Loss: 0.0976 Acc: 0.9704 Pre: 0.9444 Rec: 0.9543 F1: 0.9493 Time in epoch: 6677.4661\n",
      "TP: 2632.0 TN: 6566.0 FP: 155.0 FN: 126.0\n",
      "test Loss: 0.1366 Acc: 0.9590 Pre: 0.9406 Rec: 0.9291 F1: 0.9349 Time in epoch: 6741.4698\n",
      "TP: 2203.0 TN: 4986.0 FP: 139.0 FN: 168.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2227 Acc: 0.9224 Pre: 0.8575 Rec: 0.8595 F1: 0.8585 Time in epoch: 6593.1793\n",
      "TP: 66860.0 TN: 195085.0 FP: 11109.0 FN: 10928.0\n",
      "val Loss: 0.0884 Acc: 0.9761 Pre: 0.9617 Rec: 0.9558 F1: 0.9587 Time in epoch: 6677.4239\n",
      "TP: 2636.0 TN: 6616.0 FP: 105.0 FN: 122.0\n",
      "test Loss: 0.1310 Acc: 0.9613 Pre: 0.9452 Rec: 0.9317 F1: 0.9384 Time in epoch: 6743.6449\n",
      "TP: 2209.0 TN: 4997.0 FP: 128.0 FN: 162.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2175 Acc: 0.9235 Pre: 0.8592 Rec: 0.8621 F1: 0.8606 Time in epoch: 6594.0381\n",
      "TP: 67059.0 TN: 195207.0 FP: 10987.0 FN: 10729.0\n",
      "val Loss: 0.0896 Acc: 0.9767 Pre: 0.9635 Rec: 0.9561 F1: 0.9598 Time in epoch: 6675.0816\n",
      "TP: 2637.0 TN: 6621.0 FP: 100.0 FN: 121.0\n",
      "test Loss: 0.1330 Acc: 0.9569 Pre: 0.9437 Rec: 0.9186 F1: 0.9310 Time in epoch: 6740.5305\n",
      "TP: 2178.0 TN: 4995.0 FP: 130.0 FN: 193.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2143 Acc: 0.9247 Pre: 0.8615 Rec: 0.8642 F1: 0.8629 Time in epoch: 6586.2624\n",
      "TP: 67228.0 TN: 195383.0 FP: 10811.0 FN: 10560.0\n",
      "val Loss: 0.0894 Acc: 0.9759 Pre: 0.9675 Rec: 0.9492 F1: 0.9583 Time in epoch: 6671.0050\n",
      "TP: 2618.0 TN: 6633.0 FP: 88.0 FN: 140.0\n",
      "test Loss: 0.1299 Acc: 0.9596 Pre: 0.9476 Rec: 0.9232 F1: 0.9353 Time in epoch: 6738.3119\n",
      "TP: 2189.0 TN: 5004.0 FP: 121.0 FN: 182.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9291 Pre: 0.8694 Rec: 0.8721 F1: 0.8708 Time in epoch: 6583.8663\n",
      "TP: 67841.0 TN: 196006.0 FP: 10188.0 FN: 9947.0\n",
      "val Loss: 0.0866 Acc: 0.9769 Pre: 0.9672 Rec: 0.9529 F1: 0.9600 Time in epoch: 6670.2250\n",
      "TP: 2628.0 TN: 6632.0 FP: 89.0 FN: 130.0\n",
      "test Loss: 0.1256 Acc: 0.9610 Pre: 0.9498 Rec: 0.9258 F1: 0.9376 Time in epoch: 6737.6426\n",
      "TP: 2195.0 TN: 5009.0 FP: 116.0 FN: 176.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1982 Acc: 0.9303 Pre: 0.8704 Rec: 0.8759 F1: 0.8732 Time in epoch: 6582.7664\n",
      "TP: 68135.0 TN: 196053.0 FP: 10141.0 FN: 9653.0\n",
      "val Loss: 0.0917 Acc: 0.9749 Pre: 0.9536 Rec: 0.9605 F1: 0.9570 Time in epoch: 6667.2042\n",
      "TP: 2649.0 TN: 6592.0 FP: 129.0 FN: 109.0\n",
      "test Loss: 0.1266 Acc: 0.9596 Pre: 0.9367 Rec: 0.9355 F1: 0.9361 Time in epoch: 6734.1958\n",
      "TP: 2218.0 TN: 4975.0 FP: 150.0 FN: 153.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1955 Acc: 0.9314 Pre: 0.8735 Rec: 0.8764 F1: 0.8750 Time in epoch: 6579.3820\n",
      "TP: 68175.0 TN: 196324.0 FP: 9870.0 FN: 9613.0\n",
      "val Loss: 0.0909 Acc: 0.9765 Pre: 0.9662 Rec: 0.9525 F1: 0.9593 Time in epoch: 6664.3381\n",
      "TP: 2627.0 TN: 6629.0 FP: 92.0 FN: 131.0\n",
      "test Loss: 0.1273 Acc: 0.9613 Pre: 0.9498 Rec: 0.9266 F1: 0.9381 Time in epoch: 6732.0744\n",
      "TP: 2197.0 TN: 5009.0 FP: 116.0 FN: 174.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1946 Acc: 0.9316 Pre: 0.8744 Rec: 0.8761 F1: 0.8752 Time in epoch: 6589.5227\n",
      "TP: 68148.0 TN: 196403.0 FP: 9791.0 FN: 9640.0\n",
      "val Loss: 0.0881 Acc: 0.9782 Pre: 0.9670 Rec: 0.9576 F1: 0.9623 Time in epoch: 6674.3246\n",
      "TP: 2641.0 TN: 6631.0 FP: 90.0 FN: 117.0\n",
      "test Loss: 0.1260 Acc: 0.9610 Pre: 0.9459 Rec: 0.9300 F1: 0.9379 Time in epoch: 6740.9559\n",
      "TP: 2205.0 TN: 4999.0 FP: 126.0 FN: 166.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1927 Acc: 0.9323 Pre: 0.8752 Rec: 0.8779 F1: 0.8765 Time in epoch: 6578.2204\n",
      "TP: 68288.0 TN: 196458.0 FP: 9736.0 FN: 9500.0\n",
      "val Loss: 0.0876 Acc: 0.9762 Pre: 0.9658 Rec: 0.9518 F1: 0.9587 Time in epoch: 6663.1713\n",
      "TP: 2625.0 TN: 6628.0 FP: 93.0 FN: 133.0\n",
      "test Loss: 0.1264 Acc: 0.9605 Pre: 0.9489 Rec: 0.9249 F1: 0.9368 Time in epoch: 6730.5109\n",
      "TP: 2193.0 TN: 5007.0 FP: 118.0 FN: 178.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1914 Acc: 0.9322 Pre: 0.8749 Rec: 0.8779 F1: 0.8764 Time in epoch: 6584.5049\n",
      "TP: 68289.0 TN: 196433.0 FP: 9761.0 FN: 9499.0\n",
      "val Loss: 0.0901 Acc: 0.9770 Pre: 0.9625 Rec: 0.9583 F1: 0.9604 Time in epoch: 6669.0873\n",
      "TP: 2643.0 TN: 6618.0 FP: 103.0 FN: 115.0\n",
      "test Loss: 0.1268 Acc: 0.9608 Pre: 0.9440 Rec: 0.9313 F1: 0.9376 Time in epoch: 6735.7105\n",
      "TP: 2208.0 TN: 4994.0 FP: 131.0 FN: 163.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1900 Acc: 0.9328 Pre: 0.8763 Rec: 0.8788 F1: 0.8775 Time in epoch: 6568.6860\n",
      "TP: 68359.0 TN: 196541.0 FP: 9653.0 FN: 9429.0\n",
      "val Loss: 0.0871 Acc: 0.9782 Pre: 0.9674 Rec: 0.9572 F1: 0.9623 Time in epoch: 6652.2496\n",
      "TP: 2640.0 TN: 6632.0 FP: 89.0 FN: 118.0\n",
      "test Loss: 0.1258 Acc: 0.9596 Pre: 0.9476 Rec: 0.9232 F1: 0.9353 Time in epoch: 6718.8078\n",
      "TP: 2189.0 TN: 5004.0 FP: 121.0 FN: 182.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1888 Acc: 0.9330 Pre: 0.8776 Rec: 0.8779 F1: 0.8777 Time in epoch: 6571.7484\n",
      "TP: 68288.0 TN: 196669.0 FP: 9525.0 FN: 9500.0\n",
      "val Loss: 0.0879 Acc: 0.9768 Pre: 0.9618 Rec: 0.9583 F1: 0.9600 Time in epoch: 6654.8569\n",
      "TP: 2643.0 TN: 6616.0 FP: 105.0 FN: 115.0\n",
      "test Loss: 0.1247 Acc: 0.9600 Pre: 0.9461 Rec: 0.9262 F1: 0.9361 Time in epoch: 6721.4439\n",
      "TP: 2196.0 TN: 5000.0 FP: 125.0 FN: 175.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1874 Acc: 0.9334 Pre: 0.8772 Rec: 0.8803 F1: 0.8787 Time in epoch: 6573.3377\n",
      "TP: 68474.0 TN: 196604.0 FP: 9590.0 FN: 9314.0\n",
      "val Loss: 0.0900 Acc: 0.9762 Pre: 0.9600 Rec: 0.9579 F1: 0.9590 Time in epoch: 6656.8276\n",
      "TP: 2642.0 TN: 6611.0 FP: 110.0 FN: 116.0\n",
      "test Loss: 0.1263 Acc: 0.9600 Pre: 0.9442 Rec: 0.9283 F1: 0.9362 Time in epoch: 6722.6405\n",
      "TP: 2201.0 TN: 4995.0 FP: 130.0 FN: 170.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1884 Acc: 0.9332 Pre: 0.8778 Rec: 0.8786 F1: 0.8782 Time in epoch: 6570.6030\n",
      "TP: 68343.0 TN: 196677.0 FP: 9517.0 FN: 9445.0\n",
      "val Loss: 0.0880 Acc: 0.9766 Pre: 0.9614 Rec: 0.9579 F1: 0.9597 Time in epoch: 6654.8704\n",
      "TP: 2642.0 TN: 6615.0 FP: 106.0 FN: 116.0\n",
      "test Loss: 0.1262 Acc: 0.9605 Pre: 0.9462 Rec: 0.9279 F1: 0.9370 Time in epoch: 6721.2176\n",
      "TP: 2200.0 TN: 5000.0 FP: 125.0 FN: 171.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1878 Acc: 0.9336 Pre: 0.8778 Rec: 0.8800 F1: 0.8789 Time in epoch: 6574.9467\n",
      "TP: 68454.0 TN: 196667.0 FP: 9527.0 FN: 9334.0\n",
      "val Loss: 0.0868 Acc: 0.9775 Pre: 0.9653 Rec: 0.9572 F1: 0.9612 Time in epoch: 6658.1496\n",
      "TP: 2640.0 TN: 6626.0 FP: 95.0 FN: 118.0\n",
      "test Loss: 0.1258 Acc: 0.9605 Pre: 0.9482 Rec: 0.9258 F1: 0.9368 Time in epoch: 6724.1504\n",
      "TP: 2195.0 TN: 5005.0 FP: 120.0 FN: 176.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1865 Acc: 0.9344 Pre: 0.8791 Rec: 0.8819 F1: 0.8805 Time in epoch: 6572.4055\n",
      "TP: 68602.0 TN: 196757.0 FP: 9437.0 FN: 9186.0\n",
      "val Loss: 0.0897 Acc: 0.9764 Pre: 0.9621 Rec: 0.9565 F1: 0.9593 Time in epoch: 6656.5836\n",
      "TP: 2638.0 TN: 6617.0 FP: 104.0 FN: 120.0\n",
      "test Loss: 0.1261 Acc: 0.9612 Pre: 0.9491 Rec: 0.9270 F1: 0.9379 Time in epoch: 6722.9284\n",
      "TP: 2198.0 TN: 5007.0 FP: 118.0 FN: 173.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1873 Acc: 0.9337 Pre: 0.8781 Rec: 0.8803 F1: 0.8792 Time in epoch: 6569.7510\n",
      "TP: 68473.0 TN: 196686.0 FP: 9508.0 FN: 9315.0\n",
      "val Loss: 0.0906 Acc: 0.9763 Pre: 0.9621 Rec: 0.9561 F1: 0.9591 Time in epoch: 6653.8058\n",
      "TP: 2637.0 TN: 6617.0 FP: 104.0 FN: 121.0\n",
      "test Loss: 0.1274 Acc: 0.9602 Pre: 0.9466 Rec: 0.9266 F1: 0.9365 Time in epoch: 6720.5801\n",
      "TP: 2197.0 TN: 5001.0 FP: 124.0 FN: 174.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1873 Acc: 0.9337 Pre: 0.8781 Rec: 0.8804 F1: 0.8792 Time in epoch: 6572.2894\n",
      "TP: 68482.0 TN: 196685.0 FP: 9509.0 FN: 9306.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0906 Acc: 0.9757 Pre: 0.9603 Rec: 0.9561 F1: 0.9582 Time in epoch: 6656.9316\n",
      "TP: 2637.0 TN: 6612.0 FP: 109.0 FN: 121.0\n",
      "test Loss: 0.1277 Acc: 0.9606 Pre: 0.9459 Rec: 0.9287 F1: 0.9372 Time in epoch: 6723.7924\n",
      "TP: 2202.0 TN: 4999.0 FP: 126.0 FN: 169.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1867 Acc: 0.9333 Pre: 0.8778 Rec: 0.8790 F1: 0.8784 Time in epoch: 6571.1534\n",
      "TP: 68373.0 TN: 196677.0 FP: 9517.0 FN: 9415.0\n",
      "val Loss: 0.0884 Acc: 0.9765 Pre: 0.9641 Rec: 0.9547 F1: 0.9594 Time in epoch: 6654.4771\n",
      "TP: 2633.0 TN: 6623.0 FP: 98.0 FN: 125.0\n",
      "test Loss: 0.1268 Acc: 0.9601 Pre: 0.9481 Rec: 0.9245 F1: 0.9362 Time in epoch: 6720.3013\n",
      "TP: 2192.0 TN: 5005.0 FP: 120.0 FN: 179.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1867 Acc: 0.9335 Pre: 0.8775 Rec: 0.8803 F1: 0.8789 Time in epoch: 6572.4890\n",
      "TP: 68480.0 TN: 196630.0 FP: 9564.0 FN: 9308.0\n",
      "val Loss: 0.0890 Acc: 0.9761 Pre: 0.9597 Rec: 0.9579 F1: 0.9588 Time in epoch: 6657.7912\n",
      "TP: 2642.0 TN: 6610.0 FP: 111.0 FN: 116.0\n",
      "test Loss: 0.1264 Acc: 0.9606 Pre: 0.9463 Rec: 0.9283 F1: 0.9372 Time in epoch: 6724.9837\n",
      "TP: 2201.0 TN: 5000.0 FP: 125.0 FN: 170.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1865 Acc: 0.9340 Pre: 0.8789 Rec: 0.8802 F1: 0.8796 Time in epoch: 6585.5412\n",
      "TP: 68472.0 TN: 196760.0 FP: 9434.0 FN: 9316.0\n",
      "val Loss: 0.0885 Acc: 0.9764 Pre: 0.9611 Rec: 0.9576 F1: 0.9593 Time in epoch: 6670.4155\n",
      "TP: 2641.0 TN: 6614.0 FP: 107.0 FN: 117.0\n",
      "test Loss: 0.1256 Acc: 0.9598 Pre: 0.9438 Rec: 0.9283 F1: 0.9360 Time in epoch: 6737.7997\n",
      "TP: 2201.0 TN: 4994.0 FP: 131.0 FN: 170.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1863 Acc: 0.9344 Pre: 0.8795 Rec: 0.8812 F1: 0.8804 Time in epoch: 6583.7272\n",
      "TP: 68550.0 TN: 196803.0 FP: 9391.0 FN: 9238.0\n",
      "test Loss: 0.1259 Acc: 0.9604 Pre: 0.9454 Rec: 0.9283 F1: 0.9368 Time in epoch: 6736.0899\n",
      "TP: 2201.0 TN: 4998.0 FP: 127.0 FN: 170.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1861 Acc: 0.9337 Pre: 0.8778 Rec: 0.8805 F1: 0.8791 Time in epoch: 6582.4227\n",
      "TP: 68494.0 TN: 196656.0 FP: 9538.0 FN: 9294.0\n",
      "val Loss: 0.0872 Acc: 0.9769 Pre: 0.9638 Rec: 0.9565 F1: 0.9601 Time in epoch: 6667.1781\n",
      "TP: 2638.0 TN: 6622.0 FP: 99.0 FN: 120.0\n",
      "test Loss: 0.1263 Acc: 0.9604 Pre: 0.9485 Rec: 0.9249 F1: 0.9366 Time in epoch: 6734.5529\n",
      "TP: 2193.0 TN: 5006.0 FP: 119.0 FN: 178.0\n",
      "\n",
      "Training complete in 2805m 11s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_400_new/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
