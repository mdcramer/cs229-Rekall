{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/train.txt'\n",
    "rekall_val_file = 'commercials/data/rekall_val.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "# val_paths, Y_val = read_file(val_file)\n",
    "val_paths, Y_val = read_file(rekall_val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 64130, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print(t_start)\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print(time.time() - t_start)\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_train val test\n",
      "Epoch 0/24\n",
      "1573180379.0749404\n",
      "----------\n",
      "327.9725525379181\n",
      "train Loss: 0.3918 Acc: 0.8365 Pre: 0.7297 Rec: 0.7046 F1: 0.7169\n",
      "TP: 1963.0 TN: 5966.0 FP: 727.0 FN: 823.0\n",
      "426.4830002784729\n",
      "val Loss: 0.1983 Acc: 0.9452 Pre: 0.9395 Rec: 0.8697 F1: 0.9033\n",
      "TP: 2423.0 TN: 6537.0 FP: 156.0 FN: 363.0\n",
      "505.0868525505066\n",
      "test Loss: 0.2158 Acc: 0.9366 Pre: 0.9169 Rec: 0.8794 F1: 0.8977\n",
      "TP: 2085.0 TN: 4936.0 FP: 189.0 FN: 286.0\n",
      "\n",
      "Epoch 1/24\n",
      "1573180884.1630695\n",
      "----------\n",
      "327.5732161998749\n",
      "train Loss: 0.3001 Acc: 0.8814 Pre: 0.7968 Rec: 0.8008 F1: 0.7988\n",
      "TP: 2231.0 TN: 6124.0 FP: 569.0 FN: 555.0\n",
      "426.10866713523865\n",
      "val Loss: 0.1703 Acc: 0.9575 Pre: 0.9505 Rec: 0.9024 F1: 0.9258\n",
      "TP: 2514.0 TN: 6562.0 FP: 131.0 FN: 272.0\n",
      "504.1655857563019\n",
      "test Loss: 0.2172 Acc: 0.9290 Pre: 0.8691 Rec: 0.9131 F1: 0.8906\n",
      "TP: 2165.0 TN: 4799.0 FP: 326.0 FN: 206.0\n",
      "\n",
      "Epoch 2/24\n",
      "1573181388.3299727\n",
      "----------\n",
      "327.43024706840515\n",
      "train Loss: 0.2698 Acc: 0.9018 Pre: 0.8347 Rec: 0.8302 F1: 0.8325\n",
      "TP: 2313.0 TN: 6235.0 FP: 458.0 FN: 473.0\n",
      "426.1670229434967\n",
      "val Loss: 0.1842 Acc: 0.9468 Pre: 0.8943 Rec: 0.9289 F1: 0.9113\n",
      "TP: 2588.0 TN: 6387.0 FP: 306.0 FN: 198.0\n",
      "504.2467529773712\n",
      "test Loss: 0.2770 Acc: 0.8969 Pre: 0.7813 Rec: 0.9359 F1: 0.8517\n",
      "TP: 2219.0 TN: 4504.0 FP: 621.0 FN: 152.0\n",
      "\n",
      "Epoch 3/24\n",
      "1573181892.5780828\n",
      "----------\n",
      "327.48573756217957\n",
      "train Loss: 0.2482 Acc: 0.9094 Pre: 0.8465 Rec: 0.8449 F1: 0.8457\n",
      "TP: 2354.0 TN: 6266.0 FP: 427.0 FN: 432.0\n",
      "425.97921204566956\n",
      "val Loss: 0.1371 Acc: 0.9572 Pre: 0.9287 Rec: 0.9253 F1: 0.9270\n",
      "TP: 2578.0 TN: 6495.0 FP: 198.0 FN: 208.0\n",
      "503.9661283493042\n",
      "test Loss: 0.2045 Acc: 0.9317 Pre: 0.8582 Rec: 0.9393 F1: 0.8969\n",
      "TP: 2227.0 TN: 4757.0 FP: 368.0 FN: 144.0\n",
      "\n",
      "Epoch 4/24\n",
      "1573182396.5455353\n",
      "----------\n",
      "327.40416741371155\n",
      "train Loss: 0.2380 Acc: 0.9112 Pre: 0.8527 Rec: 0.8435 F1: 0.8481\n",
      "TP: 2350.0 TN: 6287.0 FP: 406.0 FN: 436.0\n",
      "425.90061473846436\n",
      "val Loss: 0.1623 Acc: 0.9541 Pre: 0.9069 Rec: 0.9404 F1: 0.9233\n",
      "TP: 2620.0 TN: 6424.0 FP: 269.0 FN: 166.0\n",
      "503.8500370979309\n",
      "test Loss: 0.2468 Acc: 0.9236 Pre: 0.8400 Rec: 0.9367 F1: 0.8857\n",
      "TP: 2221.0 TN: 4702.0 FP: 423.0 FN: 150.0\n",
      "\n",
      "Epoch 5/24\n",
      "1573182900.3969111\n",
      "----------\n",
      "327.47591376304626\n",
      "train Loss: 0.2242 Acc: 0.9155 Pre: 0.8543 Rec: 0.8589 F1: 0.8566\n",
      "TP: 2393.0 TN: 6285.0 FP: 408.0 FN: 393.0\n",
      "425.9371039867401\n",
      "val Loss: 0.1371 Acc: 0.9647 Pre: 0.9514 Rec: 0.9271 F1: 0.9391\n",
      "TP: 2583.0 TN: 6561.0 FP: 132.0 FN: 203.0\n",
      "503.91319704055786\n",
      "test Loss: 0.1935 Acc: 0.9426 Pre: 0.9039 Rec: 0.9161 F1: 0.9099\n",
      "TP: 2172.0 TN: 4894.0 FP: 231.0 FN: 199.0\n",
      "\n",
      "Epoch 6/24\n",
      "1573183404.3118072\n",
      "----------\n",
      "327.19658732414246\n",
      "train Loss: 0.2033 Acc: 0.9256 Pre: 0.8686 Rec: 0.8801 F1: 0.8743\n",
      "TP: 2452.0 TN: 6322.0 FP: 371.0 FN: 334.0\n",
      "425.7486174106598\n",
      "val Loss: 0.1172 Acc: 0.9660 Pre: 0.9369 Rec: 0.9483 F1: 0.9426\n",
      "TP: 2642.0 TN: 6515.0 FP: 178.0 FN: 144.0\n",
      "503.9866828918457\n",
      "test Loss: 0.2235 Acc: 0.9288 Pre: 0.8488 Rec: 0.9426 F1: 0.8933\n",
      "TP: 2235.0 TN: 4727.0 FP: 398.0 FN: 136.0\n",
      "\n",
      "Epoch 7/24\n",
      "1573183908.2998602\n",
      "----------\n",
      "327.5172083377838\n",
      "train Loss: 0.1848 Acc: 0.9331 Pre: 0.8797 Rec: 0.8948 F1: 0.8872\n",
      "TP: 2493.0 TN: 6352.0 FP: 341.0 FN: 293.0\n",
      "426.1566481590271\n",
      "val Loss: 0.1066 Acc: 0.9684 Pre: 0.9455 Rec: 0.9469 F1: 0.9462\n",
      "TP: 2638.0 TN: 6541.0 FP: 152.0 FN: 148.0\n",
      "504.2563536167145\n",
      "test Loss: 0.1943 Acc: 0.9358 Pre: 0.8677 Rec: 0.9405 F1: 0.9027\n",
      "TP: 2230.0 TN: 4785.0 FP: 340.0 FN: 141.0\n",
      "\n",
      "Epoch 8/24\n",
      "1573184412.5575192\n",
      "----------\n",
      "327.16236758232117\n",
      "train Loss: 0.1852 Acc: 0.9321 Pre: 0.8809 Rec: 0.8891 F1: 0.8850\n",
      "TP: 2477.0 TN: 6358.0 FP: 335.0 FN: 309.0\n",
      "425.81257009506226\n",
      "val Loss: 0.1282 Acc: 0.9635 Pre: 0.9227 Rec: 0.9559 F1: 0.9390\n",
      "TP: 2663.0 TN: 6470.0 FP: 223.0 FN: 123.0\n",
      "503.9346935749054\n",
      "test Loss: 0.2528 Acc: 0.9217 Pre: 0.8258 Rec: 0.9536 F1: 0.8851\n",
      "TP: 2261.0 TN: 4648.0 FP: 477.0 FN: 110.0\n",
      "\n",
      "Epoch 9/24\n",
      "1573184916.493501\n",
      "----------\n",
      "327.3461172580719\n",
      "train Loss: 0.1838 Acc: 0.9337 Pre: 0.8832 Rec: 0.8927 F1: 0.8879\n",
      "TP: 2487.0 TN: 6364.0 FP: 329.0 FN: 299.0\n",
      "425.896066904068\n",
      "val Loss: 0.1077 Acc: 0.9674 Pre: 0.9499 Rec: 0.9386 F1: 0.9442\n",
      "TP: 2615.0 TN: 6555.0 FP: 138.0 FN: 171.0\n",
      "503.9201912879944\n",
      "test Loss: 0.1976 Acc: 0.9352 Pre: 0.8778 Rec: 0.9237 F1: 0.9001\n",
      "TP: 2190.0 TN: 4820.0 FP: 305.0 FN: 181.0\n",
      "\n",
      "Epoch 10/24\n",
      "1573185420.4150295\n",
      "----------\n",
      "327.5148620605469\n",
      "train Loss: 0.1829 Acc: 0.9344 Pre: 0.8870 Rec: 0.8902 F1: 0.8886\n",
      "TP: 2480.0 TN: 6377.0 FP: 316.0 FN: 306.0\n",
      "426.0118417739868\n",
      "val Loss: 0.1066 Acc: 0.9659 Pre: 0.9326 Rec: 0.9530 F1: 0.9427\n",
      "TP: 2655.0 TN: 6501.0 FP: 192.0 FN: 131.0\n",
      "504.01544213294983\n",
      "test Loss: 0.2108 Acc: 0.9304 Pre: 0.8517 Rec: 0.9443 F1: 0.8956\n",
      "TP: 2239.0 TN: 4735.0 FP: 390.0 FN: 132.0\n",
      "\n",
      "Epoch 11/24\n",
      "1573185924.4318602\n",
      "----------\n",
      "327.61385345458984\n",
      "train Loss: 0.1772 Acc: 0.9355 Pre: 0.8863 Rec: 0.8955 F1: 0.8909\n",
      "TP: 2495.0 TN: 6373.0 FP: 320.0 FN: 291.0\n",
      "426.17620277404785\n",
      "val Loss: 0.1001 Acc: 0.9703 Pre: 0.9481 Rec: 0.9508 F1: 0.9495\n",
      "TP: 2649.0 TN: 6548.0 FP: 145.0 FN: 137.0\n",
      "504.3452425003052\n",
      "test Loss: 0.1939 Acc: 0.9364 Pre: 0.8767 Rec: 0.9296 F1: 0.9024\n",
      "TP: 2204.0 TN: 4815.0 FP: 310.0 FN: 167.0\n",
      "\n",
      "Epoch 12/24\n",
      "1573186428.7785125\n",
      "----------\n",
      "327.53435802459717\n",
      "train Loss: 0.1733 Acc: 0.9358 Pre: 0.8908 Rec: 0.8905 F1: 0.8907\n",
      "TP: 2481.0 TN: 6389.0 FP: 304.0 FN: 305.0\n",
      "426.03828620910645\n",
      "val Loss: 0.1029 Acc: 0.9668 Pre: 0.9352 Rec: 0.9530 F1: 0.9440\n",
      "TP: 2655.0 TN: 6509.0 FP: 184.0 FN: 131.0\n",
      "503.9670958518982\n",
      "test Loss: 0.2004 Acc: 0.9325 Pre: 0.8679 Rec: 0.9279 F1: 0.8969\n",
      "TP: 2200.0 TN: 4790.0 FP: 335.0 FN: 171.0\n",
      "\n",
      "Epoch 13/24\n",
      "1573186932.7469742\n",
      "----------\n",
      "327.4819025993347\n",
      "train Loss: 0.1685 Acc: 0.9408 Pre: 0.8946 Rec: 0.9052 F1: 0.8999\n",
      "TP: 2522.0 TN: 6396.0 FP: 297.0 FN: 264.0\n",
      "426.1472010612488\n",
      "val Loss: 0.0999 Acc: 0.9674 Pre: 0.9362 Rec: 0.9541 F1: 0.9451\n",
      "TP: 2658.0 TN: 6512.0 FP: 181.0 FN: 128.0\n",
      "504.0962247848511\n",
      "test Loss: 0.1992 Acc: 0.9321 Pre: 0.8668 Rec: 0.9279 F1: 0.8963\n",
      "TP: 2200.0 TN: 4787.0 FP: 338.0 FN: 171.0\n",
      "\n",
      "Epoch 14/24\n",
      "1573187436.8445237\n",
      "----------\n",
      "327.55106687545776\n",
      "train Loss: 0.1660 Acc: 0.9408 Pre: 0.9006 Rec: 0.8977 F1: 0.8992\n",
      "TP: 2501.0 TN: 6417.0 FP: 276.0 FN: 285.0\n",
      "426.04280614852905\n",
      "val Loss: 0.0994 Acc: 0.9680 Pre: 0.9395 Rec: 0.9526 F1: 0.9460\n",
      "TP: 2654.0 TN: 6522.0 FP: 171.0 FN: 132.0\n",
      "504.25305581092834\n",
      "test Loss: 0.1994 Acc: 0.9332 Pre: 0.8690 Rec: 0.9287 F1: 0.8979\n",
      "TP: 2202.0 TN: 4793.0 FP: 332.0 FN: 169.0\n",
      "\n",
      "Epoch 15/24\n",
      "1573187941.0988297\n",
      "----------\n",
      "327.3538854122162\n",
      "train Loss: 0.1683 Acc: 0.9364 Pre: 0.8864 Rec: 0.8988 F1: 0.8925\n",
      "TP: 2504.0 TN: 6372.0 FP: 321.0 FN: 282.0\n",
      "426.0744249820709\n",
      "val Loss: 0.1019 Acc: 0.9672 Pre: 0.9341 Rec: 0.9559 F1: 0.9448\n",
      "TP: 2663.0 TN: 6505.0 FP: 188.0 FN: 123.0\n",
      "504.13403701782227\n",
      "test Loss: 0.2064 Acc: 0.9294 Pre: 0.8556 Rec: 0.9346 F1: 0.8934\n",
      "TP: 2216.0 TN: 4751.0 FP: 374.0 FN: 155.0\n",
      "\n",
      "Epoch 16/24\n",
      "1573188445.234307\n",
      "----------\n",
      "327.6175811290741\n",
      "train Loss: 0.1726 Acc: 0.9371 Pre: 0.8900 Rec: 0.8970 F1: 0.8935\n",
      "TP: 2499.0 TN: 6384.0 FP: 309.0 FN: 287.0\n",
      "426.4131190776825\n",
      "val Loss: 0.0966 Acc: 0.9700 Pre: 0.9516 Rec: 0.9462 F1: 0.9489\n",
      "TP: 2636.0 TN: 6559.0 FP: 134.0 FN: 150.0\n",
      "504.64115500450134\n",
      "test Loss: 0.1813 Acc: 0.9414 Pre: 0.8979 Rec: 0.9194 F1: 0.9085\n",
      "TP: 2180.0 TN: 4877.0 FP: 248.0 FN: 191.0\n",
      "\n",
      "Epoch 17/24\n",
      "1573188949.8767116\n",
      "----------\n",
      "327.57916259765625\n",
      "train Loss: 0.1684 Acc: 0.9380 Pre: 0.8968 Rec: 0.8916 F1: 0.8942\n",
      "TP: 2484.0 TN: 6407.0 FP: 286.0 FN: 302.0\n",
      "426.17449855804443\n",
      "val Loss: 0.0984 Acc: 0.9692 Pre: 0.9413 Rec: 0.9548 F1: 0.9480\n",
      "TP: 2660.0 TN: 6527.0 FP: 166.0 FN: 126.0\n",
      "504.2484607696533\n",
      "test Loss: 0.2031 Acc: 0.9333 Pre: 0.8613 Rec: 0.9405 F1: 0.8992\n",
      "TP: 2230.0 TN: 4766.0 FP: 359.0 FN: 141.0\n",
      "\n",
      "Epoch 18/24\n",
      "1573189454.1264744\n",
      "----------\n",
      "327.606085062027\n",
      "train Loss: 0.1682 Acc: 0.9385 Pre: 0.8913 Rec: 0.9006 F1: 0.8959\n",
      "TP: 2509.0 TN: 6387.0 FP: 306.0 FN: 277.0\n",
      "426.3283166885376\n",
      "val Loss: 0.0963 Acc: 0.9704 Pre: 0.9570 Rec: 0.9415 F1: 0.9492\n",
      "TP: 2623.0 TN: 6575.0 FP: 118.0 FN: 163.0\n",
      "504.2691423892975\n",
      "test Loss: 0.1832 Acc: 0.9405 Pre: 0.9005 Rec: 0.9127 F1: 0.9066\n",
      "TP: 2164.0 TN: 4886.0 FP: 239.0 FN: 207.0\n",
      "\n",
      "Epoch 19/24\n",
      "1573189958.3972845\n",
      "----------\n",
      "327.4927623271942\n",
      "train Loss: 0.1704 Acc: 0.9412 Pre: 0.9008 Rec: 0.8991 F1: 0.8999\n",
      "TP: 2505.0 TN: 6417.0 FP: 276.0 FN: 281.0\n",
      "425.9182541370392\n",
      "val Loss: 0.0996 Acc: 0.9685 Pre: 0.9386 Rec: 0.9551 F1: 0.9468\n",
      "TP: 2661.0 TN: 6519.0 FP: 174.0 FN: 125.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503.8979694843292\n",
      "test Loss: 0.2144 Acc: 0.9273 Pre: 0.8517 Rec: 0.9325 F1: 0.8903\n",
      "TP: 2211.0 TN: 4740.0 FP: 385.0 FN: 160.0\n",
      "\n",
      "Epoch 20/24\n",
      "1573190462.2969224\n",
      "----------\n",
      "327.44844603538513\n",
      "train Loss: 0.1679 Acc: 0.9403 Pre: 0.8987 Rec: 0.8981 F1: 0.8984\n",
      "TP: 2502.0 TN: 6411.0 FP: 282.0 FN: 284.0\n",
      "426.12836718559265\n",
      "val Loss: 0.0961 Acc: 0.9696 Pre: 0.9467 Rec: 0.9501 F1: 0.9484\n",
      "TP: 2647.0 TN: 6544.0 FP: 149.0 FN: 139.0\n",
      "504.2623052597046\n",
      "test Loss: 0.1896 Acc: 0.9368 Pre: 0.8823 Rec: 0.9232 F1: 0.9023\n",
      "TP: 2189.0 TN: 4833.0 FP: 292.0 FN: 182.0\n",
      "\n",
      "Epoch 21/24\n",
      "1573190966.5606005\n",
      "----------\n",
      "327.4991533756256\n",
      "train Loss: 0.1630 Acc: 0.9392 Pre: 0.8949 Rec: 0.8988 F1: 0.8968\n",
      "TP: 2504.0 TN: 6399.0 FP: 294.0 FN: 282.0\n",
      "426.0752944946289\n",
      "val Loss: 0.1027 Acc: 0.9670 Pre: 0.9316 Rec: 0.9580 F1: 0.9446\n",
      "TP: 2669.0 TN: 6497.0 FP: 196.0 FN: 117.0\n",
      "504.06450295448303\n",
      "test Loss: 0.2175 Acc: 0.9257 Pre: 0.8475 Rec: 0.9329 F1: 0.8882\n",
      "TP: 2212.0 TN: 4727.0 FP: 398.0 FN: 159.0\n",
      "\n",
      "Epoch 22/24\n",
      "1573191470.6263573\n",
      "----------\n",
      "327.33413672447205\n",
      "train Loss: 0.1685 Acc: 0.9382 Pre: 0.8912 Rec: 0.8995 F1: 0.8953\n",
      "TP: 2506.0 TN: 6387.0 FP: 306.0 FN: 280.0\n",
      "425.8543767929077\n",
      "val Loss: 0.0996 Acc: 0.9682 Pre: 0.9346 Rec: 0.9591 F1: 0.9467\n",
      "TP: 2672.0 TN: 6506.0 FP: 187.0 FN: 114.0\n",
      "503.80958247184753\n",
      "test Loss: 0.2066 Acc: 0.9285 Pre: 0.8511 Rec: 0.9380 F1: 0.8925\n",
      "TP: 2224.0 TN: 4736.0 FP: 389.0 FN: 147.0\n",
      "\n",
      "Epoch 23/24\n",
      "1573191974.4371743\n",
      "----------\n",
      "327.3956742286682\n",
      "train Loss: 0.1691 Acc: 0.9391 Pre: 0.8980 Rec: 0.8945 F1: 0.8962\n",
      "TP: 2492.0 TN: 6410.0 FP: 283.0 FN: 294.0\n",
      "425.91895174980164\n",
      "val Loss: 0.0961 Acc: 0.9694 Pre: 0.9422 Rec: 0.9544 F1: 0.9483\n",
      "TP: 2659.0 TN: 6530.0 FP: 163.0 FN: 127.0\n",
      "503.8087754249573\n",
      "test Loss: 0.1971 Acc: 0.9333 Pre: 0.8661 Rec: 0.9334 F1: 0.8985\n",
      "TP: 2213.0 TN: 4783.0 FP: 342.0 FN: 158.0\n",
      "\n",
      "Epoch 24/24\n",
      "1573192478.247231\n",
      "----------\n",
      "327.3617148399353\n",
      "train Loss: 0.1709 Acc: 0.9375 Pre: 0.8923 Rec: 0.8955 F1: 0.8939\n",
      "TP: 2495.0 TN: 6392.0 FP: 301.0 FN: 291.0\n",
      "425.9158833026886\n",
      "val Loss: 0.1024 Acc: 0.9680 Pre: 0.9315 Rec: 0.9620 F1: 0.9465\n",
      "TP: 2680.0 TN: 6496.0 FP: 197.0 FN: 106.0\n",
      "504.0951669216156\n",
      "test Loss: 0.2189 Acc: 0.9264 Pre: 0.8433 Rec: 0.9422 F1: 0.8900\n",
      "TP: 2234.0 TN: 4710.0 FP: 415.0 FN: 137.0\n",
      "\n",
      "Training complete in 210m 3s\n",
      "Best epoch: 11\n",
      "Best val Acc: 0.970250\n",
      "Best val Pre: 0.948103\n",
      "Best val Rec: 0.950826\n",
      "Best val F1: 0.949462\n",
      "Test Acc: 0.936366\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'val_train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=True)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
