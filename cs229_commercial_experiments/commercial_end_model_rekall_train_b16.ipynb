{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = 1     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/rekall_train.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, load_percentage = 1):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = sorted(list(set(videos))) # set of all videos\n",
    "        num_videos = int(len(videos) * load_percentage) # number of videos to use\n",
    "        videos = videos[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append('commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file, data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = 4,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 64130, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2592 Acc: 0.9068 Pre: 0.8493 Rec: 0.8289 F1: 0.8390 Time in epoch: 1606.6843\n",
      "TP: 15573.0 TN: 42579.0 FP: 2764.0 FN: 3214.0\n",
      "val Loss: 0.1127 Acc: 0.9671 Pre: 0.9454 Rec: 0.9413 F1: 0.9433 Time in epoch: 1680.8572\n",
      "TP: 2596.0 TN: 6571.0 FP: 150.0 FN: 162.0\n",
      "test Loss: 0.1460 Acc: 0.9552 Pre: 0.9354 Rec: 0.9220 F1: 0.9286 Time in epoch: 1739.5565\n",
      "TP: 2186.0 TN: 4974.0 FP: 151.0 FN: 185.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2174 Acc: 0.9241 Pre: 0.8786 Rec: 0.8595 F1: 0.8690 Time in epoch: 1604.3580\n",
      "TP: 16148.0 TN: 43112.0 FP: 2231.0 FN: 2639.0\n",
      "val Loss: 0.0979 Acc: 0.9704 Pre: 0.9431 Rec: 0.9558 F1: 0.9494 Time in epoch: 1675.4673\n",
      "TP: 2636.0 TN: 6562.0 FP: 159.0 FN: 122.0\n",
      "test Loss: 0.1299 Acc: 0.9581 Pre: 0.9312 Rec: 0.9367 F1: 0.9340 Time in epoch: 1732.4799\n",
      "TP: 2221.0 TN: 4961.0 FP: 164.0 FN: 150.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2068 Acc: 0.9285 Pre: 0.8869 Rec: 0.8663 F1: 0.8765 Time in epoch: 1578.2039\n",
      "TP: 16275.0 TN: 43267.0 FP: 2076.0 FN: 2512.0\n",
      "val Loss: 0.1029 Acc: 0.9685 Pre: 0.9492 Rec: 0.9420 F1: 0.9456 Time in epoch: 1649.2409\n",
      "TP: 2598.0 TN: 6582.0 FP: 139.0 FN: 160.0\n",
      "test Loss: 0.1375 Acc: 0.9565 Pre: 0.9551 Rec: 0.9051 F1: 0.9294 Time in epoch: 1706.5987\n",
      "TP: 2146.0 TN: 5024.0 FP: 101.0 FN: 225.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.1966 Acc: 0.9308 Pre: 0.8886 Rec: 0.8735 F1: 0.8810 Time in epoch: 1559.7940\n",
      "TP: 16410.0 TN: 43285.0 FP: 2058.0 FN: 2377.0\n",
      "val Loss: 0.1298 Acc: 0.9597 Pre: 0.9163 Rec: 0.9482 F1: 0.9319 Time in epoch: 1630.7801\n",
      "TP: 2615.0 TN: 6482.0 FP: 239.0 FN: 143.0\n",
      "test Loss: 0.1418 Acc: 0.9540 Pre: 0.9238 Rec: 0.9313 F1: 0.9275 Time in epoch: 1687.7846\n",
      "TP: 2208.0 TN: 4943.0 FP: 182.0 FN: 163.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1915 Acc: 0.9345 Pre: 0.8964 Rec: 0.8777 F1: 0.8870 Time in epoch: 1544.0826\n",
      "TP: 16489.0 TN: 43438.0 FP: 1905.0 FN: 2298.0\n",
      "val Loss: 0.1078 Acc: 0.9656 Pre: 0.9349 Rec: 0.9478 F1: 0.9413 Time in epoch: 1615.1752\n",
      "TP: 2614.0 TN: 6539.0 FP: 182.0 FN: 144.0\n",
      "test Loss: 0.1348 Acc: 0.9601 Pre: 0.9435 Rec: 0.9296 F1: 0.9365 Time in epoch: 1671.7005\n",
      "TP: 2204.0 TN: 4993.0 FP: 132.0 FN: 167.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1823 Acc: 0.9364 Pre: 0.8993 Rec: 0.8816 F1: 0.8903 Time in epoch: 1505.5073\n",
      "TP: 16562.0 TN: 43488.0 FP: 1855.0 FN: 2225.0\n",
      "val Loss: 0.1047 Acc: 0.9707 Pre: 0.9457 Rec: 0.9540 F1: 0.9498 Time in epoch: 1573.1245\n",
      "TP: 2631.0 TN: 6570.0 FP: 151.0 FN: 127.0\n",
      "test Loss: 0.1437 Acc: 0.9564 Pre: 0.9338 Rec: 0.9279 F1: 0.9308 Time in epoch: 1627.3309\n",
      "TP: 2200.0 TN: 4969.0 FP: 156.0 FN: 171.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1682 Acc: 0.9405 Pre: 0.9082 Rec: 0.8865 F1: 0.8972 Time in epoch: 1521.1737\n",
      "TP: 16655.0 TN: 43660.0 FP: 1683.0 FN: 2132.0\n",
      "val Loss: 0.0995 Acc: 0.9695 Pre: 0.9389 Rec: 0.9576 F1: 0.9481 Time in epoch: 1592.7358\n",
      "TP: 2641.0 TN: 6549.0 FP: 172.0 FN: 117.0\n",
      "test Loss: 0.1333 Acc: 0.9566 Pre: 0.9306 Rec: 0.9325 F1: 0.9315 Time in epoch: 1648.3602\n",
      "TP: 2211.0 TN: 4960.0 FP: 165.0 FN: 160.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1619 Acc: 0.9432 Pre: 0.9128 Rec: 0.8914 F1: 0.9020 Time in epoch: 1642.6862\n",
      "TP: 16746.0 TN: 43744.0 FP: 1599.0 FN: 2041.0\n",
      "val Loss: 0.1058 Acc: 0.9657 Pre: 0.9276 Rec: 0.9569 F1: 0.9420 Time in epoch: 1716.6267\n",
      "TP: 2639.0 TN: 6515.0 FP: 206.0 FN: 119.0\n",
      "test Loss: 0.1352 Acc: 0.9552 Pre: 0.9220 Rec: 0.9376 F1: 0.9297 Time in epoch: 1775.6866\n",
      "TP: 2223.0 TN: 4937.0 FP: 188.0 FN: 148.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1603 Acc: 0.9440 Pre: 0.9143 Rec: 0.8925 F1: 0.9032 Time in epoch: 1597.6465\n",
      "TP: 16767.0 TN: 43771.0 FP: 1572.0 FN: 2020.0\n",
      "val Loss: 0.1152 Acc: 0.9615 Pre: 0.9105 Rec: 0.9623 F1: 0.9357 Time in epoch: 1668.4939\n",
      "TP: 2654.0 TN: 6460.0 FP: 261.0 FN: 104.0\n",
      "test Loss: 0.1390 Acc: 0.9554 Pre: 0.9176 Rec: 0.9439 F1: 0.9306 Time in epoch: 1725.0508\n",
      "TP: 2238.0 TN: 4924.0 FP: 201.0 FN: 133.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1579 Acc: 0.9446 Pre: 0.9150 Rec: 0.8939 F1: 0.9043 Time in epoch: 1583.8267\n",
      "TP: 16793.0 TN: 43782.0 FP: 1561.0 FN: 1994.0\n",
      "val Loss: 0.1058 Acc: 0.9646 Pre: 0.9237 Rec: 0.9572 F1: 0.9402 Time in epoch: 1655.0849\n",
      "TP: 2640.0 TN: 6503.0 FP: 218.0 FN: 118.0\n",
      "test Loss: 0.1369 Acc: 0.9569 Pre: 0.9263 Rec: 0.9384 F1: 0.9323 Time in epoch: 1712.0926\n",
      "TP: 2225.0 TN: 4948.0 FP: 177.0 FN: 146.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1545 Acc: 0.9452 Pre: 0.9143 Rec: 0.8970 F1: 0.9055 Time in epoch: 1575.8009\n",
      "TP: 16851.0 TN: 43763.0 FP: 1580.0 FN: 1936.0\n",
      "val Loss: 0.1235 Acc: 0.9575 Pre: 0.8974 Rec: 0.9641 F1: 0.9296 Time in epoch: 1646.9062\n",
      "TP: 2659.0 TN: 6417.0 FP: 304.0 FN: 99.0\n",
      "test Loss: 0.1400 Acc: 0.9548 Pre: 0.9137 Rec: 0.9464 F1: 0.9298 Time in epoch: 1703.2408\n",
      "TP: 2244.0 TN: 4913.0 FP: 212.0 FN: 127.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1555 Acc: 0.9446 Pre: 0.9152 Rec: 0.8938 F1: 0.9044 Time in epoch: 1545.9765\n",
      "TP: 16792.0 TN: 43787.0 FP: 1556.0 FN: 1995.0\n",
      "val Loss: 0.1032 Acc: 0.9652 Pre: 0.9263 Rec: 0.9565 F1: 0.9411 Time in epoch: 1615.4369\n",
      "TP: 2638.0 TN: 6511.0 FP: 210.0 FN: 120.0\n",
      "test Loss: 0.1353 Acc: 0.9569 Pre: 0.9288 Rec: 0.9355 F1: 0.9321 Time in epoch: 1671.7954\n",
      "TP: 2218.0 TN: 4955.0 FP: 170.0 FN: 153.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1516 Acc: 0.9467 Pre: 0.9182 Rec: 0.8979 F1: 0.9079 Time in epoch: 1464.8707\n",
      "TP: 16868.0 TN: 43841.0 FP: 1502.0 FN: 1919.0\n",
      "val Loss: 0.1093 Acc: 0.9632 Pre: 0.9149 Rec: 0.9630 F1: 0.9384 Time in epoch: 1532.6144\n",
      "TP: 2656.0 TN: 6474.0 FP: 247.0 FN: 102.0\n",
      "test Loss: 0.1364 Acc: 0.9548 Pre: 0.9164 Rec: 0.9431 F1: 0.9295 Time in epoch: 1586.7248\n",
      "TP: 2236.0 TN: 4921.0 FP: 204.0 FN: 135.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1501 Acc: 0.9466 Pre: 0.9165 Rec: 0.8995 F1: 0.9079 Time in epoch: 1472.3357\n",
      "TP: 16899.0 TN: 43804.0 FP: 1539.0 FN: 1888.0\n",
      "val Loss: 0.1160 Acc: 0.9591 Pre: 0.9044 Rec: 0.9608 F1: 0.9318 Time in epoch: 1540.0763\n",
      "TP: 2650.0 TN: 6441.0 FP: 280.0 FN: 108.0\n",
      "test Loss: 0.1396 Acc: 0.9528 Pre: 0.9105 Rec: 0.9435 F1: 0.9267 Time in epoch: 1594.1549\n",
      "TP: 2237.0 TN: 4905.0 FP: 220.0 FN: 134.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1481 Acc: 0.9476 Pre: 0.9198 Rec: 0.8997 F1: 0.9096 Time in epoch: 1461.7736\n",
      "TP: 16902.0 TN: 43870.0 FP: 1473.0 FN: 1885.0\n",
      "val Loss: 0.1105 Acc: 0.9632 Pre: 0.9161 Rec: 0.9616 F1: 0.9383 Time in epoch: 1529.3277\n",
      "TP: 2652.0 TN: 6478.0 FP: 243.0 FN: 106.0\n",
      "test Loss: 0.1364 Acc: 0.9550 Pre: 0.9202 Rec: 0.9393 F1: 0.9297 Time in epoch: 1583.2410\n",
      "TP: 2227.0 TN: 4932.0 FP: 193.0 FN: 144.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1499 Acc: 0.9479 Pre: 0.9190 Rec: 0.9016 F1: 0.9102 Time in epoch: 1461.4188\n",
      "TP: 16938.0 TN: 43851.0 FP: 1492.0 FN: 1849.0\n",
      "val Loss: 0.1038 Acc: 0.9654 Pre: 0.9263 Rec: 0.9572 F1: 0.9415 Time in epoch: 1528.8842\n",
      "TP: 2640.0 TN: 6511.0 FP: 210.0 FN: 118.0\n",
      "test Loss: 0.1363 Acc: 0.9566 Pre: 0.9277 Rec: 0.9359 F1: 0.9318 Time in epoch: 1582.9111\n",
      "TP: 2219.0 TN: 4952.0 FP: 173.0 FN: 152.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1485 Acc: 0.9460 Pre: 0.9173 Rec: 0.8964 F1: 0.9067 Time in epoch: 1459.6218\n",
      "TP: 16841.0 TN: 43824.0 FP: 1519.0 FN: 1946.0\n",
      "val Loss: 0.1238 Acc: 0.9569 Pre: 0.8964 Rec: 0.9630 F1: 0.9285 Time in epoch: 1527.1404\n",
      "TP: 2656.0 TN: 6414.0 FP: 307.0 FN: 102.0\n",
      "test Loss: 0.1450 Acc: 0.9526 Pre: 0.9094 Rec: 0.9443 F1: 0.9265 Time in epoch: 1581.0465\n",
      "TP: 2239.0 TN: 4902.0 FP: 223.0 FN: 132.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1484 Acc: 0.9476 Pre: 0.9200 Rec: 0.8994 F1: 0.9096 Time in epoch: 1470.5062\n",
      "TP: 16897.0 TN: 43874.0 FP: 1469.0 FN: 1890.0\n",
      "val Loss: 0.1021 Acc: 0.9684 Pre: 0.9392 Rec: 0.9529 F1: 0.9460 Time in epoch: 1538.1134\n",
      "TP: 2628.0 TN: 6551.0 FP: 170.0 FN: 130.0\n",
      "test Loss: 0.1355 Acc: 0.9568 Pre: 0.9361 Rec: 0.9266 F1: 0.9313 Time in epoch: 1592.2133\n",
      "TP: 2197.0 TN: 4975.0 FP: 150.0 FN: 174.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1501 Acc: 0.9456 Pre: 0.9164 Rec: 0.8962 F1: 0.9062 Time in epoch: 1463.3508\n",
      "TP: 16836.0 TN: 43807.0 FP: 1536.0 FN: 1951.0\n",
      "val Loss: 0.1041 Acc: 0.9662 Pre: 0.9274 Rec: 0.9590 F1: 0.9430 Time in epoch: 1530.9382\n",
      "TP: 2645.0 TN: 6514.0 FP: 207.0 FN: 113.0\n",
      "test Loss: 0.1364 Acc: 0.9558 Pre: 0.9271 Rec: 0.9338 F1: 0.9304 Time in epoch: 1584.9173\n",
      "TP: 2214.0 TN: 4951.0 FP: 174.0 FN: 157.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1505 Acc: 0.9470 Pre: 0.9186 Rec: 0.8988 F1: 0.9086 Time in epoch: 1461.5980\n",
      "TP: 16885.0 TN: 43846.0 FP: 1497.0 FN: 1902.0\n",
      "val Loss: 0.1120 Acc: 0.9624 Pre: 0.9167 Rec: 0.9579 F1: 0.9369 Time in epoch: 1529.1729\n",
      "TP: 2642.0 TN: 6481.0 FP: 240.0 FN: 116.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1366 Acc: 0.9545 Pre: 0.9240 Rec: 0.9329 F1: 0.9284 Time in epoch: 1583.3719\n",
      "TP: 2212.0 TN: 4943.0 FP: 182.0 FN: 159.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1495 Acc: 0.9475 Pre: 0.9203 Rec: 0.8987 F1: 0.9094 Time in epoch: 1463.1112\n",
      "TP: 16884.0 TN: 43880.0 FP: 1463.0 FN: 1903.0\n",
      "val Loss: 0.1092 Acc: 0.9635 Pre: 0.9193 Rec: 0.9587 F1: 0.9386 Time in epoch: 1530.6775\n",
      "TP: 2644.0 TN: 6489.0 FP: 232.0 FN: 114.0\n",
      "test Loss: 0.1353 Acc: 0.9554 Pre: 0.9235 Rec: 0.9367 F1: 0.9301 Time in epoch: 1584.5969\n",
      "TP: 2221.0 TN: 4941.0 FP: 184.0 FN: 150.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1508 Acc: 0.9467 Pre: 0.9167 Rec: 0.8997 F1: 0.9081 Time in epoch: 1473.4942\n",
      "TP: 16902.0 TN: 43807.0 FP: 1536.0 FN: 1885.0\n",
      "val Loss: 0.1098 Acc: 0.9637 Pre: 0.9191 Rec: 0.9598 F1: 0.9390 Time in epoch: 1540.5231\n",
      "TP: 2647.0 TN: 6488.0 FP: 233.0 FN: 111.0\n",
      "test Loss: 0.1384 Acc: 0.9538 Pre: 0.9182 Rec: 0.9376 F1: 0.9278 Time in epoch: 1594.0306\n",
      "TP: 2223.0 TN: 4927.0 FP: 198.0 FN: 148.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9471 Pre: 0.9198 Rec: 0.8979 F1: 0.9087 Time in epoch: 1463.9265\n",
      "TP: 16868.0 TN: 43872.0 FP: 1471.0 FN: 1919.0\n",
      "val Loss: 0.1139 Acc: 0.9612 Pre: 0.9101 Rec: 0.9616 F1: 0.9351 Time in epoch: 1530.8886\n",
      "TP: 2652.0 TN: 6459.0 FP: 262.0 FN: 106.0\n",
      "test Loss: 0.1377 Acc: 0.9558 Pre: 0.9187 Rec: 0.9439 F1: 0.9311 Time in epoch: 1584.5312\n",
      "TP: 2238.0 TN: 4927.0 FP: 198.0 FN: 133.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1473 Acc: 0.9482 Pre: 0.9202 Rec: 0.9014 F1: 0.9107 Time in epoch: 1469.1355\n",
      "TP: 16934.0 TN: 43874.0 FP: 1469.0 FN: 1853.0\n",
      "val Loss: 0.1154 Acc: 0.9611 Pre: 0.9120 Rec: 0.9587 F1: 0.9348 Time in epoch: 1536.2345\n",
      "TP: 2644.0 TN: 6466.0 FP: 255.0 FN: 114.0\n",
      "test Loss: 0.1413 Acc: 0.9540 Pre: 0.9176 Rec: 0.9388 F1: 0.9281 Time in epoch: 1589.9677\n",
      "TP: 2226.0 TN: 4925.0 FP: 200.0 FN: 145.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1472 Acc: 0.9473 Pre: 0.9192 Rec: 0.8992 F1: 0.9091 Time in epoch: 1466.6010\n",
      "TP: 16894.0 TN: 43858.0 FP: 1485.0 FN: 1893.0\n",
      "val Loss: 0.1096 Acc: 0.9635 Pre: 0.9211 Rec: 0.9565 F1: 0.9385 Time in epoch: 1533.7809\n",
      "TP: 2638.0 TN: 6495.0 FP: 226.0 FN: 120.0\n",
      "test Loss: 0.1386 Acc: 0.9542 Pre: 0.9250 Rec: 0.9308 F1: 0.9279 Time in epoch: 1587.5656\n",
      "TP: 2207.0 TN: 4946.0 FP: 179.0 FN: 164.0\n",
      "\n",
      "Training complete in 684m 6s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
