{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = 0.6     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/rekall_train.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, load_percentage = 1):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = sorted(list(set(videos))) # set of all videos\n",
    "        num_videos = int(len(videos) * load_percentage) # number of videos to use\n",
    "        videos = videos[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append('commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file, data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = 4,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 37813, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None, path=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f} Time in epoch: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1, time.time() - t_start))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "            if path is not None:\n",
    "                torch.save(model.state_dict(), os.path.join(path, 'seed_{}_epoch_{}.pth'.format(seed, epoch)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsundar/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2677 Acc: 0.8999 Pre: 0.8427 Rec: 0.8240 F1: 0.8332 Time in epoch: 908.2409\n",
      "TP: 9455.0 TN: 24573.0 FP: 1765.0 FN: 2020.0\n",
      "val Loss: 0.1082 Acc: 0.9651 Pre: 0.9411 Rec: 0.9387 F1: 0.9399 Time in epoch: 980.4906\n",
      "TP: 2589.0 TN: 6559.0 FP: 162.0 FN: 169.0\n",
      "test Loss: 0.1586 Acc: 0.9496 Pre: 0.9411 Rec: 0.8967 F1: 0.9184 Time in epoch: 1038.2466\n",
      "TP: 2126.0 TN: 4992.0 FP: 133.0 FN: 245.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2255 Acc: 0.9211 Pre: 0.8764 Rec: 0.8616 F1: 0.8690 Time in epoch: 899.9982\n",
      "TP: 9887.0 TN: 24944.0 FP: 1394.0 FN: 1588.0\n",
      "val Loss: 0.1178 Acc: 0.9594 Pre: 0.9136 Rec: 0.9503 F1: 0.9316 Time in epoch: 971.9950\n",
      "TP: 2621.0 TN: 6473.0 FP: 248.0 FN: 137.0\n",
      "test Loss: 0.1429 Acc: 0.9557 Pre: 0.9229 Rec: 0.9384 F1: 0.9306 Time in epoch: 1029.4122\n",
      "TP: 2225.0 TN: 4939.0 FP: 186.0 FN: 146.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2126 Acc: 0.9260 Pre: 0.8849 Rec: 0.8692 F1: 0.8770 Time in epoch: 901.3944\n",
      "TP: 9974.0 TN: 25041.0 FP: 1297.0 FN: 1501.0\n",
      "val Loss: 0.1110 Acc: 0.9651 Pre: 0.9280 Rec: 0.9540 F1: 0.9408 Time in epoch: 973.2751\n",
      "TP: 2631.0 TN: 6517.0 FP: 204.0 FN: 127.0\n",
      "test Loss: 0.1456 Acc: 0.9549 Pre: 0.9302 Rec: 0.9270 F1: 0.9286 Time in epoch: 1030.8591\n",
      "TP: 2198.0 TN: 4960.0 FP: 165.0 FN: 173.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2003 Acc: 0.9296 Pre: 0.8917 Rec: 0.8742 F1: 0.8829 Time in epoch: 902.7648\n",
      "TP: 10031.0 TN: 25120.0 FP: 1218.0 FN: 1444.0\n",
      "val Loss: 0.1223 Acc: 0.9542 Pre: 0.8897 Rec: 0.9619 F1: 0.9244 Time in epoch: 974.6834\n",
      "TP: 2653.0 TN: 6392.0 FP: 329.0 FN: 105.0\n",
      "test Loss: 0.1529 Acc: 0.9430 Pre: 0.8839 Rec: 0.9439 F1: 0.9129 Time in epoch: 1032.8482\n",
      "TP: 2238.0 TN: 4831.0 FP: 294.0 FN: 133.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1916 Acc: 0.9337 Pre: 0.8991 Rec: 0.8804 F1: 0.8897 Time in epoch: 902.5214\n",
      "TP: 10103.0 TN: 25204.0 FP: 1134.0 FN: 1372.0\n",
      "val Loss: 0.1122 Acc: 0.9615 Pre: 0.9250 Rec: 0.9442 F1: 0.9345 Time in epoch: 974.3825\n",
      "TP: 2604.0 TN: 6510.0 FP: 211.0 FN: 154.0\n",
      "test Loss: 0.1429 Acc: 0.9542 Pre: 0.9367 Rec: 0.9173 F1: 0.9269 Time in epoch: 1031.8567\n",
      "TP: 2175.0 TN: 4978.0 FP: 147.0 FN: 196.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1855 Acc: 0.9349 Pre: 0.9020 Rec: 0.8811 F1: 0.8915 Time in epoch: 900.6807\n",
      "TP: 10111.0 TN: 25240.0 FP: 1098.0 FN: 1364.0\n",
      "val Loss: 0.1068 Acc: 0.9671 Pre: 0.9570 Rec: 0.9286 F1: 0.9426 Time in epoch: 972.6302\n",
      "TP: 2561.0 TN: 6606.0 FP: 115.0 FN: 197.0\n",
      "test Loss: 0.1532 Acc: 0.9538 Pre: 0.9530 Rec: 0.8984 F1: 0.9249 Time in epoch: 1030.1395\n",
      "TP: 2130.0 TN: 5020.0 FP: 105.0 FN: 241.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1662 Acc: 0.9412 Pre: 0.9101 Rec: 0.8946 F1: 0.9023 Time in epoch: 897.8417\n",
      "TP: 10266.0 TN: 25324.0 FP: 1014.0 FN: 1209.0\n",
      "val Loss: 0.1314 Acc: 0.9474 Pre: 0.8692 Rec: 0.9641 F1: 0.9142 Time in epoch: 969.8749\n",
      "TP: 2659.0 TN: 6321.0 FP: 400.0 FN: 99.0\n",
      "test Loss: 0.1464 Acc: 0.9534 Pre: 0.9140 Rec: 0.9414 F1: 0.9275 Time in epoch: 1027.3584\n",
      "TP: 2232.0 TN: 4915.0 FP: 210.0 FN: 139.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1624 Acc: 0.9433 Pre: 0.9162 Rec: 0.8951 F1: 0.9055 Time in epoch: 898.8552\n",
      "TP: 10271.0 TN: 25399.0 FP: 939.0 FN: 1204.0\n",
      "val Loss: 0.1215 Acc: 0.9540 Pre: 0.8912 Rec: 0.9590 F1: 0.9239 Time in epoch: 970.7683\n",
      "TP: 2645.0 TN: 6398.0 FP: 323.0 FN: 113.0\n",
      "test Loss: 0.1430 Acc: 0.9550 Pre: 0.9245 Rec: 0.9342 F1: 0.9293 Time in epoch: 1028.1897\n",
      "TP: 2215.0 TN: 4944.0 FP: 181.0 FN: 156.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1567 Acc: 0.9463 Pre: 0.9208 Rec: 0.9007 F1: 0.9106 Time in epoch: 900.8748\n",
      "TP: 10335.0 TN: 25449.0 FP: 889.0 FN: 1140.0\n",
      "val Loss: 0.1161 Acc: 0.9564 Pre: 0.9033 Rec: 0.9521 F1: 0.9271 Time in epoch: 972.7931\n",
      "TP: 2626.0 TN: 6440.0 FP: 281.0 FN: 132.0\n",
      "test Loss: 0.1426 Acc: 0.9564 Pre: 0.9316 Rec: 0.9304 F1: 0.9310 Time in epoch: 1030.2909\n",
      "TP: 2206.0 TN: 4963.0 FP: 162.0 FN: 165.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1580 Acc: 0.9445 Pre: 0.9178 Rec: 0.8975 F1: 0.9076 Time in epoch: 902.1699\n",
      "TP: 10299.0 TN: 25416.0 FP: 922.0 FN: 1176.0\n",
      "val Loss: 0.1097 Acc: 0.9595 Pre: 0.9110 Rec: 0.9540 F1: 0.9320 Time in epoch: 974.0804\n",
      "TP: 2631.0 TN: 6464.0 FP: 257.0 FN: 127.0\n",
      "test Loss: 0.1443 Acc: 0.9554 Pre: 0.9288 Rec: 0.9304 F1: 0.9296 Time in epoch: 1031.5345\n",
      "TP: 2206.0 TN: 4956.0 FP: 169.0 FN: 165.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9452 Pre: 0.9196 Rec: 0.8978 F1: 0.9085 Time in epoch: 901.2165\n",
      "TP: 10302.0 TN: 25437.0 FP: 901.0 FN: 1173.0\n",
      "val Loss: 0.1243 Acc: 0.9504 Pre: 0.8806 Rec: 0.9598 F1: 0.9185 Time in epoch: 973.1444\n",
      "TP: 2647.0 TN: 6362.0 FP: 359.0 FN: 111.0\n",
      "test Loss: 0.1489 Acc: 0.9525 Pre: 0.9107 Rec: 0.9422 F1: 0.9262 Time in epoch: 1030.5967\n",
      "TP: 2234.0 TN: 4906.0 FP: 219.0 FN: 137.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1518 Acc: 0.9453 Pre: 0.9175 Rec: 0.9008 F1: 0.9091 Time in epoch: 900.4137\n",
      "TP: 10337.0 TN: 25409.0 FP: 929.0 FN: 1138.0\n",
      "val Loss: 0.1262 Acc: 0.9523 Pre: 0.8854 Rec: 0.9605 F1: 0.9214 Time in epoch: 972.3610\n",
      "TP: 2649.0 TN: 6378.0 FP: 343.0 FN: 109.0\n",
      "test Loss: 0.1496 Acc: 0.9530 Pre: 0.9153 Rec: 0.9384 F1: 0.9267 Time in epoch: 1029.8648\n",
      "TP: 2225.0 TN: 4919.0 FP: 206.0 FN: 146.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1525 Acc: 0.9459 Pre: 0.9207 Rec: 0.8991 F1: 0.9097 Time in epoch: 901.5997\n",
      "TP: 10317.0 TN: 25449.0 FP: 889.0 FN: 1158.0\n",
      "val Loss: 0.1307 Acc: 0.9493 Pre: 0.8754 Rec: 0.9627 F1: 0.9169 Time in epoch: 973.6119\n",
      "TP: 2655.0 TN: 6343.0 FP: 378.0 FN: 103.0\n",
      "test Loss: 0.1486 Acc: 0.9530 Pre: 0.9142 Rec: 0.9397 F1: 0.9268 Time in epoch: 1031.0624\n",
      "TP: 2228.0 TN: 4916.0 FP: 209.0 FN: 143.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1517 Acc: 0.9459 Pre: 0.9195 Rec: 0.9004 F1: 0.9099 Time in epoch: 901.8701\n",
      "TP: 10332.0 TN: 25434.0 FP: 904.0 FN: 1143.0\n",
      "val Loss: 0.1324 Acc: 0.9480 Pre: 0.8734 Rec: 0.9605 F1: 0.9149 Time in epoch: 973.8194\n",
      "TP: 2649.0 TN: 6337.0 FP: 384.0 FN: 109.0\n",
      "test Loss: 0.1492 Acc: 0.9526 Pre: 0.9141 Rec: 0.9384 F1: 0.9261 Time in epoch: 1031.3079\n",
      "TP: 2225.0 TN: 4916.0 FP: 209.0 FN: 146.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9471 Pre: 0.9228 Rec: 0.9011 F1: 0.9118 Time in epoch: 903.5492\n",
      "TP: 10340.0 TN: 25473.0 FP: 865.0 FN: 1135.0\n",
      "val Loss: 0.1416 Acc: 0.9427 Pre: 0.8560 Rec: 0.9656 F1: 0.9075 Time in epoch: 975.4463\n",
      "TP: 2663.0 TN: 6273.0 FP: 448.0 FN: 95.0\n",
      "test Loss: 0.1549 Acc: 0.9502 Pre: 0.9045 Rec: 0.9422 F1: 0.9229 Time in epoch: 1032.8971\n",
      "TP: 2234.0 TN: 4889.0 FP: 236.0 FN: 137.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1479 Acc: 0.9482 Pre: 0.9221 Rec: 0.9059 F1: 0.9139 Time in epoch: 902.7526\n",
      "TP: 10395.0 TN: 25460.0 FP: 878.0 FN: 1080.0\n",
      "val Loss: 0.1285 Acc: 0.9492 Pre: 0.8776 Rec: 0.9590 F1: 0.9165 Time in epoch: 974.9005\n",
      "TP: 2645.0 TN: 6352.0 FP: 369.0 FN: 113.0\n",
      "test Loss: 0.1481 Acc: 0.9537 Pre: 0.9189 Rec: 0.9363 F1: 0.9275 Time in epoch: 1032.3854\n",
      "TP: 2220.0 TN: 4929.0 FP: 196.0 FN: 151.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1461 Acc: 0.9487 Pre: 0.9248 Rec: 0.9047 F1: 0.9146 Time in epoch: 901.0393\n",
      "TP: 10381.0 TN: 25494.0 FP: 844.0 FN: 1094.0\n",
      "val Loss: 0.1234 Acc: 0.9523 Pre: 0.8864 Rec: 0.9590 F1: 0.9213 Time in epoch: 973.1147\n",
      "TP: 2645.0 TN: 6382.0 FP: 339.0 FN: 113.0\n",
      "test Loss: 0.1470 Acc: 0.9545 Pre: 0.9222 Rec: 0.9350 F1: 0.9286 Time in epoch: 1030.6291\n",
      "TP: 2217.0 TN: 4938.0 FP: 187.0 FN: 154.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1458 Acc: 0.9487 Pre: 0.9241 Rec: 0.9055 F1: 0.9147 Time in epoch: 901.1195\n",
      "TP: 10391.0 TN: 25484.0 FP: 854.0 FN: 1084.0\n",
      "val Loss: 0.1300 Acc: 0.9490 Pre: 0.8763 Rec: 0.9605 F1: 0.9165 Time in epoch: 973.0804\n",
      "TP: 2649.0 TN: 6347.0 FP: 374.0 FN: 109.0\n",
      "test Loss: 0.1500 Acc: 0.9513 Pre: 0.9107 Rec: 0.9380 F1: 0.9242 Time in epoch: 1030.5117\n",
      "TP: 2224.0 TN: 4907.0 FP: 218.0 FN: 147.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1473 Acc: 0.9477 Pre: 0.9226 Rec: 0.9034 F1: 0.9129 Time in epoch: 901.5284\n",
      "TP: 10367.0 TN: 25468.0 FP: 870.0 FN: 1108.0\n",
      "val Loss: 0.1346 Acc: 0.9463 Pre: 0.8664 Rec: 0.9641 F1: 0.9126 Time in epoch: 973.5024\n",
      "TP: 2659.0 TN: 6311.0 FP: 410.0 FN: 99.0\n",
      "test Loss: 0.1520 Acc: 0.9500 Pre: 0.9054 Rec: 0.9401 F1: 0.9224 Time in epoch: 1030.9875\n",
      "TP: 2229.0 TN: 4892.0 FP: 233.0 FN: 142.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1466 Acc: 0.9480 Pre: 0.9216 Rec: 0.9058 F1: 0.9136 Time in epoch: 901.3669\n",
      "TP: 10394.0 TN: 25454.0 FP: 884.0 FN: 1081.0\n",
      "val Loss: 0.1116 Acc: 0.9586 Pre: 0.9116 Rec: 0.9500 F1: 0.9304 Time in epoch: 973.3647\n",
      "TP: 2620.0 TN: 6467.0 FP: 254.0 FN: 138.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1459 Acc: 0.9561 Pre: 0.9378 Rec: 0.9224 F1: 0.9300 Time in epoch: 1030.8805\n",
      "TP: 2187.0 TN: 4980.0 FP: 145.0 FN: 184.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1460 Acc: 0.9488 Pre: 0.9263 Rec: 0.9033 F1: 0.9146 Time in epoch: 901.5547\n",
      "TP: 10365.0 TN: 25513.0 FP: 825.0 FN: 1110.0\n",
      "val Loss: 0.1329 Acc: 0.9477 Pre: 0.8708 Rec: 0.9630 F1: 0.9146 Time in epoch: 973.4898\n",
      "TP: 2656.0 TN: 6327.0 FP: 394.0 FN: 102.0\n",
      "test Loss: 0.1514 Acc: 0.9514 Pre: 0.9118 Rec: 0.9372 F1: 0.9243 Time in epoch: 1030.9052\n",
      "TP: 2222.0 TN: 4910.0 FP: 215.0 FN: 149.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1452 Acc: 0.9490 Pre: 0.9275 Rec: 0.9025 F1: 0.9148 Time in epoch: 901.2817\n",
      "TP: 10356.0 TN: 25529.0 FP: 809.0 FN: 1119.0\n",
      "val Loss: 0.1313 Acc: 0.9487 Pre: 0.8757 Rec: 0.9601 F1: 0.9159 Time in epoch: 973.1722\n",
      "TP: 2648.0 TN: 6345.0 FP: 376.0 FN: 110.0\n",
      "test Loss: 0.1502 Acc: 0.9514 Pre: 0.9135 Rec: 0.9350 F1: 0.9241 Time in epoch: 1030.6041\n",
      "TP: 2217.0 TN: 4915.0 FP: 210.0 FN: 154.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1493 Acc: 0.9464 Pre: 0.9210 Rec: 0.9005 F1: 0.9106 Time in epoch: 902.4711\n",
      "TP: 10333.0 TN: 25452.0 FP: 886.0 FN: 1142.0\n",
      "val Loss: 0.1274 Acc: 0.9509 Pre: 0.8813 Rec: 0.9608 F1: 0.9193 Time in epoch: 974.4898\n",
      "TP: 2650.0 TN: 6364.0 FP: 357.0 FN: 108.0\n",
      "test Loss: 0.1479 Acc: 0.9530 Pre: 0.9163 Rec: 0.9372 F1: 0.9266 Time in epoch: 1031.9280\n",
      "TP: 2222.0 TN: 4922.0 FP: 203.0 FN: 149.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1483 Acc: 0.9472 Pre: 0.9213 Rec: 0.9030 F1: 0.9121 Time in epoch: 899.1769\n",
      "TP: 10362.0 TN: 25453.0 FP: 885.0 FN: 1113.0\n",
      "val Loss: 0.1401 Acc: 0.9441 Pre: 0.8594 Rec: 0.9659 F1: 0.9095 Time in epoch: 971.3050\n",
      "TP: 2664.0 TN: 6285.0 FP: 436.0 FN: 94.0\n",
      "test Loss: 0.1566 Acc: 0.9488 Pre: 0.8995 Rec: 0.9435 F1: 0.9210 Time in epoch: 1028.8950\n",
      "TP: 2237.0 TN: 4875.0 FP: 250.0 FN: 134.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1491 Acc: 0.9471 Pre: 0.9217 Rec: 0.9022 F1: 0.9119 Time in epoch: 897.0063\n",
      "TP: 10353.0 TN: 25459.0 FP: 879.0 FN: 1122.0\n",
      "val Loss: 0.1358 Acc: 0.9460 Pre: 0.8665 Rec: 0.9627 F1: 0.9121 Time in epoch: 969.1147\n",
      "TP: 2655.0 TN: 6312.0 FP: 409.0 FN: 103.0\n",
      "test Loss: 0.1526 Acc: 0.9506 Pre: 0.9082 Rec: 0.9388 F1: 0.9233 Time in epoch: 1026.6553\n",
      "TP: 2226.0 TN: 4900.0 FP: 225.0 FN: 145.0\n",
      "\n",
      "Training complete in 429m 44s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_b16_rekall_train_60/'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False, path=path)\n",
    "        # torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
