{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'bernie_interviews/data/train.txt'\n",
    "val_file = 'bernie_interviews/data/val.txt'\n",
    "test_file = 'bernie_interviews/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('bernie_interviews/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train']),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train']),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val']),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 6835, 'val_train': 3026, 'val': 3026, 'test': 3563}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9699 Pre: 0.8085 Rec: 0.2879 F1: 0.4246\n",
      "TP: 76.0 TN: 6553.0 FP: 18.0 FN: 188.0\n",
      "val Loss: 0.0506 Acc: 0.9874 Pre: 0.7922 Rec: 0.7349 F1: 0.7625\n",
      "TP: 61.0 TN: 2927.0 FP: 16.0 FN: 22.0\n",
      "test Loss: 0.0455 Acc: 0.9846 Pre: 0.7600 Rec: 0.7103 F1: 0.7343\n",
      "TP: 76.0 TN: 3432.0 FP: 24.0 FN: 31.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.0744 Acc: 0.9823 Pre: 0.8950 Rec: 0.6136 F1: 0.7281\n",
      "TP: 162.0 TN: 6552.0 FP: 19.0 FN: 102.0\n",
      "val Loss: 0.1319 Acc: 0.9617 Pre: 0.4108 Rec: 0.9157 F1: 0.5672\n",
      "TP: 76.0 TN: 2834.0 FP: 109.0 FN: 7.0\n",
      "test Loss: 0.1249 Acc: 0.9635 Pre: 0.4502 Rec: 0.9720 F1: 0.6154\n",
      "TP: 104.0 TN: 3329.0 FP: 127.0 FN: 3.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0676 Acc: 0.9830 Pre: 0.8978 Rec: 0.6326 F1: 0.7422\n",
      "TP: 167.0 TN: 6552.0 FP: 19.0 FN: 97.0\n",
      "val Loss: 0.0564 Acc: 0.9861 Pre: 0.6881 Rec: 0.9036 F1: 0.7812\n",
      "TP: 75.0 TN: 2909.0 FP: 34.0 FN: 8.0\n",
      "test Loss: 0.0605 Acc: 0.9832 Pre: 0.6715 Rec: 0.8598 F1: 0.7541\n",
      "TP: 92.0 TN: 3411.0 FP: 45.0 FN: 15.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0660 Acc: 0.9843 Pre: 0.9153 Rec: 0.6553 F1: 0.7638\n",
      "TP: 173.0 TN: 6555.0 FP: 16.0 FN: 91.0\n",
      "val Loss: 0.0609 Acc: 0.9845 Pre: 0.6579 Rec: 0.9036 F1: 0.7614\n",
      "TP: 75.0 TN: 2904.0 FP: 39.0 FN: 8.0\n",
      "test Loss: 0.0539 Acc: 0.9882 Pre: 0.7338 Rec: 0.9533 F1: 0.8293\n",
      "TP: 102.0 TN: 3419.0 FP: 37.0 FN: 5.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0586 Acc: 0.9848 Pre: 0.9211 Rec: 0.6629 F1: 0.7709\n",
      "TP: 175.0 TN: 6556.0 FP: 15.0 FN: 89.0\n",
      "val Loss: 0.0471 Acc: 0.9891 Pre: 0.7500 Rec: 0.9036 F1: 0.8197\n",
      "TP: 75.0 TN: 2918.0 FP: 25.0 FN: 8.0\n",
      "test Loss: 0.0329 Acc: 0.9907 Pre: 0.7891 Rec: 0.9439 F1: 0.8596\n",
      "TP: 101.0 TN: 3429.0 FP: 27.0 FN: 6.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0548 Acc: 0.9858 Pre: 0.9113 Rec: 0.7008 F1: 0.7923\n",
      "TP: 185.0 TN: 6553.0 FP: 18.0 FN: 79.0\n",
      "val Loss: 0.0432 Acc: 0.9914 Pre: 0.8202 Rec: 0.8795 F1: 0.8488\n",
      "TP: 73.0 TN: 2927.0 FP: 16.0 FN: 10.0\n",
      "test Loss: 0.0337 Acc: 0.9927 Pre: 0.8403 Rec: 0.9346 F1: 0.8850\n",
      "TP: 100.0 TN: 3437.0 FP: 19.0 FN: 7.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0421 Acc: 0.9889 Pre: 0.9519 Rec: 0.7500 F1: 0.8390\n",
      "TP: 198.0 TN: 6561.0 FP: 10.0 FN: 66.0\n",
      "val Loss: 0.0401 Acc: 0.9907 Pre: 0.8022 Rec: 0.8795 F1: 0.8391\n",
      "TP: 73.0 TN: 2925.0 FP: 18.0 FN: 10.0\n",
      "test Loss: 0.0322 Acc: 0.9910 Pre: 0.8049 Rec: 0.9252 F1: 0.8609\n",
      "TP: 99.0 TN: 3432.0 FP: 24.0 FN: 8.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0404 Acc: 0.9883 Pre: 0.9510 Rec: 0.7348 F1: 0.8291\n",
      "TP: 194.0 TN: 6561.0 FP: 10.0 FN: 70.0\n",
      "val Loss: 0.0430 Acc: 0.9884 Pre: 0.7400 Rec: 0.8916 F1: 0.8087\n",
      "TP: 74.0 TN: 2917.0 FP: 26.0 FN: 9.0\n",
      "test Loss: 0.0378 Acc: 0.9891 Pre: 0.7576 Rec: 0.9346 F1: 0.8368\n",
      "TP: 100.0 TN: 3424.0 FP: 32.0 FN: 7.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0431 Acc: 0.9898 Pre: 0.9575 Rec: 0.7689 F1: 0.8529\n",
      "TP: 203.0 TN: 6562.0 FP: 9.0 FN: 61.0\n",
      "val Loss: 0.0378 Acc: 0.9907 Pre: 0.8235 Rec: 0.8434 F1: 0.8333\n",
      "TP: 70.0 TN: 2928.0 FP: 15.0 FN: 13.0\n",
      "test Loss: 0.0292 Acc: 0.9916 Pre: 0.8291 Rec: 0.9065 F1: 0.8661\n",
      "TP: 97.0 TN: 3436.0 FP: 20.0 FN: 10.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0394 Acc: 0.9896 Pre: 0.9707 Rec: 0.7538 F1: 0.8486\n",
      "TP: 199.0 TN: 6565.0 FP: 6.0 FN: 65.0\n",
      "val Loss: 0.0437 Acc: 0.9881 Pre: 0.7374 Rec: 0.8795 F1: 0.8022\n",
      "TP: 73.0 TN: 2917.0 FP: 26.0 FN: 10.0\n",
      "test Loss: 0.0363 Acc: 0.9899 Pre: 0.7752 Rec: 0.9346 F1: 0.8475\n",
      "TP: 100.0 TN: 3427.0 FP: 29.0 FN: 7.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0369 Acc: 0.9890 Pre: 0.9437 Rec: 0.7614 F1: 0.8428\n",
      "TP: 201.0 TN: 6559.0 FP: 12.0 FN: 63.0\n",
      "val Loss: 0.0403 Acc: 0.9904 Pre: 0.7872 Rec: 0.8916 F1: 0.8362\n",
      "TP: 74.0 TN: 2923.0 FP: 20.0 FN: 9.0\n",
      "test Loss: 0.0341 Acc: 0.9905 Pre: 0.8067 Rec: 0.8972 F1: 0.8496\n",
      "TP: 96.0 TN: 3433.0 FP: 23.0 FN: 11.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.9914 Pre: 0.9638 Rec: 0.8068 F1: 0.8784\n",
      "TP: 213.0 TN: 6563.0 FP: 8.0 FN: 51.0\n",
      "val Loss: 0.0434 Acc: 0.9901 Pre: 0.7789 Rec: 0.8916 F1: 0.8315\n",
      "TP: 74.0 TN: 2922.0 FP: 21.0 FN: 9.0\n",
      "test Loss: 0.0371 Acc: 0.9910 Pre: 0.7953 Rec: 0.9439 F1: 0.8632\n",
      "TP: 101.0 TN: 3430.0 FP: 26.0 FN: 6.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0392 Acc: 0.9903 Pre: 0.9626 Rec: 0.7803 F1: 0.8619\n",
      "TP: 206.0 TN: 6563.0 FP: 8.0 FN: 58.0\n",
      "val Loss: 0.0526 Acc: 0.9878 Pre: 0.7170 Rec: 0.9157 F1: 0.8042\n",
      "TP: 76.0 TN: 2913.0 FP: 30.0 FN: 7.0\n",
      "test Loss: 0.0456 Acc: 0.9865 Pre: 0.7063 Rec: 0.9439 F1: 0.8080\n",
      "TP: 101.0 TN: 3414.0 FP: 42.0 FN: 6.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9909 Pre: 0.9469 Rec: 0.8106 F1: 0.8735\n",
      "TP: 214.0 TN: 6559.0 FP: 12.0 FN: 50.0\n",
      "val Loss: 0.0413 Acc: 0.9911 Pre: 0.8043 Rec: 0.8916 F1: 0.8457\n",
      "TP: 74.0 TN: 2925.0 FP: 18.0 FN: 9.0\n",
      "test Loss: 0.0349 Acc: 0.9902 Pre: 0.7857 Rec: 0.9252 F1: 0.8498\n",
      "TP: 99.0 TN: 3429.0 FP: 27.0 FN: 8.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9906 Pre: 0.9386 Rec: 0.8106 F1: 0.8699\n",
      "TP: 214.0 TN: 6557.0 FP: 14.0 FN: 50.0\n",
      "val Loss: 0.0401 Acc: 0.9907 Pre: 0.7957 Rec: 0.8916 F1: 0.8409\n",
      "TP: 74.0 TN: 2924.0 FP: 19.0 FN: 9.0\n",
      "test Loss: 0.0346 Acc: 0.9899 Pre: 0.7934 Rec: 0.8972 F1: 0.8421\n",
      "TP: 96.0 TN: 3431.0 FP: 25.0 FN: 11.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0321 Acc: 0.9896 Pre: 0.9531 Rec: 0.7689 F1: 0.8512\n",
      "TP: 203.0 TN: 6561.0 FP: 10.0 FN: 61.0\n",
      "val Loss: 0.0417 Acc: 0.9917 Pre: 0.8152 Rec: 0.9036 F1: 0.8571\n",
      "TP: 75.0 TN: 2926.0 FP: 17.0 FN: 8.0\n",
      "test Loss: 0.0372 Acc: 0.9902 Pre: 0.7812 Rec: 0.9346 F1: 0.8511\n",
      "TP: 100.0 TN: 3428.0 FP: 28.0 FN: 7.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9905 Pre: 0.9628 Rec: 0.7841 F1: 0.8643\n",
      "TP: 207.0 TN: 6563.0 FP: 8.0 FN: 57.0\n",
      "val Loss: 0.0380 Acc: 0.9927 Pre: 0.8506 Rec: 0.8916 F1: 0.8706\n",
      "TP: 74.0 TN: 2930.0 FP: 13.0 FN: 9.0\n",
      "test Loss: 0.0320 Acc: 0.9910 Pre: 0.8151 Rec: 0.9065 F1: 0.8584\n",
      "TP: 97.0 TN: 3434.0 FP: 22.0 FN: 10.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.9920 Pre: 0.9686 Rec: 0.8182 F1: 0.8871\n",
      "TP: 216.0 TN: 6564.0 FP: 7.0 FN: 48.0\n",
      "val Loss: 0.0444 Acc: 0.9894 Pre: 0.7629 Rec: 0.8916 F1: 0.8222\n",
      "TP: 74.0 TN: 2920.0 FP: 23.0 FN: 9.0\n",
      "test Loss: 0.0356 Acc: 0.9896 Pre: 0.7692 Rec: 0.9346 F1: 0.8439\n",
      "TP: 100.0 TN: 3426.0 FP: 30.0 FN: 7.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0346 Acc: 0.9903 Pre: 0.9420 Rec: 0.7992 F1: 0.8648\n",
      "TP: 211.0 TN: 6558.0 FP: 13.0 FN: 53.0\n",
      "val Loss: 0.0536 Acc: 0.9874 Pre: 0.7103 Rec: 0.9157 F1: 0.8000\n",
      "TP: 76.0 TN: 2912.0 FP: 31.0 FN: 7.0\n",
      "test Loss: 0.0474 Acc: 0.9862 Pre: 0.7042 Rec: 0.9346 F1: 0.8032\n",
      "TP: 100.0 TN: 3414.0 FP: 42.0 FN: 7.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0283 Acc: 0.9925 Pre: 0.9610 Rec: 0.8409 F1: 0.8970\n",
      "TP: 222.0 TN: 6562.0 FP: 9.0 FN: 42.0\n",
      "val Loss: 0.0456 Acc: 0.9894 Pre: 0.7525 Rec: 0.9157 F1: 0.8261\n",
      "TP: 76.0 TN: 2918.0 FP: 25.0 FN: 7.0\n",
      "test Loss: 0.0401 Acc: 0.9882 Pre: 0.7372 Rec: 0.9439 F1: 0.8279\n",
      "TP: 101.0 TN: 3420.0 FP: 36.0 FN: 6.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0298 Acc: 0.9918 Pre: 0.9727 Rec: 0.8106 F1: 0.8843\n",
      "TP: 214.0 TN: 6565.0 FP: 6.0 FN: 50.0\n",
      "val Loss: 0.0366 Acc: 0.9924 Pre: 0.8488 Rec: 0.8795 F1: 0.8639\n",
      "TP: 73.0 TN: 2930.0 FP: 13.0 FN: 10.0\n",
      "test Loss: 0.0294 Acc: 0.9916 Pre: 0.8407 Rec: 0.8879 F1: 0.8636\n",
      "TP: 95.0 TN: 3438.0 FP: 18.0 FN: 12.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0354 Acc: 0.9906 Pre: 0.9630 Rec: 0.7879 F1: 0.8667\n",
      "TP: 208.0 TN: 6563.0 FP: 8.0 FN: 56.0\n",
      "val Loss: 0.0371 Acc: 0.9914 Pre: 0.8202 Rec: 0.8795 F1: 0.8488\n",
      "TP: 73.0 TN: 2927.0 FP: 16.0 FN: 10.0\n",
      "test Loss: 0.0304 Acc: 0.9910 Pre: 0.8261 Rec: 0.8879 F1: 0.8559\n",
      "TP: 95.0 TN: 3436.0 FP: 20.0 FN: 12.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0294 Acc: 0.9912 Pre: 0.9722 Rec: 0.7955 F1: 0.8750\n",
      "TP: 210.0 TN: 6565.0 FP: 6.0 FN: 54.0\n",
      "val Loss: 0.0373 Acc: 0.9931 Pre: 0.8605 Rec: 0.8916 F1: 0.8757\n",
      "TP: 74.0 TN: 2931.0 FP: 12.0 FN: 9.0\n",
      "test Loss: 0.0315 Acc: 0.9913 Pre: 0.8333 Rec: 0.8879 F1: 0.8597\n",
      "TP: 95.0 TN: 3437.0 FP: 19.0 FN: 12.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0373 Acc: 0.9898 Pre: 0.9619 Rec: 0.7652 F1: 0.8523\n",
      "TP: 202.0 TN: 6563.0 FP: 8.0 FN: 62.0\n",
      "val Loss: 0.0427 Acc: 0.9907 Pre: 0.7895 Rec: 0.9036 F1: 0.8427\n",
      "TP: 75.0 TN: 2923.0 FP: 20.0 FN: 8.0\n",
      "test Loss: 0.0373 Acc: 0.9893 Pre: 0.7634 Rec: 0.9346 F1: 0.8403\n",
      "TP: 100.0 TN: 3425.0 FP: 31.0 FN: 7.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0274 Acc: 0.9930 Pre: 0.9909 Rec: 0.8258 F1: 0.9008\n",
      "TP: 218.0 TN: 6569.0 FP: 2.0 FN: 46.0\n",
      "val Loss: 0.0405 Acc: 0.9911 Pre: 0.7979 Rec: 0.9036 F1: 0.8475\n",
      "TP: 75.0 TN: 2924.0 FP: 19.0 FN: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0334 Acc: 0.9902 Pre: 0.7857 Rec: 0.9252 F1: 0.8498\n",
      "TP: 99.0 TN: 3429.0 FP: 27.0 FN: 8.0\n",
      "\n",
      "Training complete in 47m 18s\n",
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.1098 Acc: 0.9710 Pre: 0.8438 Rec: 0.3068 F1: 0.4500\n",
      "TP: 81.0 TN: 6556.0 FP: 15.0 FN: 183.0\n",
      "val Loss: 0.0596 Acc: 0.9861 Pre: 0.6952 Rec: 0.8795 F1: 0.7766\n",
      "TP: 73.0 TN: 2911.0 FP: 32.0 FN: 10.0\n",
      "test Loss: 0.0476 Acc: 0.9882 Pre: 0.7519 Rec: 0.9065 F1: 0.8220\n",
      "TP: 97.0 TN: 3424.0 FP: 32.0 FN: 10.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.0743 Acc: 0.9827 Pre: 0.9244 Rec: 0.6023 F1: 0.7294\n",
      "TP: 159.0 TN: 6558.0 FP: 13.0 FN: 105.0\n",
      "val Loss: 0.0479 Acc: 0.9898 Pre: 0.8333 Rec: 0.7831 F1: 0.8075\n",
      "TP: 65.0 TN: 2930.0 FP: 13.0 FN: 18.0\n",
      "test Loss: 0.0378 Acc: 0.9919 Pre: 0.8900 Rec: 0.8318 F1: 0.8599\n",
      "TP: 89.0 TN: 3445.0 FP: 11.0 FN: 18.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0746 Acc: 0.9804 Pre: 0.8652 Rec: 0.5833 F1: 0.6968\n",
      "TP: 154.0 TN: 6547.0 FP: 24.0 FN: 110.0\n",
      "val Loss: 0.0657 Acc: 0.9861 Pre: 0.7030 Rec: 0.8554 F1: 0.7717\n",
      "TP: 71.0 TN: 2913.0 FP: 30.0 FN: 12.0\n",
      "test Loss: 0.0395 Acc: 0.9921 Pre: 0.8319 Rec: 0.9252 F1: 0.8761\n",
      "TP: 99.0 TN: 3436.0 FP: 20.0 FN: 8.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0650 Acc: 0.9842 Pre: 0.9286 Rec: 0.6402 F1: 0.7578\n",
      "TP: 169.0 TN: 6558.0 FP: 13.0 FN: 95.0\n",
      "val Loss: 0.0390 Acc: 0.9941 Pre: 0.8824 Rec: 0.9036 F1: 0.8929\n",
      "TP: 75.0 TN: 2933.0 FP: 10.0 FN: 8.0\n",
      "test Loss: 0.0379 Acc: 0.9919 Pre: 0.9149 Rec: 0.8037 F1: 0.8557\n",
      "TP: 86.0 TN: 3448.0 FP: 8.0 FN: 21.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0614 Acc: 0.9861 Pre: 0.9471 Rec: 0.6780 F1: 0.7903\n",
      "TP: 179.0 TN: 6561.0 FP: 10.0 FN: 85.0\n",
      "val Loss: 0.0782 Acc: 0.9812 Pre: 0.6016 Rec: 0.9277 F1: 0.7299\n",
      "TP: 77.0 TN: 2892.0 FP: 51.0 FN: 6.0\n",
      "test Loss: 0.0505 Acc: 0.9846 Pre: 0.6806 Rec: 0.9159 F1: 0.7809\n",
      "TP: 98.0 TN: 3410.0 FP: 46.0 FN: 9.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0593 Acc: 0.9849 Pre: 0.9259 Rec: 0.6629 F1: 0.7726\n",
      "TP: 175.0 TN: 6557.0 FP: 14.0 FN: 89.0\n",
      "val Loss: 0.0557 Acc: 0.9871 Pre: 0.7037 Rec: 0.9157 F1: 0.7958\n",
      "TP: 76.0 TN: 2911.0 FP: 32.0 FN: 7.0\n",
      "test Loss: 0.0662 Acc: 0.9860 Pre: 0.7714 Rec: 0.7570 F1: 0.7642\n",
      "TP: 81.0 TN: 3432.0 FP: 24.0 FN: 26.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0427 Acc: 0.9880 Pre: 0.9596 Rec: 0.7197 F1: 0.8225\n",
      "TP: 190.0 TN: 6563.0 FP: 8.0 FN: 74.0\n",
      "val Loss: 0.0482 Acc: 0.9884 Pre: 0.7308 Rec: 0.9157 F1: 0.8128\n",
      "TP: 76.0 TN: 2915.0 FP: 28.0 FN: 7.0\n",
      "test Loss: 0.0607 Acc: 0.9882 Pre: 0.8351 Rec: 0.7570 F1: 0.7941\n",
      "TP: 81.0 TN: 3440.0 FP: 16.0 FN: 26.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 0.9887 Pre: 0.9652 Rec: 0.7348 F1: 0.8344\n",
      "TP: 194.0 TN: 6564.0 FP: 7.0 FN: 70.0\n",
      "val Loss: 0.0562 Acc: 0.9874 Pre: 0.7103 Rec: 0.9157 F1: 0.8000\n",
      "TP: 76.0 TN: 2912.0 FP: 31.0 FN: 7.0\n",
      "test Loss: 0.0642 Acc: 0.9868 Pre: 0.7885 Rec: 0.7664 F1: 0.7773\n",
      "TP: 82.0 TN: 3434.0 FP: 22.0 FN: 25.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0355 Acc: 0.9901 Pre: 0.9667 Rec: 0.7689 F1: 0.8565\n",
      "TP: 203.0 TN: 6564.0 FP: 7.0 FN: 61.0\n",
      "val Loss: 0.0568 Acc: 0.9881 Pre: 0.7196 Rec: 0.9277 F1: 0.8105\n",
      "TP: 77.0 TN: 2913.0 FP: 30.0 FN: 6.0\n",
      "test Loss: 0.0618 Acc: 0.9857 Pre: 0.7500 Rec: 0.7850 F1: 0.7671\n",
      "TP: 84.0 TN: 3428.0 FP: 28.0 FN: 23.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0406 Acc: 0.9883 Pre: 0.9554 Rec: 0.7311 F1: 0.8283\n",
      "TP: 193.0 TN: 6562.0 FP: 9.0 FN: 71.0\n",
      "val Loss: 0.0656 Acc: 0.9851 Pre: 0.6667 Rec: 0.9157 F1: 0.7716\n",
      "TP: 76.0 TN: 2905.0 FP: 38.0 FN: 7.0\n",
      "test Loss: 0.0696 Acc: 0.9818 Pre: 0.6641 Rec: 0.7944 F1: 0.7234\n",
      "TP: 85.0 TN: 3413.0 FP: 43.0 FN: 22.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9911 Pre: 0.9765 Rec: 0.7879 F1: 0.8721\n",
      "TP: 208.0 TN: 6566.0 FP: 5.0 FN: 56.0\n",
      "val Loss: 0.0525 Acc: 0.9884 Pre: 0.7308 Rec: 0.9157 F1: 0.8128\n",
      "TP: 76.0 TN: 2915.0 FP: 28.0 FN: 7.0\n",
      "test Loss: 0.0638 Acc: 0.9865 Pre: 0.7757 Rec: 0.7757 F1: 0.7757\n",
      "TP: 83.0 TN: 3432.0 FP: 24.0 FN: 24.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0362 Acc: 0.9899 Pre: 0.9710 Rec: 0.7614 F1: 0.8535\n",
      "TP: 201.0 TN: 6565.0 FP: 6.0 FN: 63.0\n",
      "val Loss: 0.0421 Acc: 0.9904 Pre: 0.7755 Rec: 0.9157 F1: 0.8398\n",
      "TP: 76.0 TN: 2921.0 FP: 22.0 FN: 7.0\n",
      "test Loss: 0.0589 Acc: 0.9885 Pre: 0.8300 Rec: 0.7757 F1: 0.8019\n",
      "TP: 83.0 TN: 3439.0 FP: 17.0 FN: 24.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9905 Pre: 0.9671 Rec: 0.7803 F1: 0.8637\n",
      "TP: 206.0 TN: 6564.0 FP: 7.0 FN: 58.0\n",
      "val Loss: 0.0395 Acc: 0.9927 Pre: 0.8352 Rec: 0.9157 F1: 0.8736\n",
      "TP: 76.0 TN: 2928.0 FP: 15.0 FN: 7.0\n",
      "test Loss: 0.0592 Acc: 0.9902 Pre: 0.9000 Rec: 0.7570 F1: 0.8223\n",
      "TP: 81.0 TN: 3447.0 FP: 9.0 FN: 26.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0364 Acc: 0.9899 Pre: 0.9665 Rec: 0.7652 F1: 0.8541\n",
      "TP: 202.0 TN: 6564.0 FP: 7.0 FN: 62.0\n",
      "val Loss: 0.0448 Acc: 0.9898 Pre: 0.7600 Rec: 0.9157 F1: 0.8306\n",
      "TP: 76.0 TN: 2919.0 FP: 24.0 FN: 7.0\n",
      "test Loss: 0.0557 Acc: 0.9868 Pre: 0.7941 Rec: 0.7570 F1: 0.7751\n",
      "TP: 81.0 TN: 3435.0 FP: 21.0 FN: 26.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0394 Acc: 0.9887 Pre: 0.9474 Rec: 0.7500 F1: 0.8372\n",
      "TP: 198.0 TN: 6560.0 FP: 11.0 FN: 66.0\n",
      "val Loss: 0.0357 Acc: 0.9934 Pre: 0.8539 Rec: 0.9157 F1: 0.8837\n",
      "TP: 76.0 TN: 2930.0 FP: 13.0 FN: 7.0\n",
      "test Loss: 0.0584 Acc: 0.9899 Pre: 0.8901 Rec: 0.7570 F1: 0.8182\n",
      "TP: 81.0 TN: 3446.0 FP: 10.0 FN: 26.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.9911 Pre: 0.9721 Rec: 0.7917 F1: 0.8727\n",
      "TP: 209.0 TN: 6565.0 FP: 6.0 FN: 55.0\n",
      "val Loss: 0.0561 Acc: 0.9861 Pre: 0.6814 Rec: 0.9277 F1: 0.7857\n",
      "TP: 77.0 TN: 2907.0 FP: 36.0 FN: 6.0\n",
      "test Loss: 0.0659 Acc: 0.9860 Pre: 0.7615 Rec: 0.7757 F1: 0.7685\n",
      "TP: 83.0 TN: 3430.0 FP: 26.0 FN: 24.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.9905 Pre: 0.9671 Rec: 0.7803 F1: 0.8637\n",
      "TP: 206.0 TN: 6564.0 FP: 7.0 FN: 58.0\n",
      "val Loss: 0.0497 Acc: 0.9901 Pre: 0.7677 Rec: 0.9157 F1: 0.8352\n",
      "TP: 76.0 TN: 2920.0 FP: 23.0 FN: 7.0\n",
      "test Loss: 0.0650 Acc: 0.9860 Pre: 0.7714 Rec: 0.7570 F1: 0.7642\n",
      "TP: 81.0 TN: 3432.0 FP: 24.0 FN: 26.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0354 Acc: 0.9898 Pre: 0.9575 Rec: 0.7689 F1: 0.8529\n",
      "TP: 203.0 TN: 6562.0 FP: 9.0 FN: 61.0\n",
      "val Loss: 0.0379 Acc: 0.9921 Pre: 0.8172 Rec: 0.9157 F1: 0.8636\n",
      "TP: 76.0 TN: 2926.0 FP: 17.0 FN: 7.0\n",
      "test Loss: 0.0584 Acc: 0.9893 Pre: 0.8710 Rec: 0.7570 F1: 0.8100\n",
      "TP: 81.0 TN: 3444.0 FP: 12.0 FN: 26.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0332 Acc: 0.9924 Pre: 0.9649 Rec: 0.8333 F1: 0.8943\n",
      "TP: 220.0 TN: 6563.0 FP: 8.0 FN: 44.0\n",
      "val Loss: 0.0506 Acc: 0.9888 Pre: 0.7379 Rec: 0.9157 F1: 0.8172\n",
      "TP: 76.0 TN: 2916.0 FP: 27.0 FN: 7.0\n",
      "test Loss: 0.0632 Acc: 0.9860 Pre: 0.7714 Rec: 0.7570 F1: 0.7642\n",
      "TP: 81.0 TN: 3432.0 FP: 24.0 FN: 26.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9911 Pre: 0.9721 Rec: 0.7917 F1: 0.8727\n",
      "TP: 209.0 TN: 6565.0 FP: 6.0 FN: 55.0\n",
      "val Loss: 0.0509 Acc: 0.9868 Pre: 0.6972 Rec: 0.9157 F1: 0.7917\n",
      "TP: 76.0 TN: 2910.0 FP: 33.0 FN: 7.0\n",
      "test Loss: 0.0618 Acc: 0.9857 Pre: 0.7642 Rec: 0.7570 F1: 0.7606\n",
      "TP: 81.0 TN: 3431.0 FP: 25.0 FN: 26.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9906 Pre: 0.9425 Rec: 0.8068 F1: 0.8694\n",
      "TP: 213.0 TN: 6558.0 FP: 13.0 FN: 51.0\n",
      "val Loss: 0.0480 Acc: 0.9894 Pre: 0.7476 Rec: 0.9277 F1: 0.8280\n",
      "TP: 77.0 TN: 2917.0 FP: 26.0 FN: 6.0\n",
      "test Loss: 0.0656 Acc: 0.9862 Pre: 0.7788 Rec: 0.7570 F1: 0.7678\n",
      "TP: 81.0 TN: 3433.0 FP: 23.0 FN: 26.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9909 Pre: 0.9633 Rec: 0.7955 F1: 0.8714\n",
      "TP: 210.0 TN: 6563.0 FP: 8.0 FN: 54.0\n",
      "val Loss: 0.0580 Acc: 0.9865 Pre: 0.6875 Rec: 0.9277 F1: 0.7897\n",
      "TP: 77.0 TN: 2908.0 FP: 35.0 FN: 6.0\n",
      "test Loss: 0.0678 Acc: 0.9848 Pre: 0.7387 Rec: 0.7664 F1: 0.7523\n",
      "TP: 82.0 TN: 3427.0 FP: 29.0 FN: 25.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0353 Acc: 0.9899 Pre: 0.9665 Rec: 0.7652 F1: 0.8541\n",
      "TP: 202.0 TN: 6564.0 FP: 7.0 FN: 62.0\n",
      "val Loss: 0.0438 Acc: 0.9904 Pre: 0.7755 Rec: 0.9157 F1: 0.8398\n",
      "TP: 76.0 TN: 2921.0 FP: 22.0 FN: 7.0\n",
      "test Loss: 0.0614 Acc: 0.9877 Pre: 0.8182 Rec: 0.7570 F1: 0.7864\n",
      "TP: 81.0 TN: 3438.0 FP: 18.0 FN: 26.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0297 Acc: 0.9915 Pre: 0.9725 Rec: 0.8030 F1: 0.8797\n",
      "TP: 212.0 TN: 6565.0 FP: 6.0 FN: 52.0\n",
      "val Loss: 0.0338 Acc: 0.9944 Pre: 0.8837 Rec: 0.9157 F1: 0.8994\n",
      "TP: 76.0 TN: 2933.0 FP: 10.0 FN: 7.0\n",
      "test Loss: 0.0571 Acc: 0.9907 Pre: 0.9205 Rec: 0.7570 F1: 0.8308\n",
      "TP: 81.0 TN: 3449.0 FP: 7.0 FN: 26.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0331 Acc: 0.9898 Pre: 0.9663 Rec: 0.7614 F1: 0.8517\n",
      "TP: 201.0 TN: 6564.0 FP: 7.0 FN: 63.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0446 Acc: 0.9911 Pre: 0.7917 Rec: 0.9157 F1: 0.8492\n",
      "TP: 76.0 TN: 2923.0 FP: 20.0 FN: 7.0\n",
      "test Loss: 0.0616 Acc: 0.9871 Pre: 0.8020 Rec: 0.7570 F1: 0.7788\n",
      "TP: 81.0 TN: 3436.0 FP: 20.0 FN: 26.0\n",
      "\n",
      "Training complete in 47m 9s\n",
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.1062 Acc: 0.9719 Pre: 0.8462 Rec: 0.3333 F1: 0.4783\n",
      "TP: 88.0 TN: 6555.0 FP: 16.0 FN: 176.0\n",
      "val Loss: 0.1292 Acc: 0.9564 Pre: 0.3781 Rec: 0.9157 F1: 0.5352\n",
      "TP: 76.0 TN: 2818.0 FP: 125.0 FN: 7.0\n",
      "test Loss: 0.1379 Acc: 0.9548 Pre: 0.3937 Rec: 0.9346 F1: 0.5540\n",
      "TP: 100.0 TN: 3302.0 FP: 154.0 FN: 7.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.0756 Acc: 0.9811 Pre: 0.8947 Rec: 0.5795 F1: 0.7034\n",
      "TP: 153.0 TN: 6553.0 FP: 18.0 FN: 111.0\n",
      "val Loss: 0.0613 Acc: 0.9851 Pre: 0.6727 Rec: 0.8916 F1: 0.7668\n",
      "TP: 74.0 TN: 2907.0 FP: 36.0 FN: 9.0\n",
      "test Loss: 0.0434 Acc: 0.9896 Pre: 0.7652 Rec: 0.9439 F1: 0.8452\n",
      "TP: 101.0 TN: 3425.0 FP: 31.0 FN: 6.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0688 Acc: 0.9813 Pre: 0.8579 Rec: 0.6174 F1: 0.7181\n",
      "TP: 163.0 TN: 6544.0 FP: 27.0 FN: 101.0\n",
      "val Loss: 0.0545 Acc: 0.9838 Pre: 0.6466 Rec: 0.9036 F1: 0.7538\n",
      "TP: 75.0 TN: 2902.0 FP: 41.0 FN: 8.0\n",
      "test Loss: 0.0440 Acc: 0.9874 Pre: 0.7214 Rec: 0.9439 F1: 0.8178\n",
      "TP: 101.0 TN: 3417.0 FP: 39.0 FN: 6.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0615 Acc: 0.9836 Pre: 0.8918 Rec: 0.6553 F1: 0.7555\n",
      "TP: 173.0 TN: 6550.0 FP: 21.0 FN: 91.0\n",
      "val Loss: 0.0634 Acc: 0.9851 Pre: 0.6667 Rec: 0.9157 F1: 0.7716\n",
      "TP: 76.0 TN: 2905.0 FP: 38.0 FN: 7.0\n",
      "test Loss: 0.0467 Acc: 0.9826 Pre: 0.6471 Rec: 0.9252 F1: 0.7615\n",
      "TP: 99.0 TN: 3402.0 FP: 54.0 FN: 8.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0583 Acc: 0.9846 Pre: 0.8995 Rec: 0.6780 F1: 0.7732\n",
      "TP: 179.0 TN: 6551.0 FP: 20.0 FN: 85.0\n",
      "val Loss: 0.0434 Acc: 0.9924 Pre: 0.8333 Rec: 0.9036 F1: 0.8671\n",
      "TP: 75.0 TN: 2928.0 FP: 15.0 FN: 8.0\n",
      "test Loss: 0.0392 Acc: 0.9924 Pre: 0.8333 Rec: 0.9346 F1: 0.8811\n",
      "TP: 100.0 TN: 3436.0 FP: 20.0 FN: 7.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0545 Acc: 0.9854 Pre: 0.9020 Rec: 0.6970 F1: 0.7863\n",
      "TP: 184.0 TN: 6551.0 FP: 20.0 FN: 80.0\n",
      "val Loss: 0.0454 Acc: 0.9888 Pre: 0.7692 Rec: 0.8434 F1: 0.8046\n",
      "TP: 70.0 TN: 2922.0 FP: 21.0 FN: 13.0\n",
      "test Loss: 0.0324 Acc: 0.9944 Pre: 0.8850 Rec: 0.9346 F1: 0.9091\n",
      "TP: 100.0 TN: 3443.0 FP: 13.0 FN: 7.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0499 Acc: 0.9862 Pre: 0.9337 Rec: 0.6932 F1: 0.7957\n",
      "TP: 183.0 TN: 6558.0 FP: 13.0 FN: 81.0\n",
      "val Loss: 0.0458 Acc: 0.9901 Pre: 0.7789 Rec: 0.8916 F1: 0.8315\n",
      "TP: 74.0 TN: 2922.0 FP: 21.0 FN: 9.0\n",
      "test Loss: 0.0344 Acc: 0.9933 Pre: 0.8547 Rec: 0.9346 F1: 0.8929\n",
      "TP: 100.0 TN: 3439.0 FP: 17.0 FN: 7.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0469 Acc: 0.9876 Pre: 0.9543 Rec: 0.7121 F1: 0.8156\n",
      "TP: 188.0 TN: 6562.0 FP: 9.0 FN: 76.0\n",
      "val Loss: 0.0465 Acc: 0.9884 Pre: 0.7308 Rec: 0.9157 F1: 0.8128\n",
      "TP: 76.0 TN: 2915.0 FP: 28.0 FN: 7.0\n",
      "test Loss: 0.0371 Acc: 0.9907 Pre: 0.7937 Rec: 0.9346 F1: 0.8584\n",
      "TP: 100.0 TN: 3430.0 FP: 26.0 FN: 7.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0417 Acc: 0.9884 Pre: 0.9426 Rec: 0.7462 F1: 0.8330\n",
      "TP: 197.0 TN: 6559.0 FP: 12.0 FN: 67.0\n",
      "val Loss: 0.0449 Acc: 0.9904 Pre: 0.7755 Rec: 0.9157 F1: 0.8398\n",
      "TP: 76.0 TN: 2921.0 FP: 22.0 FN: 7.0\n",
      "test Loss: 0.0381 Acc: 0.9919 Pre: 0.8197 Rec: 0.9346 F1: 0.8734\n",
      "TP: 100.0 TN: 3434.0 FP: 22.0 FN: 7.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.9905 Pre: 0.9671 Rec: 0.7803 F1: 0.8637\n",
      "TP: 206.0 TN: 6564.0 FP: 7.0 FN: 58.0\n",
      "val Loss: 0.0556 Acc: 0.9855 Pre: 0.6726 Rec: 0.9157 F1: 0.7755\n",
      "TP: 76.0 TN: 2906.0 FP: 37.0 FN: 7.0\n",
      "test Loss: 0.0478 Acc: 0.9871 Pre: 0.7194 Rec: 0.9346 F1: 0.8130\n",
      "TP: 100.0 TN: 3417.0 FP: 39.0 FN: 7.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0396 Acc: 0.9892 Pre: 0.9567 Rec: 0.7538 F1: 0.8432\n",
      "TP: 199.0 TN: 6562.0 FP: 9.0 FN: 65.0\n",
      "val Loss: 0.0440 Acc: 0.9891 Pre: 0.7451 Rec: 0.9157 F1: 0.8216\n",
      "TP: 76.0 TN: 2917.0 FP: 26.0 FN: 7.0\n",
      "test Loss: 0.0359 Acc: 0.9924 Pre: 0.8333 Rec: 0.9346 F1: 0.8811\n",
      "TP: 100.0 TN: 3436.0 FP: 20.0 FN: 7.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0407 Acc: 0.9883 Pre: 0.9340 Rec: 0.7500 F1: 0.8319\n",
      "TP: 198.0 TN: 6557.0 FP: 14.0 FN: 66.0\n",
      "val Loss: 0.0421 Acc: 0.9894 Pre: 0.7525 Rec: 0.9157 F1: 0.8261\n",
      "TP: 76.0 TN: 2918.0 FP: 25.0 FN: 7.0\n",
      "test Loss: 0.0345 Acc: 0.9921 Pre: 0.8264 Rec: 0.9346 F1: 0.8772\n",
      "TP: 100.0 TN: 3435.0 FP: 21.0 FN: 7.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.9911 Pre: 0.9677 Rec: 0.7955 F1: 0.8732\n",
      "TP: 210.0 TN: 6564.0 FP: 7.0 FN: 54.0\n",
      "val Loss: 0.0407 Acc: 0.9914 Pre: 0.8000 Rec: 0.9157 F1: 0.8539\n",
      "TP: 76.0 TN: 2924.0 FP: 19.0 FN: 7.0\n",
      "test Loss: 0.0307 Acc: 0.9941 Pre: 0.8772 Rec: 0.9346 F1: 0.9050\n",
      "TP: 100.0 TN: 3442.0 FP: 14.0 FN: 7.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.9912 Pre: 0.9766 Rec: 0.7917 F1: 0.8745\n",
      "TP: 209.0 TN: 6566.0 FP: 5.0 FN: 55.0\n",
      "val Loss: 0.0431 Acc: 0.9907 Pre: 0.7835 Rec: 0.9157 F1: 0.8444\n",
      "TP: 76.0 TN: 2922.0 FP: 21.0 FN: 7.0\n",
      "test Loss: 0.0346 Acc: 0.9941 Pre: 0.8772 Rec: 0.9346 F1: 0.9050\n",
      "TP: 100.0 TN: 3442.0 FP: 14.0 FN: 7.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9901 Pre: 0.9623 Rec: 0.7727 F1: 0.8571\n",
      "TP: 204.0 TN: 6563.0 FP: 8.0 FN: 60.0\n",
      "val Loss: 0.0439 Acc: 0.9898 Pre: 0.7600 Rec: 0.9157 F1: 0.8306\n",
      "TP: 76.0 TN: 2919.0 FP: 24.0 FN: 7.0\n",
      "test Loss: 0.0349 Acc: 0.9933 Pre: 0.8609 Rec: 0.9252 F1: 0.8919\n",
      "TP: 99.0 TN: 3440.0 FP: 16.0 FN: 8.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0318 Acc: 0.9908 Pre: 0.9589 Rec: 0.7955 F1: 0.8696\n",
      "TP: 210.0 TN: 6562.0 FP: 9.0 FN: 54.0\n",
      "val Loss: 0.0350 Acc: 0.9931 Pre: 0.8444 Rec: 0.9157 F1: 0.8786\n",
      "TP: 76.0 TN: 2929.0 FP: 14.0 FN: 7.0\n",
      "test Loss: 0.0277 Acc: 0.9935 Pre: 0.8818 Rec: 0.9065 F1: 0.8940\n",
      "TP: 97.0 TN: 3443.0 FP: 13.0 FN: 10.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0330 Acc: 0.9908 Pre: 0.9389 Rec: 0.8144 F1: 0.8722\n",
      "TP: 215.0 TN: 6557.0 FP: 14.0 FN: 49.0\n",
      "val Loss: 0.0476 Acc: 0.9901 Pre: 0.7677 Rec: 0.9157 F1: 0.8352\n",
      "TP: 76.0 TN: 2920.0 FP: 23.0 FN: 7.0\n",
      "test Loss: 0.0357 Acc: 0.9924 Pre: 0.8333 Rec: 0.9346 F1: 0.8811\n",
      "TP: 100.0 TN: 3436.0 FP: 20.0 FN: 7.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0299 Acc: 0.9909 Pre: 0.9469 Rec: 0.8106 F1: 0.8735\n",
      "TP: 214.0 TN: 6559.0 FP: 12.0 FN: 50.0\n",
      "val Loss: 0.0453 Acc: 0.9891 Pre: 0.7451 Rec: 0.9157 F1: 0.8216\n",
      "TP: 76.0 TN: 2917.0 FP: 26.0 FN: 7.0\n",
      "test Loss: 0.0370 Acc: 0.9919 Pre: 0.8197 Rec: 0.9346 F1: 0.8734\n",
      "TP: 100.0 TN: 3434.0 FP: 22.0 FN: 7.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0318 Acc: 0.9909 Pre: 0.9720 Rec: 0.7879 F1: 0.8703\n",
      "TP: 208.0 TN: 6565.0 FP: 6.0 FN: 56.0\n",
      "val Loss: 0.0498 Acc: 0.9878 Pre: 0.7170 Rec: 0.9157 F1: 0.8042\n",
      "TP: 76.0 TN: 2913.0 FP: 30.0 FN: 7.0\n",
      "test Loss: 0.0409 Acc: 0.9913 Pre: 0.8065 Rec: 0.9346 F1: 0.8658\n",
      "TP: 100.0 TN: 3432.0 FP: 24.0 FN: 7.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0325 Acc: 0.9899 Pre: 0.9535 Rec: 0.7765 F1: 0.8559\n",
      "TP: 205.0 TN: 6561.0 FP: 10.0 FN: 59.0\n",
      "val Loss: 0.0403 Acc: 0.9904 Pre: 0.7755 Rec: 0.9157 F1: 0.8398\n",
      "TP: 76.0 TN: 2921.0 FP: 22.0 FN: 7.0\n",
      "test Loss: 0.0328 Acc: 0.9935 Pre: 0.8684 Rec: 0.9252 F1: 0.8959\n",
      "TP: 99.0 TN: 3441.0 FP: 15.0 FN: 8.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.9918 Pre: 0.9860 Rec: 0.7992 F1: 0.8828\n",
      "TP: 211.0 TN: 6568.0 FP: 3.0 FN: 53.0\n",
      "val Loss: 0.0454 Acc: 0.9891 Pre: 0.7451 Rec: 0.9157 F1: 0.8216\n",
      "TP: 76.0 TN: 2917.0 FP: 26.0 FN: 7.0\n",
      "test Loss: 0.0375 Acc: 0.9916 Pre: 0.8130 Rec: 0.9346 F1: 0.8696\n",
      "TP: 100.0 TN: 3433.0 FP: 23.0 FN: 7.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.9905 Pre: 0.9671 Rec: 0.7803 F1: 0.8637\n",
      "TP: 206.0 TN: 6564.0 FP: 7.0 FN: 58.0\n",
      "val Loss: 0.0343 Acc: 0.9941 Pre: 0.8736 Rec: 0.9157 F1: 0.8941\n",
      "TP: 76.0 TN: 2932.0 FP: 11.0 FN: 7.0\n",
      "test Loss: 0.0278 Acc: 0.9933 Pre: 0.8952 Rec: 0.8785 F1: 0.8868\n",
      "TP: 94.0 TN: 3445.0 FP: 11.0 FN: 13.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9908 Pre: 0.9763 Rec: 0.7803 F1: 0.8674\n",
      "TP: 206.0 TN: 6566.0 FP: 5.0 FN: 58.0\n",
      "val Loss: 0.0411 Acc: 0.9911 Pre: 0.7917 Rec: 0.9157 F1: 0.8492\n",
      "TP: 76.0 TN: 2923.0 FP: 20.0 FN: 7.0\n",
      "test Loss: 0.0321 Acc: 0.9941 Pre: 0.8772 Rec: 0.9346 F1: 0.9050\n",
      "TP: 100.0 TN: 3442.0 FP: 14.0 FN: 7.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.9917 Pre: 0.9559 Rec: 0.8220 F1: 0.8839\n",
      "TP: 217.0 TN: 6561.0 FP: 10.0 FN: 47.0\n",
      "val Loss: 0.0405 Acc: 0.9917 Pre: 0.8085 Rec: 0.9157 F1: 0.8588\n",
      "TP: 76.0 TN: 2925.0 FP: 18.0 FN: 7.0\n",
      "test Loss: 0.0324 Acc: 0.9927 Pre: 0.8584 Rec: 0.9065 F1: 0.8818\n",
      "TP: 97.0 TN: 3440.0 FP: 16.0 FN: 10.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0265 Acc: 0.9914 Pre: 0.9325 Rec: 0.8371 F1: 0.8822\n",
      "TP: 221.0 TN: 6555.0 FP: 16.0 FN: 43.0\n",
      "val Loss: 0.0468 Acc: 0.9891 Pre: 0.7451 Rec: 0.9157 F1: 0.8216\n",
      "TP: 76.0 TN: 2917.0 FP: 26.0 FN: 7.0\n",
      "test Loss: 0.0377 Acc: 0.9916 Pre: 0.8130 Rec: 0.9346 F1: 0.8696\n",
      "TP: 100.0 TN: 3433.0 FP: 23.0 FN: 7.0\n",
      "\n",
      "Training complete in 46m 41s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "for seed in range(2, 5):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9801 Pre: 0.6304 Rec: 0.8131 F1: 0.7102\n",
      "TP: 87.0 TN: 3405.0 FP: 51.0 FN: 20.0\n",
      "Smoothed stats:\n",
      "(0.9912994667415099, 0.8877551020408163, 0.8130841121495327, 0.848780487804878, 87, 3445, 11, 20)\n",
      "1\n",
      "Acc: 0.9806 Pre: 0.6484 Rec: 0.7757 F1: 0.7064\n",
      "TP: 83.0 TN: 3411.0 FP: 45.0 FN: 24.0\n",
      "Smoothed stats:\n",
      "(0.9918607914678642, 0.9431818181818182, 0.7757009345794392, 0.8512820512820513, 83, 3451, 5, 24)\n",
      "2\n",
      "Acc: 0.9902 Pre: 0.7857 Rec: 0.9252 F1: 0.8498\n",
      "TP: 99.0 TN: 3429.0 FP: 27.0 FN: 8.0\n",
      "Smoothed stats:\n",
      "(0.9963513892786977, 0.9433962264150944, 0.9345794392523364, 0.9389671361502347, 100, 3450, 6, 7)\n",
      "3\n",
      "Acc: 0.9871 Pre: 0.8020 Rec: 0.7570 F1: 0.7788\n",
      "TP: 81.0 TN: 3436.0 FP: 20.0 FN: 26.0\n",
      "Smoothed stats:\n",
      "(0.9915801291046871, 0.963855421686747, 0.7476635514018691, 0.8421052631578946, 80, 3453, 3, 27)\n",
      "4\n",
      "Acc: 0.9916 Pre: 0.8130 Rec: 0.9346 F1: 0.8696\n",
      "TP: 100.0 TN: 3433.0 FP: 23.0 FN: 7.0\n",
      "Smoothed stats:\n",
      "(0.9969127140050519, 0.9528301886792453, 0.9439252336448598, 0.948356807511737, 101, 3451, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
