{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'bernie_interviews/data/train.txt'\n",
    "val_file = 'bernie_interviews/data/val.txt'\n",
    "test_file = 'bernie_interviews/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('bernie_interviews/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train']),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train']),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val']),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 6835, 'val_train': 3026, 'val': 3026, 'test': 3563}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.1046 Acc: 0.9719 Pre: 0.8396 Rec: 0.3371 F1: 0.4811\n",
      "TP: 89.0 TN: 6554.0 FP: 17.0 FN: 175.0\n",
      "val Loss: 0.0610 Acc: 0.9845 Pre: 0.6607 Rec: 0.8916 F1: 0.7590\n",
      "TP: 74.0 TN: 2905.0 FP: 38.0 FN: 9.0\n",
      "test Loss: 0.0470 Acc: 0.9857 Pre: 0.6892 Rec: 0.9533 F1: 0.8000\n",
      "TP: 102.0 TN: 3410.0 FP: 46.0 FN: 5.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.0803 Acc: 0.9826 Pre: 0.9240 Rec: 0.5985 F1: 0.7264\n",
      "TP: 158.0 TN: 6558.0 FP: 13.0 FN: 106.0\n",
      "val Loss: 0.0577 Acc: 0.9891 Pre: 0.7551 Rec: 0.8916 F1: 0.8177\n",
      "TP: 74.0 TN: 2919.0 FP: 24.0 FN: 9.0\n",
      "test Loss: 0.0556 Acc: 0.9854 Pre: 0.7132 Rec: 0.8598 F1: 0.7797\n",
      "TP: 92.0 TN: 3419.0 FP: 37.0 FN: 15.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0640 Acc: 0.9833 Pre: 0.8866 Rec: 0.6515 F1: 0.7511\n",
      "TP: 172.0 TN: 6549.0 FP: 22.0 FN: 92.0\n",
      "val Loss: 0.0813 Acc: 0.9828 Pre: 0.6325 Rec: 0.8916 F1: 0.7400\n",
      "TP: 74.0 TN: 2900.0 FP: 43.0 FN: 9.0\n",
      "test Loss: 0.0637 Acc: 0.9812 Pre: 0.6333 Rec: 0.8879 F1: 0.7393\n",
      "TP: 95.0 TN: 3401.0 FP: 55.0 FN: 12.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0591 Acc: 0.9851 Pre: 0.9091 Rec: 0.6818 F1: 0.7792\n",
      "TP: 180.0 TN: 6553.0 FP: 18.0 FN: 84.0\n",
      "val Loss: 0.1449 Acc: 0.9547 Pre: 0.3702 Rec: 0.9277 F1: 0.5292\n",
      "TP: 77.0 TN: 2812.0 FP: 131.0 FN: 6.0\n",
      "test Loss: 0.1331 Acc: 0.9593 Pre: 0.4234 Rec: 0.9813 F1: 0.5915\n",
      "TP: 105.0 TN: 3313.0 FP: 143.0 FN: 2.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0591 Acc: 0.9854 Pre: 0.9316 Rec: 0.6705 F1: 0.7797\n",
      "TP: 177.0 TN: 6558.0 FP: 13.0 FN: 87.0\n",
      "val Loss: 0.0818 Acc: 0.9769 Pre: 0.5468 Rec: 0.9157 F1: 0.6847\n",
      "TP: 76.0 TN: 2880.0 FP: 63.0 FN: 7.0\n",
      "test Loss: 0.0677 Acc: 0.9798 Pre: 0.6000 Rec: 0.9813 F1: 0.7447\n",
      "TP: 105.0 TN: 3386.0 FP: 70.0 FN: 2.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0555 Acc: 0.9851 Pre: 0.9091 Rec: 0.6818 F1: 0.7792\n",
      "TP: 180.0 TN: 6553.0 FP: 18.0 FN: 84.0\n",
      "val Loss: 0.0522 Acc: 0.9848 Pre: 0.7126 Rec: 0.7470 F1: 0.7294\n",
      "TP: 62.0 TN: 2918.0 FP: 25.0 FN: 21.0\n",
      "test Loss: 0.0307 Acc: 0.9935 Pre: 0.9038 Rec: 0.8785 F1: 0.8910\n",
      "TP: 94.0 TN: 3446.0 FP: 10.0 FN: 13.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0495 Acc: 0.9873 Pre: 0.9538 Rec: 0.7045 F1: 0.8105\n",
      "TP: 186.0 TN: 6562.0 FP: 9.0 FN: 78.0\n",
      "val Loss: 0.0765 Acc: 0.9785 Pre: 0.5662 Rec: 0.9277 F1: 0.7032\n",
      "TP: 77.0 TN: 2884.0 FP: 59.0 FN: 6.0\n",
      "test Loss: 0.0613 Acc: 0.9826 Pre: 0.6380 Rec: 0.9720 F1: 0.7704\n",
      "TP: 104.0 TN: 3397.0 FP: 59.0 FN: 3.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0390 Acc: 0.9893 Pre: 0.9614 Rec: 0.7538 F1: 0.8450\n",
      "TP: 199.0 TN: 6563.0 FP: 8.0 FN: 65.0\n",
      "val Loss: 0.0569 Acc: 0.9835 Pre: 0.6387 Rec: 0.9157 F1: 0.7525\n",
      "TP: 76.0 TN: 2900.0 FP: 43.0 FN: 7.0\n",
      "test Loss: 0.0415 Acc: 0.9893 Pre: 0.7518 Rec: 0.9626 F1: 0.8443\n",
      "TP: 103.0 TN: 3422.0 FP: 34.0 FN: 4.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0349 Acc: 0.9908 Pre: 0.9718 Rec: 0.7841 F1: 0.8679\n",
      "TP: 207.0 TN: 6565.0 FP: 6.0 FN: 57.0\n",
      "val Loss: 0.0501 Acc: 0.9851 Pre: 0.6792 Rec: 0.8675 F1: 0.7619\n",
      "TP: 72.0 TN: 2909.0 FP: 34.0 FN: 11.0\n",
      "test Loss: 0.0351 Acc: 0.9919 Pre: 0.8145 Rec: 0.9439 F1: 0.8745\n",
      "TP: 101.0 TN: 3433.0 FP: 23.0 FN: 6.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0358 Acc: 0.9887 Pre: 0.9606 Rec: 0.7386 F1: 0.8351\n",
      "TP: 195.0 TN: 6563.0 FP: 8.0 FN: 69.0\n",
      "val Loss: 0.0395 Acc: 0.9894 Pre: 0.7629 Rec: 0.8916 F1: 0.8222\n",
      "TP: 74.0 TN: 2920.0 FP: 23.0 FN: 9.0\n",
      "test Loss: 0.0280 Acc: 0.9930 Pre: 0.8417 Rec: 0.9439 F1: 0.8899\n",
      "TP: 101.0 TN: 3437.0 FP: 19.0 FN: 6.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0360 Acc: 0.9902 Pre: 0.9581 Rec: 0.7803 F1: 0.8601\n",
      "TP: 206.0 TN: 6562.0 FP: 9.0 FN: 58.0\n",
      "val Loss: 0.0471 Acc: 0.9874 Pre: 0.7320 Rec: 0.8554 F1: 0.7889\n",
      "TP: 71.0 TN: 2917.0 FP: 26.0 FN: 12.0\n",
      "test Loss: 0.0310 Acc: 0.9927 Pre: 0.8347 Rec: 0.9439 F1: 0.8860\n",
      "TP: 101.0 TN: 3436.0 FP: 20.0 FN: 6.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0321 Acc: 0.9908 Pre: 0.9589 Rec: 0.7955 F1: 0.8696\n",
      "TP: 210.0 TN: 6562.0 FP: 9.0 FN: 54.0\n",
      "val Loss: 0.0620 Acc: 0.9825 Pre: 0.6250 Rec: 0.9036 F1: 0.7389\n",
      "TP: 75.0 TN: 2898.0 FP: 45.0 FN: 8.0\n",
      "test Loss: 0.0435 Acc: 0.9888 Pre: 0.7445 Rec: 0.9533 F1: 0.8361\n",
      "TP: 102.0 TN: 3421.0 FP: 35.0 FN: 5.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0347 Acc: 0.9892 Pre: 0.9318 Rec: 0.7765 F1: 0.8471\n",
      "TP: 205.0 TN: 6556.0 FP: 15.0 FN: 59.0\n",
      "val Loss: 0.0492 Acc: 0.9858 Pre: 0.6852 Rec: 0.8916 F1: 0.7749\n",
      "TP: 74.0 TN: 2909.0 FP: 34.0 FN: 9.0\n",
      "test Loss: 0.0380 Acc: 0.9896 Pre: 0.7612 Rec: 0.9533 F1: 0.8465\n",
      "TP: 102.0 TN: 3424.0 FP: 32.0 FN: 5.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9921 Pre: 0.9605 Rec: 0.8295 F1: 0.8902\n",
      "TP: 219.0 TN: 6562.0 FP: 9.0 FN: 45.0\n",
      "val Loss: 0.0813 Acc: 0.9749 Pre: 0.5245 Rec: 0.9036 F1: 0.6637\n",
      "TP: 75.0 TN: 2875.0 FP: 68.0 FN: 8.0\n",
      "test Loss: 0.0616 Acc: 0.9837 Pre: 0.6561 Rec: 0.9626 F1: 0.7803\n",
      "TP: 103.0 TN: 3402.0 FP: 54.0 FN: 4.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0347 Acc: 0.9902 Pre: 0.9539 Rec: 0.7841 F1: 0.8607\n",
      "TP: 207.0 TN: 6561.0 FP: 10.0 FN: 57.0\n",
      "val Loss: 0.0648 Acc: 0.9818 Pre: 0.6148 Rec: 0.9036 F1: 0.7317\n",
      "TP: 75.0 TN: 2896.0 FP: 47.0 FN: 8.0\n",
      "test Loss: 0.0481 Acc: 0.9879 Pre: 0.7254 Rec: 0.9626 F1: 0.8273\n",
      "TP: 103.0 TN: 3417.0 FP: 39.0 FN: 4.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0339 Acc: 0.9896 Pre: 0.9617 Rec: 0.7614 F1: 0.8499\n",
      "TP: 201.0 TN: 6563.0 FP: 8.0 FN: 63.0\n",
      "val Loss: 0.0599 Acc: 0.9835 Pre: 0.6410 Rec: 0.9036 F1: 0.7500\n",
      "TP: 75.0 TN: 2901.0 FP: 42.0 FN: 8.0\n",
      "test Loss: 0.0443 Acc: 0.9888 Pre: 0.7445 Rec: 0.9533 F1: 0.8361\n",
      "TP: 102.0 TN: 3421.0 FP: 35.0 FN: 5.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0347 Acc: 0.9911 Pre: 0.9511 Rec: 0.8106 F1: 0.8753\n",
      "TP: 214.0 TN: 6560.0 FP: 11.0 FN: 50.0\n",
      "val Loss: 0.0612 Acc: 0.9841 Pre: 0.6522 Rec: 0.9036 F1: 0.7576\n",
      "TP: 75.0 TN: 2903.0 FP: 40.0 FN: 8.0\n",
      "test Loss: 0.0464 Acc: 0.9891 Pre: 0.7500 Rec: 0.9533 F1: 0.8395\n",
      "TP: 102.0 TN: 3422.0 FP: 34.0 FN: 5.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0331 Acc: 0.9895 Pre: 0.9615 Rec: 0.7576 F1: 0.8475\n",
      "TP: 200.0 TN: 6563.0 FP: 8.0 FN: 64.0\n",
      "val Loss: 0.0526 Acc: 0.9841 Pre: 0.6522 Rec: 0.9036 F1: 0.7576\n",
      "TP: 75.0 TN: 2903.0 FP: 40.0 FN: 8.0\n",
      "test Loss: 0.0401 Acc: 0.9899 Pre: 0.7669 Rec: 0.9533 F1: 0.8500\n",
      "TP: 102.0 TN: 3425.0 FP: 31.0 FN: 5.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0293 Acc: 0.9915 Pre: 0.9518 Rec: 0.8220 F1: 0.8821\n",
      "TP: 217.0 TN: 6560.0 FP: 11.0 FN: 47.0\n",
      "val Loss: 0.0652 Acc: 0.9831 Pre: 0.6356 Rec: 0.9036 F1: 0.7463\n",
      "TP: 75.0 TN: 2900.0 FP: 43.0 FN: 8.0\n",
      "test Loss: 0.0470 Acc: 0.9874 Pre: 0.7183 Rec: 0.9533 F1: 0.8193\n",
      "TP: 102.0 TN: 3416.0 FP: 40.0 FN: 5.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0307 Acc: 0.9918 Pre: 0.9685 Rec: 0.8144 F1: 0.8848\n",
      "TP: 215.0 TN: 6564.0 FP: 7.0 FN: 49.0\n",
      "val Loss: 0.0512 Acc: 0.9865 Pre: 0.6944 Rec: 0.9036 F1: 0.7853\n",
      "TP: 75.0 TN: 2910.0 FP: 33.0 FN: 8.0\n",
      "test Loss: 0.0374 Acc: 0.9902 Pre: 0.7769 Rec: 0.9439 F1: 0.8523\n",
      "TP: 101.0 TN: 3427.0 FP: 29.0 FN: 6.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9906 Pre: 0.9587 Rec: 0.7917 F1: 0.8672\n",
      "TP: 209.0 TN: 6562.0 FP: 9.0 FN: 55.0\n",
      "val Loss: 0.0631 Acc: 0.9845 Pre: 0.6579 Rec: 0.9036 F1: 0.7614\n",
      "TP: 75.0 TN: 2904.0 FP: 39.0 FN: 8.0\n",
      "test Loss: 0.0459 Acc: 0.9891 Pre: 0.7500 Rec: 0.9533 F1: 0.8395\n",
      "TP: 102.0 TN: 3422.0 FP: 34.0 FN: 5.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0334 Acc: 0.9911 Pre: 0.9432 Rec: 0.8182 F1: 0.8763\n",
      "TP: 216.0 TN: 6558.0 FP: 13.0 FN: 48.0\n",
      "val Loss: 0.0612 Acc: 0.9831 Pre: 0.6356 Rec: 0.9036 F1: 0.7463\n",
      "TP: 75.0 TN: 2900.0 FP: 43.0 FN: 8.0\n",
      "test Loss: 0.0446 Acc: 0.9882 Pre: 0.7338 Rec: 0.9533 F1: 0.8293\n",
      "TP: 102.0 TN: 3419.0 FP: 37.0 FN: 5.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0299 Acc: 0.9906 Pre: 0.9630 Rec: 0.7879 F1: 0.8667\n",
      "TP: 208.0 TN: 6563.0 FP: 8.0 FN: 56.0\n",
      "val Loss: 0.0521 Acc: 0.9848 Pre: 0.6637 Rec: 0.9036 F1: 0.7653\n",
      "TP: 75.0 TN: 2905.0 FP: 38.0 FN: 8.0\n",
      "test Loss: 0.0411 Acc: 0.9896 Pre: 0.7612 Rec: 0.9533 F1: 0.8465\n",
      "TP: 102.0 TN: 3424.0 FP: 32.0 FN: 5.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.9908 Pre: 0.9507 Rec: 0.8030 F1: 0.8706\n",
      "TP: 212.0 TN: 6560.0 FP: 11.0 FN: 52.0\n",
      "val Loss: 0.0508 Acc: 0.9838 Pre: 0.6466 Rec: 0.9036 F1: 0.7538\n",
      "TP: 75.0 TN: 2902.0 FP: 41.0 FN: 8.0\n",
      "test Loss: 0.0396 Acc: 0.9888 Pre: 0.7481 Rec: 0.9439 F1: 0.8347\n",
      "TP: 101.0 TN: 3422.0 FP: 34.0 FN: 6.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0362 Acc: 0.9902 Pre: 0.9668 Rec: 0.7727 F1: 0.8589\n",
      "TP: 204.0 TN: 6564.0 FP: 7.0 FN: 60.0\n",
      "val Loss: 0.0664 Acc: 0.9825 Pre: 0.6250 Rec: 0.9036 F1: 0.7389\n",
      "TP: 75.0 TN: 2898.0 FP: 45.0 FN: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0499 Acc: 0.9868 Pre: 0.7083 Rec: 0.9533 F1: 0.8127\n",
      "TP: 102.0 TN: 3414.0 FP: 42.0 FN: 5.0\n",
      "\n",
      "Training complete in 49m 31s\n",
      "Best epoch: 9\n",
      "Best val Acc: 0.989425\n",
      "Best val Pre: 0.762887\n",
      "Best val Rec: 0.891566\n",
      "Best val F1: 0.822222\n",
      "Test Acc: 0.992983\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=True)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
