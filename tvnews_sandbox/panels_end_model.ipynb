{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'tvnews_sandbox/data_panels/train.txt'\n",
    "val_file = 'tvnews_sandbox/data_panels/val.txt'\n",
    "test_file = 'tvnews_sandbox/data_panels/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('tvnews_sandbox/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12611558156547184\n",
      "0.11103767349636484\n",
      "0.12489475161380859\n"
     ]
    }
   ],
   "source": [
    "def class_balance(filename):\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            labels.append(int(label))\n",
    "    \n",
    "    cb = len([lb for lb in labels if lb == 1]) / len(labels)\n",
    "    \n",
    "    return cb\n",
    "\n",
    "print(class_balance(train_file))\n",
    "print(class_balance(val_file))\n",
    "print(class_balance(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 6835, 'val_train': 3026, 'val': 3026, 'test': 3563}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3359 Acc: 0.8840 Pre: 0.3770 Rec: 0.0685 F1: 0.1159\n",
      "TP: 23.0 TN: 2652.0 FP: 38.0 FN: 313.0\n",
      "val Loss: 0.2770 Acc: 0.8949 Pre: 1.0000 Rec: 0.0536 F1: 0.1017\n",
      "TP: 18.0 TN: 2690.0 FP: 0.0 FN: 318.0\n",
      "test Loss: 0.3914 Acc: 0.8774 Pre: 0.7857 Rec: 0.0247 F1: 0.0479\n",
      "TP: 11.0 TN: 3115.0 FP: 3.0 FN: 434.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2983 Acc: 0.8876 Pre: 0.4836 Rec: 0.1756 F1: 0.2576\n",
      "TP: 59.0 TN: 2627.0 FP: 63.0 FN: 277.0\n",
      "val Loss: 0.1922 Acc: 0.9213 Pre: 0.8451 Rec: 0.3571 F1: 0.5021\n",
      "TP: 120.0 TN: 2668.0 FP: 22.0 FN: 216.0\n",
      "test Loss: 0.3213 Acc: 0.8846 Pre: 0.6349 Rec: 0.1798 F1: 0.2802\n",
      "TP: 80.0 TN: 3072.0 FP: 46.0 FN: 365.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2733 Acc: 0.9009 Pre: 0.6139 Rec: 0.2887 F1: 0.3927\n",
      "TP: 97.0 TN: 2629.0 FP: 61.0 FN: 239.0\n",
      "val Loss: 0.1854 Acc: 0.9309 Pre: 0.7292 Rec: 0.6012 F1: 0.6591\n",
      "TP: 202.0 TN: 2615.0 FP: 75.0 FN: 134.0\n",
      "test Loss: 0.3218 Acc: 0.8748 Pre: 0.4981 Rec: 0.2876 F1: 0.3647\n",
      "TP: 128.0 TN: 2989.0 FP: 129.0 FN: 317.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2594 Acc: 0.9015 Pre: 0.6131 Rec: 0.3065 F1: 0.4087\n",
      "TP: 103.0 TN: 2625.0 FP: 65.0 FN: 233.0\n",
      "val Loss: 0.1668 Acc: 0.9395 Pre: 0.6977 Rec: 0.8036 F1: 0.7469\n",
      "TP: 270.0 TN: 2573.0 FP: 117.0 FN: 66.0\n",
      "test Loss: 0.3531 Acc: 0.8754 Pre: 0.5012 Rec: 0.4809 F1: 0.4908\n",
      "TP: 214.0 TN: 2905.0 FP: 213.0 FN: 231.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2474 Acc: 0.9134 Pre: 0.6927 Rec: 0.3958 F1: 0.5038\n",
      "TP: 133.0 TN: 2631.0 FP: 59.0 FN: 203.0\n",
      "val Loss: 0.1463 Acc: 0.9475 Pre: 0.7479 Rec: 0.7946 F1: 0.7706\n",
      "TP: 267.0 TN: 2600.0 FP: 90.0 FN: 69.0\n",
      "test Loss: 0.3673 Acc: 0.8841 Pre: 0.5430 Rec: 0.4539 F1: 0.4945\n",
      "TP: 202.0 TN: 2948.0 FP: 170.0 FN: 243.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2339 Acc: 0.9184 Pre: 0.7214 Rec: 0.4315 F1: 0.5400\n",
      "TP: 145.0 TN: 2634.0 FP: 56.0 FN: 191.0\n",
      "val Loss: 0.1706 Acc: 0.9428 Pre: 0.6840 Rec: 0.9018 F1: 0.7779\n",
      "TP: 303.0 TN: 2550.0 FP: 140.0 FN: 33.0\n",
      "test Loss: 0.4241 Acc: 0.8560 Pre: 0.4289 Rec: 0.4607 F1: 0.4442\n",
      "TP: 205.0 TN: 2845.0 FP: 273.0 FN: 240.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1761 Acc: 0.9369 Pre: 0.8251 Rec: 0.5476 F1: 0.6583\n",
      "TP: 184.0 TN: 2651.0 FP: 39.0 FN: 152.0\n",
      "val Loss: 0.1102 Acc: 0.9643 Pre: 0.8220 Rec: 0.8661 F1: 0.8435\n",
      "TP: 291.0 TN: 2627.0 FP: 63.0 FN: 45.0\n",
      "test Loss: 0.3951 Acc: 0.8813 Pre: 0.5353 Rec: 0.3753 F1: 0.4412\n",
      "TP: 167.0 TN: 2973.0 FP: 145.0 FN: 278.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1798 Acc: 0.9379 Pre: 0.8364 Rec: 0.5476 F1: 0.6619\n",
      "TP: 184.0 TN: 2654.0 FP: 36.0 FN: 152.0\n",
      "val Loss: 0.1124 Acc: 0.9630 Pre: 0.8060 Rec: 0.8780 F1: 0.8405\n",
      "TP: 295.0 TN: 2619.0 FP: 71.0 FN: 41.0\n",
      "test Loss: 0.3823 Acc: 0.8830 Pre: 0.5432 Rec: 0.3955 F1: 0.4577\n",
      "TP: 176.0 TN: 2970.0 FP: 148.0 FN: 269.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9405 Pre: 0.8333 Rec: 0.5804 F1: 0.6842\n",
      "TP: 195.0 TN: 2651.0 FP: 39.0 FN: 141.0\n",
      "val Loss: 0.1026 Acc: 0.9670 Pre: 0.8242 Rec: 0.8929 F1: 0.8571\n",
      "TP: 300.0 TN: 2626.0 FP: 64.0 FN: 36.0\n",
      "test Loss: 0.3891 Acc: 0.8816 Pre: 0.5347 Rec: 0.3978 F1: 0.4562\n",
      "TP: 177.0 TN: 2964.0 FP: 154.0 FN: 268.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9418 Pre: 0.8390 Rec: 0.5893 F1: 0.6923\n",
      "TP: 198.0 TN: 2652.0 FP: 38.0 FN: 138.0\n",
      "val Loss: 0.0953 Acc: 0.9699 Pre: 0.8451 Rec: 0.8929 F1: 0.8683\n",
      "TP: 300.0 TN: 2635.0 FP: 55.0 FN: 36.0\n",
      "test Loss: 0.3970 Acc: 0.8844 Pre: 0.5567 Rec: 0.3640 F1: 0.4402\n",
      "TP: 162.0 TN: 2989.0 FP: 129.0 FN: 283.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1512 Acc: 0.9491 Pre: 0.8583 Rec: 0.6488 F1: 0.7390\n",
      "TP: 218.0 TN: 2654.0 FP: 36.0 FN: 118.0\n",
      "val Loss: 0.0915 Acc: 0.9699 Pre: 0.8375 Rec: 0.9048 F1: 0.8698\n",
      "TP: 304.0 TN: 2631.0 FP: 59.0 FN: 32.0\n",
      "test Loss: 0.3960 Acc: 0.8841 Pre: 0.5526 Rec: 0.3775 F1: 0.4486\n",
      "TP: 168.0 TN: 2982.0 FP: 136.0 FN: 277.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1502 Acc: 0.9518 Pre: 0.8862 Rec: 0.6488 F1: 0.7491\n",
      "TP: 218.0 TN: 2662.0 FP: 28.0 FN: 118.0\n",
      "val Loss: 0.1207 Acc: 0.9574 Pre: 0.7458 Rec: 0.9345 F1: 0.8296\n",
      "TP: 314.0 TN: 2583.0 FP: 107.0 FN: 22.0\n",
      "test Loss: 0.4113 Acc: 0.8670 Pre: 0.4656 Rec: 0.4404 F1: 0.4527\n",
      "TP: 196.0 TN: 2893.0 FP: 225.0 FN: 249.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1464 Acc: 0.9484 Pre: 0.8571 Rec: 0.6429 F1: 0.7347\n",
      "TP: 216.0 TN: 2654.0 FP: 36.0 FN: 120.0\n",
      "val Loss: 0.0822 Acc: 0.9699 Pre: 0.8375 Rec: 0.9048 F1: 0.8698\n",
      "TP: 304.0 TN: 2631.0 FP: 59.0 FN: 32.0\n",
      "test Loss: 0.4117 Acc: 0.8796 Pre: 0.5256 Rec: 0.3685 F1: 0.4333\n",
      "TP: 164.0 TN: 2970.0 FP: 148.0 FN: 281.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1442 Acc: 0.9524 Pre: 0.8721 Rec: 0.6696 F1: 0.7576\n",
      "TP: 225.0 TN: 2657.0 FP: 33.0 FN: 111.0\n",
      "val Loss: 0.0854 Acc: 0.9729 Pre: 0.8414 Rec: 0.9315 F1: 0.8842\n",
      "TP: 313.0 TN: 2631.0 FP: 59.0 FN: 23.0\n",
      "test Loss: 0.4028 Acc: 0.8813 Pre: 0.5333 Rec: 0.3955 F1: 0.4542\n",
      "TP: 176.0 TN: 2964.0 FP: 154.0 FN: 269.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1420 Acc: 0.9514 Pre: 0.8593 Rec: 0.6726 F1: 0.7546\n",
      "TP: 226.0 TN: 2653.0 FP: 37.0 FN: 110.0\n",
      "val Loss: 0.0979 Acc: 0.9663 Pre: 0.7955 Rec: 0.9375 F1: 0.8607\n",
      "TP: 315.0 TN: 2609.0 FP: 81.0 FN: 21.0\n",
      "test Loss: 0.4045 Acc: 0.8754 Pre: 0.5013 Rec: 0.4225 F1: 0.4585\n",
      "TP: 188.0 TN: 2931.0 FP: 187.0 FN: 257.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1431 Acc: 0.9537 Pre: 0.8984 Rec: 0.6577 F1: 0.7595\n",
      "TP: 221.0 TN: 2665.0 FP: 25.0 FN: 115.0\n",
      "val Loss: 0.1063 Acc: 0.9646 Pre: 0.7800 Rec: 0.9494 F1: 0.8564\n",
      "TP: 319.0 TN: 2600.0 FP: 90.0 FN: 17.0\n",
      "test Loss: 0.4247 Acc: 0.8692 Pre: 0.4742 Rec: 0.4337 F1: 0.4531\n",
      "TP: 193.0 TN: 2904.0 FP: 214.0 FN: 252.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1357 Acc: 0.9511 Pre: 0.8884 Rec: 0.6399 F1: 0.7439\n",
      "TP: 215.0 TN: 2663.0 FP: 27.0 FN: 121.0\n",
      "val Loss: 0.0901 Acc: 0.9683 Pre: 0.8125 Rec: 0.9286 F1: 0.8667\n",
      "TP: 312.0 TN: 2618.0 FP: 72.0 FN: 24.0\n",
      "test Loss: 0.4004 Acc: 0.8821 Pre: 0.5369 Rec: 0.4090 F1: 0.4643\n",
      "TP: 182.0 TN: 2961.0 FP: 157.0 FN: 263.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9541 Pre: 0.8833 Rec: 0.6756 F1: 0.7656\n",
      "TP: 227.0 TN: 2660.0 FP: 30.0 FN: 109.0\n",
      "val Loss: 0.0861 Acc: 0.9693 Pre: 0.8140 Rec: 0.9375 F1: 0.8714\n",
      "TP: 315.0 TN: 2618.0 FP: 72.0 FN: 21.0\n",
      "test Loss: 0.4108 Acc: 0.8793 Pre: 0.5217 Rec: 0.4045 F1: 0.4557\n",
      "TP: 180.0 TN: 2953.0 FP: 165.0 FN: 265.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1458 Acc: 0.9488 Pre: 0.8787 Rec: 0.6250 F1: 0.7304\n",
      "TP: 210.0 TN: 2661.0 FP: 29.0 FN: 126.0\n",
      "val Loss: 0.0753 Acc: 0.9739 Pre: 0.8599 Rec: 0.9137 F1: 0.8860\n",
      "TP: 307.0 TN: 2640.0 FP: 50.0 FN: 29.0\n",
      "test Loss: 0.4114 Acc: 0.8807 Pre: 0.5333 Rec: 0.3596 F1: 0.4295\n",
      "TP: 160.0 TN: 2978.0 FP: 140.0 FN: 285.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1600 Acc: 0.9475 Pre: 0.8612 Rec: 0.6280 F1: 0.7263\n",
      "TP: 211.0 TN: 2656.0 FP: 34.0 FN: 125.0\n",
      "val Loss: 0.1082 Acc: 0.9620 Pre: 0.7689 Rec: 0.9405 F1: 0.8461\n",
      "TP: 316.0 TN: 2595.0 FP: 95.0 FN: 20.0\n",
      "test Loss: 0.3917 Acc: 0.8698 Pre: 0.4764 Rec: 0.4315 F1: 0.4528\n",
      "TP: 192.0 TN: 2907.0 FP: 211.0 FN: 253.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1282 Acc: 0.9554 Pre: 0.8941 Rec: 0.6786 F1: 0.7716\n",
      "TP: 228.0 TN: 2663.0 FP: 27.0 FN: 108.0\n",
      "val Loss: 0.0746 Acc: 0.9726 Pre: 0.8543 Rec: 0.9077 F1: 0.8802\n",
      "TP: 305.0 TN: 2638.0 FP: 52.0 FN: 31.0\n",
      "test Loss: 0.4095 Acc: 0.8846 Pre: 0.5559 Rec: 0.3798 F1: 0.4513\n",
      "TP: 169.0 TN: 2983.0 FP: 135.0 FN: 276.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1404 Acc: 0.9508 Pre: 0.8755 Rec: 0.6488 F1: 0.7453\n",
      "TP: 218.0 TN: 2659.0 FP: 31.0 FN: 118.0\n",
      "val Loss: 0.0725 Acc: 0.9749 Pre: 0.8736 Rec: 0.9048 F1: 0.8889\n",
      "TP: 304.0 TN: 2646.0 FP: 44.0 FN: 32.0\n",
      "test Loss: 0.4043 Acc: 0.8855 Pre: 0.5668 Rec: 0.3528 F1: 0.4349\n",
      "TP: 157.0 TN: 2998.0 FP: 120.0 FN: 288.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1327 Acc: 0.9541 Pre: 0.8956 Rec: 0.6637 F1: 0.7624\n",
      "TP: 223.0 TN: 2664.0 FP: 26.0 FN: 113.0\n",
      "val Loss: 0.1037 Acc: 0.9653 Pre: 0.7824 Rec: 0.9524 F1: 0.8591\n",
      "TP: 320.0 TN: 2601.0 FP: 89.0 FN: 16.0\n",
      "test Loss: 0.4086 Acc: 0.8684 Pre: 0.4716 Rec: 0.4472 F1: 0.4591\n",
      "TP: 199.0 TN: 2895.0 FP: 223.0 FN: 246.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1397 Acc: 0.9551 Pre: 0.8846 Rec: 0.6845 F1: 0.7718\n",
      "TP: 230.0 TN: 2660.0 FP: 30.0 FN: 106.0\n",
      "val Loss: 0.0795 Acc: 0.9732 Pre: 0.8493 Rec: 0.9226 F1: 0.8845\n",
      "TP: 310.0 TN: 2635.0 FP: 55.0 FN: 26.0\n",
      "test Loss: 0.4030 Acc: 0.8832 Pre: 0.5472 Rec: 0.3775 F1: 0.4468\n",
      "TP: 168.0 TN: 2979.0 FP: 139.0 FN: 277.0\n",
      "\n",
      "Training complete in 30m 45s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3311 Acc: 0.8876 Pre: 0.4767 Rec: 0.1220 F1: 0.1943\n",
      "TP: 41.0 TN: 2645.0 FP: 45.0 FN: 295.0\n",
      "val Loss: 0.2267 Acc: 0.9088 Pre: 0.7632 Rec: 0.2589 F1: 0.3867\n",
      "TP: 87.0 TN: 2663.0 FP: 27.0 FN: 249.0\n",
      "test Loss: 0.3319 Acc: 0.8875 Pre: 0.7619 Rec: 0.1438 F1: 0.2420\n",
      "TP: 64.0 TN: 3098.0 FP: 20.0 FN: 381.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.3155 Acc: 0.8900 Pre: 0.5135 Rec: 0.1696 F1: 0.2550\n",
      "TP: 57.0 TN: 2636.0 FP: 54.0 FN: 279.0\n",
      "val Loss: 0.2014 Acc: 0.9280 Pre: 0.7379 Rec: 0.5446 F1: 0.6267\n",
      "TP: 183.0 TN: 2625.0 FP: 65.0 FN: 153.0\n",
      "test Loss: 0.3197 Acc: 0.8914 Pre: 0.6295 Rec: 0.3169 F1: 0.4215\n",
      "TP: 141.0 TN: 3035.0 FP: 83.0 FN: 304.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2845 Acc: 0.8976 Pre: 0.6000 Rec: 0.2321 F1: 0.3348\n",
      "TP: 78.0 TN: 2638.0 FP: 52.0 FN: 258.0\n",
      "val Loss: 0.2527 Acc: 0.9147 Pre: 0.5777 Rec: 0.8631 F1: 0.6921\n",
      "TP: 290.0 TN: 2478.0 FP: 212.0 FN: 46.0\n",
      "test Loss: 0.3586 Acc: 0.8588 Pre: 0.4478 Rec: 0.5596 F1: 0.4975\n",
      "TP: 249.0 TN: 2811.0 FP: 307.0 FN: 196.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2583 Acc: 0.9124 Pre: 0.7126 Rec: 0.3542 F1: 0.4732\n",
      "TP: 119.0 TN: 2642.0 FP: 48.0 FN: 217.0\n",
      "val Loss: 0.1798 Acc: 0.9395 Pre: 0.6792 Rec: 0.8631 F1: 0.7602\n",
      "TP: 290.0 TN: 2553.0 FP: 137.0 FN: 46.0\n",
      "test Loss: 0.3845 Acc: 0.8507 Pre: 0.4145 Rec: 0.4742 F1: 0.4423\n",
      "TP: 211.0 TN: 2820.0 FP: 298.0 FN: 234.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2382 Acc: 0.9131 Pre: 0.6853 Rec: 0.4018 F1: 0.5066\n",
      "TP: 135.0 TN: 2628.0 FP: 62.0 FN: 201.0\n",
      "val Loss: 0.2659 Acc: 0.8810 Pre: 0.4798 Rec: 0.8482 F1: 0.6129\n",
      "TP: 285.0 TN: 2381.0 FP: 309.0 FN: 51.0\n",
      "test Loss: 0.4074 Acc: 0.8395 Pre: 0.4104 Rec: 0.6539 F1: 0.5043\n",
      "TP: 291.0 TN: 2700.0 FP: 418.0 FN: 154.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2303 Acc: 0.9144 Pre: 0.6974 Rec: 0.4048 F1: 0.5122\n",
      "TP: 136.0 TN: 2631.0 FP: 59.0 FN: 200.0\n",
      "val Loss: 0.1349 Acc: 0.9478 Pre: 0.8504 Rec: 0.6429 F1: 0.7322\n",
      "TP: 216.0 TN: 2652.0 FP: 38.0 FN: 120.0\n",
      "test Loss: 0.3782 Acc: 0.8897 Pre: 0.6429 Rec: 0.2629 F1: 0.3732\n",
      "TP: 117.0 TN: 3053.0 FP: 65.0 FN: 328.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2031 Acc: 0.9263 Pre: 0.7897 Rec: 0.4583 F1: 0.5800\n",
      "TP: 154.0 TN: 2649.0 FP: 41.0 FN: 182.0\n",
      "val Loss: 0.1622 Acc: 0.9412 Pre: 0.6837 Rec: 0.8750 F1: 0.7676\n",
      "TP: 294.0 TN: 2554.0 FP: 136.0 FN: 42.0\n",
      "test Loss: 0.3738 Acc: 0.8647 Pre: 0.4611 Rec: 0.4921 F1: 0.4761\n",
      "TP: 219.0 TN: 2862.0 FP: 256.0 FN: 226.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1798 Acc: 0.9339 Pre: 0.8269 Rec: 0.5119 F1: 0.6324\n",
      "TP: 172.0 TN: 2654.0 FP: 36.0 FN: 164.0\n",
      "val Loss: 0.1236 Acc: 0.9544 Pre: 0.7552 Rec: 0.8720 F1: 0.8094\n",
      "TP: 293.0 TN: 2595.0 FP: 95.0 FN: 43.0\n",
      "test Loss: 0.3526 Acc: 0.8751 Pre: 0.5000 Rec: 0.4764 F1: 0.4879\n",
      "TP: 212.0 TN: 2906.0 FP: 212.0 FN: 233.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1780 Acc: 0.9392 Pre: 0.8304 Rec: 0.5685 F1: 0.6749\n",
      "TP: 191.0 TN: 2651.0 FP: 39.0 FN: 145.0\n",
      "val Loss: 0.1820 Acc: 0.9346 Pre: 0.6397 Rec: 0.9405 F1: 0.7614\n",
      "TP: 316.0 TN: 2512.0 FP: 178.0 FN: 20.0\n",
      "test Loss: 0.4430 Acc: 0.8305 Pre: 0.3801 Rec: 0.5663 F1: 0.4549\n",
      "TP: 252.0 TN: 2707.0 FP: 411.0 FN: 193.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1634 Acc: 0.9402 Pre: 0.8384 Rec: 0.5714 F1: 0.6796\n",
      "TP: 192.0 TN: 2653.0 FP: 37.0 FN: 144.0\n",
      "val Loss: 0.0996 Acc: 0.9623 Pre: 0.8033 Rec: 0.8750 F1: 0.8376\n",
      "TP: 294.0 TN: 2618.0 FP: 72.0 FN: 42.0\n",
      "test Loss: 0.3539 Acc: 0.8832 Pre: 0.5408 Rec: 0.4315 F1: 0.4800\n",
      "TP: 192.0 TN: 2955.0 FP: 163.0 FN: 253.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1613 Acc: 0.9448 Pre: 0.8824 Rec: 0.5804 F1: 0.7002\n",
      "TP: 195.0 TN: 2664.0 FP: 26.0 FN: 141.0\n",
      "val Loss: 0.0936 Acc: 0.9653 Pre: 0.8164 Rec: 0.8869 F1: 0.8502\n",
      "TP: 298.0 TN: 2623.0 FP: 67.0 FN: 38.0\n",
      "test Loss: 0.3463 Acc: 0.8844 Pre: 0.5447 Rec: 0.4517 F1: 0.4939\n",
      "TP: 201.0 TN: 2950.0 FP: 168.0 FN: 244.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1631 Acc: 0.9445 Pre: 0.8529 Rec: 0.6042 F1: 0.7073\n",
      "TP: 203.0 TN: 2655.0 FP: 35.0 FN: 133.0\n",
      "val Loss: 0.0850 Acc: 0.9676 Pre: 0.8420 Rec: 0.8720 F1: 0.8567\n",
      "TP: 293.0 TN: 2635.0 FP: 55.0 FN: 43.0\n",
      "test Loss: 0.3403 Acc: 0.8846 Pre: 0.5509 Rec: 0.4135 F1: 0.4724\n",
      "TP: 184.0 TN: 2968.0 FP: 150.0 FN: 261.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1564 Acc: 0.9448 Pre: 0.8394 Rec: 0.6220 F1: 0.7145\n",
      "TP: 209.0 TN: 2650.0 FP: 40.0 FN: 127.0\n",
      "val Loss: 0.0809 Acc: 0.9716 Pre: 0.8551 Rec: 0.8958 F1: 0.8750\n",
      "TP: 301.0 TN: 2639.0 FP: 51.0 FN: 35.0\n",
      "test Loss: 0.3446 Acc: 0.8875 Pre: 0.5667 Rec: 0.4202 F1: 0.4826\n",
      "TP: 187.0 TN: 2975.0 FP: 143.0 FN: 258.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1502 Acc: 0.9504 Pre: 0.8690 Rec: 0.6518 F1: 0.7449\n",
      "TP: 219.0 TN: 2657.0 FP: 33.0 FN: 117.0\n",
      "val Loss: 0.0960 Acc: 0.9630 Pre: 0.7872 Rec: 0.9137 F1: 0.8457\n",
      "TP: 307.0 TN: 2607.0 FP: 83.0 FN: 29.0\n",
      "test Loss: 0.3515 Acc: 0.8793 Pre: 0.5203 Rec: 0.4315 F1: 0.4717\n",
      "TP: 192.0 TN: 2941.0 FP: 177.0 FN: 253.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1452 Acc: 0.9534 Pre: 0.8980 Rec: 0.6548 F1: 0.7573\n",
      "TP: 220.0 TN: 2665.0 FP: 25.0 FN: 116.0\n",
      "val Loss: 0.1107 Acc: 0.9594 Pre: 0.7579 Rec: 0.9315 F1: 0.8358\n",
      "TP: 313.0 TN: 2590.0 FP: 100.0 FN: 23.0\n",
      "test Loss: 0.3535 Acc: 0.8723 Pre: 0.4887 Rec: 0.4854 F1: 0.4870\n",
      "TP: 216.0 TN: 2892.0 FP: 226.0 FN: 229.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1487 Acc: 0.9494 Pre: 0.8861 Rec: 0.6250 F1: 0.7330\n",
      "TP: 210.0 TN: 2663.0 FP: 27.0 FN: 126.0\n",
      "val Loss: 0.0834 Acc: 0.9706 Pre: 0.8440 Rec: 0.9018 F1: 0.8719\n",
      "TP: 303.0 TN: 2634.0 FP: 56.0 FN: 33.0\n",
      "test Loss: 0.3269 Acc: 0.8875 Pre: 0.5659 Rec: 0.4247 F1: 0.4852\n",
      "TP: 189.0 TN: 2973.0 FP: 145.0 FN: 256.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1531 Acc: 0.9484 Pre: 0.8629 Rec: 0.6369 F1: 0.7329\n",
      "TP: 214.0 TN: 2656.0 FP: 34.0 FN: 122.0\n",
      "val Loss: 0.1197 Acc: 0.9564 Pre: 0.7361 Rec: 0.9464 F1: 0.8281\n",
      "TP: 318.0 TN: 2576.0 FP: 114.0 FN: 18.0\n",
      "test Loss: 0.3777 Acc: 0.8681 Pre: 0.4739 Rec: 0.5101 F1: 0.4913\n",
      "TP: 227.0 TN: 2866.0 FP: 252.0 FN: 218.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1394 Acc: 0.9501 Pre: 0.8685 Rec: 0.6488 F1: 0.7428\n",
      "TP: 218.0 TN: 2657.0 FP: 33.0 FN: 118.0\n",
      "val Loss: 0.0841 Acc: 0.9699 Pre: 0.8393 Rec: 0.9018 F1: 0.8694\n",
      "TP: 303.0 TN: 2632.0 FP: 58.0 FN: 33.0\n",
      "test Loss: 0.3525 Acc: 0.8793 Pre: 0.5203 Rec: 0.4315 F1: 0.4717\n",
      "TP: 192.0 TN: 2941.0 FP: 177.0 FN: 253.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1564 Acc: 0.9432 Pre: 0.8280 Rec: 0.6161 F1: 0.7065\n",
      "TP: 207.0 TN: 2647.0 FP: 43.0 FN: 129.0\n",
      "val Loss: 0.0864 Acc: 0.9712 Pre: 0.8374 Rec: 0.9196 F1: 0.8766\n",
      "TP: 309.0 TN: 2630.0 FP: 60.0 FN: 27.0\n",
      "test Loss: 0.3415 Acc: 0.8832 Pre: 0.5418 Rec: 0.4225 F1: 0.4747\n",
      "TP: 188.0 TN: 2959.0 FP: 159.0 FN: 257.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1437 Acc: 0.9501 Pre: 0.8838 Rec: 0.6339 F1: 0.7383\n",
      "TP: 213.0 TN: 2662.0 FP: 28.0 FN: 123.0\n",
      "val Loss: 0.1116 Acc: 0.9623 Pre: 0.7707 Rec: 0.9405 F1: 0.8472\n",
      "TP: 316.0 TN: 2596.0 FP: 94.0 FN: 20.0\n",
      "test Loss: 0.3561 Acc: 0.8720 Pre: 0.4880 Rec: 0.5011 F1: 0.4945\n",
      "TP: 223.0 TN: 2884.0 FP: 234.0 FN: 222.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1530 Acc: 0.9494 Pre: 0.8797 Rec: 0.6310 F1: 0.7348\n",
      "TP: 212.0 TN: 2661.0 FP: 29.0 FN: 124.0\n",
      "val Loss: 0.0991 Acc: 0.9633 Pre: 0.7778 Rec: 0.9375 F1: 0.8502\n",
      "TP: 315.0 TN: 2600.0 FP: 90.0 FN: 21.0\n",
      "test Loss: 0.3952 Acc: 0.8712 Pre: 0.4842 Rec: 0.4831 F1: 0.4837\n",
      "TP: 215.0 TN: 2889.0 FP: 229.0 FN: 230.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1341 Acc: 0.9577 Pre: 0.9000 Rec: 0.6964 F1: 0.7852\n",
      "TP: 234.0 TN: 2664.0 FP: 26.0 FN: 102.0\n",
      "val Loss: 0.0939 Acc: 0.9666 Pre: 0.8021 Rec: 0.9286 F1: 0.8607\n",
      "TP: 312.0 TN: 2613.0 FP: 77.0 FN: 24.0\n",
      "test Loss: 0.3587 Acc: 0.8771 Pre: 0.5088 Rec: 0.4562 F1: 0.4810\n",
      "TP: 203.0 TN: 2922.0 FP: 196.0 FN: 242.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1516 Acc: 0.9494 Pre: 0.8645 Rec: 0.6458 F1: 0.7394\n",
      "TP: 217.0 TN: 2656.0 FP: 34.0 FN: 119.0\n",
      "val Loss: 0.0970 Acc: 0.9653 Pre: 0.7954 Rec: 0.9256 F1: 0.8556\n",
      "TP: 311.0 TN: 2610.0 FP: 80.0 FN: 25.0\n",
      "test Loss: 0.3511 Acc: 0.8790 Pre: 0.5172 Rec: 0.4742 F1: 0.4947\n",
      "TP: 211.0 TN: 2921.0 FP: 197.0 FN: 234.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1453 Acc: 0.9508 Pre: 0.8979 Rec: 0.6280 F1: 0.7391\n",
      "TP: 211.0 TN: 2666.0 FP: 24.0 FN: 125.0\n",
      "val Loss: 0.0915 Acc: 0.9699 Pre: 0.8165 Rec: 0.9405 F1: 0.8741\n",
      "TP: 316.0 TN: 2619.0 FP: 71.0 FN: 20.0\n",
      "test Loss: 0.3692 Acc: 0.8765 Pre: 0.5062 Rec: 0.4607 F1: 0.4824\n",
      "TP: 205.0 TN: 2918.0 FP: 200.0 FN: 240.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1444 Acc: 0.9471 Pre: 0.8729 Rec: 0.6131 F1: 0.7203\n",
      "TP: 206.0 TN: 2660.0 FP: 30.0 FN: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0819 Acc: 0.9696 Pre: 0.8280 Rec: 0.9167 F1: 0.8701\n",
      "TP: 308.0 TN: 2626.0 FP: 64.0 FN: 28.0\n",
      "test Loss: 0.3528 Acc: 0.8861 Pre: 0.5549 Rec: 0.4427 F1: 0.4925\n",
      "TP: 197.0 TN: 2960.0 FP: 158.0 FN: 248.0\n",
      "\n",
      "Training complete in 28m 8s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3436 Acc: 0.8820 Pre: 0.2000 Rec: 0.0208 F1: 0.0377\n",
      "TP: 7.0 TN: 2662.0 FP: 28.0 FN: 329.0\n",
      "val Loss: 0.2458 Acc: 0.9065 Pre: 0.5943 Rec: 0.4970 F1: 0.5413\n",
      "TP: 167.0 TN: 2576.0 FP: 114.0 FN: 169.0\n",
      "test Loss: 0.3063 Acc: 0.8880 Pre: 0.5737 Rec: 0.4022 F1: 0.4729\n",
      "TP: 179.0 TN: 2985.0 FP: 133.0 FN: 266.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2925 Acc: 0.8969 Pre: 0.6277 Rec: 0.1756 F1: 0.2744\n",
      "TP: 59.0 TN: 2655.0 FP: 35.0 FN: 277.0\n",
      "val Loss: 0.2435 Acc: 0.9095 Pre: 0.5671 Rec: 0.7798 F1: 0.6566\n",
      "TP: 262.0 TN: 2490.0 FP: 200.0 FN: 74.0\n",
      "test Loss: 0.3323 Acc: 0.8647 Pre: 0.4635 Rec: 0.5281 F1: 0.4937\n",
      "TP: 235.0 TN: 2846.0 FP: 272.0 FN: 210.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2802 Acc: 0.8942 Pre: 0.5541 Rec: 0.2440 F1: 0.3388\n",
      "TP: 82.0 TN: 2624.0 FP: 66.0 FN: 254.0\n",
      "val Loss: 0.2033 Acc: 0.9365 Pre: 0.7500 Rec: 0.6429 F1: 0.6923\n",
      "TP: 216.0 TN: 2618.0 FP: 72.0 FN: 120.0\n",
      "test Loss: 0.3131 Acc: 0.8877 Pre: 0.5882 Rec: 0.3371 F1: 0.4286\n",
      "TP: 150.0 TN: 3013.0 FP: 105.0 FN: 295.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2659 Acc: 0.9078 Pre: 0.6770 Rec: 0.3244 F1: 0.4386\n",
      "TP: 109.0 TN: 2638.0 FP: 52.0 FN: 227.0\n",
      "val Loss: 0.2388 Acc: 0.9065 Pre: 0.5521 Rec: 0.8363 F1: 0.6651\n",
      "TP: 281.0 TN: 2462.0 FP: 228.0 FN: 55.0\n",
      "test Loss: 0.3654 Acc: 0.8642 Pre: 0.4623 Rec: 0.5371 F1: 0.4969\n",
      "TP: 239.0 TN: 2840.0 FP: 278.0 FN: 206.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2342 Acc: 0.9157 Pre: 0.6901 Rec: 0.4375 F1: 0.5355\n",
      "TP: 147.0 TN: 2624.0 FP: 66.0 FN: 189.0\n",
      "val Loss: 0.1323 Acc: 0.9557 Pre: 0.9073 Rec: 0.6696 F1: 0.7705\n",
      "TP: 225.0 TN: 2667.0 FP: 23.0 FN: 111.0\n",
      "test Loss: 0.3056 Acc: 0.8964 Pre: 0.6959 Rec: 0.3034 F1: 0.4225\n",
      "TP: 135.0 TN: 3059.0 FP: 59.0 FN: 310.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2402 Acc: 0.9194 Pre: 0.7614 Rec: 0.3988 F1: 0.5234\n",
      "TP: 134.0 TN: 2648.0 FP: 42.0 FN: 202.0\n",
      "val Loss: 0.2335 Acc: 0.9108 Pre: 0.5635 Rec: 0.8720 F1: 0.6846\n",
      "TP: 293.0 TN: 2463.0 FP: 227.0 FN: 43.0\n",
      "test Loss: 0.4305 Acc: 0.8487 Pre: 0.4299 Rec: 0.6472 F1: 0.5166\n",
      "TP: 288.0 TN: 2736.0 FP: 382.0 FN: 157.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1802 Acc: 0.9382 Pre: 0.8170 Rec: 0.5714 F1: 0.6725\n",
      "TP: 192.0 TN: 2647.0 FP: 43.0 FN: 144.0\n",
      "val Loss: 0.1320 Acc: 0.9518 Pre: 0.7436 Rec: 0.8631 F1: 0.7989\n",
      "TP: 290.0 TN: 2590.0 FP: 100.0 FN: 46.0\n",
      "test Loss: 0.3669 Acc: 0.8782 Pre: 0.5124 Rec: 0.5101 F1: 0.5113\n",
      "TP: 227.0 TN: 2902.0 FP: 216.0 FN: 218.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1772 Acc: 0.9365 Pre: 0.8303 Rec: 0.5387 F1: 0.6534\n",
      "TP: 181.0 TN: 2653.0 FP: 37.0 FN: 155.0\n",
      "val Loss: 0.1183 Acc: 0.9544 Pre: 0.7605 Rec: 0.8601 F1: 0.8073\n",
      "TP: 289.0 TN: 2599.0 FP: 91.0 FN: 47.0\n",
      "test Loss: 0.3610 Acc: 0.8776 Pre: 0.5112 Rec: 0.4629 F1: 0.4858\n",
      "TP: 206.0 TN: 2921.0 FP: 197.0 FN: 239.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1808 Acc: 0.9326 Pre: 0.8204 Rec: 0.5030 F1: 0.6236\n",
      "TP: 169.0 TN: 2653.0 FP: 37.0 FN: 167.0\n",
      "val Loss: 0.0939 Acc: 0.9610 Pre: 0.8150 Rec: 0.8393 F1: 0.8270\n",
      "TP: 282.0 TN: 2626.0 FP: 64.0 FN: 54.0\n",
      "test Loss: 0.3666 Acc: 0.8863 Pre: 0.5595 Rec: 0.4225 F1: 0.4814\n",
      "TP: 188.0 TN: 2970.0 FP: 148.0 FN: 257.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1650 Acc: 0.9418 Pre: 0.8361 Rec: 0.5923 F1: 0.6934\n",
      "TP: 199.0 TN: 2651.0 FP: 39.0 FN: 137.0\n",
      "val Loss: 0.1086 Acc: 0.9557 Pre: 0.7790 Rec: 0.8393 F1: 0.8080\n",
      "TP: 282.0 TN: 2610.0 FP: 80.0 FN: 54.0\n",
      "test Loss: 0.3473 Acc: 0.8846 Pre: 0.5467 Rec: 0.4472 F1: 0.4920\n",
      "TP: 199.0 TN: 2953.0 FP: 165.0 FN: 246.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1638 Acc: 0.9428 Pre: 0.8655 Rec: 0.5744 F1: 0.6905\n",
      "TP: 193.0 TN: 2660.0 FP: 30.0 FN: 143.0\n",
      "val Loss: 0.1125 Acc: 0.9580 Pre: 0.7714 Rec: 0.8839 F1: 0.8239\n",
      "TP: 297.0 TN: 2602.0 FP: 88.0 FN: 39.0\n",
      "test Loss: 0.3558 Acc: 0.8810 Pre: 0.5247 Rec: 0.5011 F1: 0.5126\n",
      "TP: 223.0 TN: 2916.0 FP: 202.0 FN: 222.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1576 Acc: 0.9451 Pre: 0.8632 Rec: 0.6012 F1: 0.7088\n",
      "TP: 202.0 TN: 2658.0 FP: 32.0 FN: 134.0\n",
      "val Loss: 0.1103 Acc: 0.9607 Pre: 0.7692 Rec: 0.9226 F1: 0.8390\n",
      "TP: 310.0 TN: 2597.0 FP: 93.0 FN: 26.0\n",
      "test Loss: 0.3788 Acc: 0.8743 Pre: 0.4967 Rec: 0.5011 F1: 0.4989\n",
      "TP: 223.0 TN: 2892.0 FP: 226.0 FN: 222.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1418 Acc: 0.9518 Pre: 0.8800 Rec: 0.6548 F1: 0.7509\n",
      "TP: 220.0 TN: 2660.0 FP: 30.0 FN: 116.0\n",
      "val Loss: 0.0814 Acc: 0.9686 Pre: 0.8338 Rec: 0.8958 F1: 0.8637\n",
      "TP: 301.0 TN: 2630.0 FP: 60.0 FN: 35.0\n",
      "test Loss: 0.3750 Acc: 0.8861 Pre: 0.5520 Rec: 0.4652 F1: 0.5049\n",
      "TP: 207.0 TN: 2950.0 FP: 168.0 FN: 238.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1479 Acc: 0.9501 Pre: 0.8838 Rec: 0.6339 F1: 0.7383\n",
      "TP: 213.0 TN: 2662.0 FP: 28.0 FN: 123.0\n",
      "val Loss: 0.0920 Acc: 0.9646 Pre: 0.8021 Rec: 0.9048 F1: 0.8503\n",
      "TP: 304.0 TN: 2615.0 FP: 75.0 FN: 32.0\n",
      "test Loss: 0.4014 Acc: 0.8782 Pre: 0.5135 Rec: 0.4697 F1: 0.4906\n",
      "TP: 209.0 TN: 2920.0 FP: 198.0 FN: 236.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1503 Acc: 0.9435 Pre: 0.8313 Rec: 0.6161 F1: 0.7077\n",
      "TP: 207.0 TN: 2648.0 FP: 42.0 FN: 129.0\n",
      "val Loss: 0.1013 Acc: 0.9636 Pre: 0.7854 Rec: 0.9256 F1: 0.8497\n",
      "TP: 311.0 TN: 2605.0 FP: 85.0 FN: 25.0\n",
      "test Loss: 0.3816 Acc: 0.8754 Pre: 0.5011 Rec: 0.5079 F1: 0.5045\n",
      "TP: 226.0 TN: 2893.0 FP: 225.0 FN: 219.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1530 Acc: 0.9475 Pre: 0.8703 Rec: 0.6190 F1: 0.7235\n",
      "TP: 208.0 TN: 2659.0 FP: 31.0 FN: 128.0\n",
      "val Loss: 0.0742 Acc: 0.9703 Pre: 0.8555 Rec: 0.8810 F1: 0.8680\n",
      "TP: 296.0 TN: 2640.0 FP: 50.0 FN: 40.0\n",
      "test Loss: 0.3946 Acc: 0.8824 Pre: 0.5376 Rec: 0.4180 F1: 0.4703\n",
      "TP: 186.0 TN: 2958.0 FP: 160.0 FN: 259.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9455 Pre: 0.8462 Rec: 0.6220 F1: 0.7170\n",
      "TP: 209.0 TN: 2652.0 FP: 38.0 FN: 127.0\n",
      "val Loss: 0.0810 Acc: 0.9679 Pre: 0.8347 Rec: 0.8869 F1: 0.8600\n",
      "TP: 298.0 TN: 2631.0 FP: 59.0 FN: 38.0\n",
      "test Loss: 0.3690 Acc: 0.8816 Pre: 0.5312 Rec: 0.4404 F1: 0.4816\n",
      "TP: 196.0 TN: 2945.0 FP: 173.0 FN: 249.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1584 Acc: 0.9448 Pre: 0.8506 Rec: 0.6101 F1: 0.7106\n",
      "TP: 205.0 TN: 2654.0 FP: 36.0 FN: 131.0\n",
      "val Loss: 0.0807 Acc: 0.9686 Pre: 0.8283 Rec: 0.9048 F1: 0.8649\n",
      "TP: 304.0 TN: 2627.0 FP: 63.0 FN: 32.0\n",
      "test Loss: 0.3749 Acc: 0.8796 Pre: 0.5200 Rec: 0.4674 F1: 0.4923\n",
      "TP: 208.0 TN: 2926.0 FP: 192.0 FN: 237.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1524 Acc: 0.9478 Pre: 0.8618 Rec: 0.6310 F1: 0.7285\n",
      "TP: 212.0 TN: 2656.0 FP: 34.0 FN: 124.0\n",
      "val Loss: 0.0826 Acc: 0.9693 Pre: 0.8347 Rec: 0.9018 F1: 0.8670\n",
      "TP: 303.0 TN: 2630.0 FP: 60.0 FN: 33.0\n",
      "test Loss: 0.3778 Acc: 0.8813 Pre: 0.5281 Rec: 0.4652 F1: 0.4946\n",
      "TP: 207.0 TN: 2933.0 FP: 185.0 FN: 238.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1436 Acc: 0.9504 Pre: 0.8750 Rec: 0.6458 F1: 0.7432\n",
      "TP: 217.0 TN: 2659.0 FP: 31.0 FN: 119.0\n",
      "val Loss: 0.0634 Acc: 0.9732 Pre: 0.9126 Rec: 0.8393 F1: 0.8744\n",
      "TP: 282.0 TN: 2663.0 FP: 27.0 FN: 54.0\n",
      "test Loss: 0.3978 Acc: 0.8905 Pre: 0.6122 Rec: 0.3371 F1: 0.4348\n",
      "TP: 150.0 TN: 3023.0 FP: 95.0 FN: 295.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1434 Acc: 0.9511 Pre: 0.8950 Rec: 0.6339 F1: 0.7422\n",
      "TP: 213.0 TN: 2665.0 FP: 25.0 FN: 123.0\n",
      "val Loss: 0.0754 Acc: 0.9706 Pre: 0.8580 Rec: 0.8810 F1: 0.8693\n",
      "TP: 296.0 TN: 2641.0 FP: 49.0 FN: 40.0\n",
      "test Loss: 0.3691 Acc: 0.8841 Pre: 0.5482 Rec: 0.4090 F1: 0.4685\n",
      "TP: 182.0 TN: 2968.0 FP: 150.0 FN: 263.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1394 Acc: 0.9491 Pre: 0.8640 Rec: 0.6429 F1: 0.7372\n",
      "TP: 216.0 TN: 2656.0 FP: 34.0 FN: 120.0\n",
      "val Loss: 0.1178 Acc: 0.9587 Pre: 0.7506 Rec: 0.9405 F1: 0.8349\n",
      "TP: 316.0 TN: 2585.0 FP: 105.0 FN: 20.0\n",
      "test Loss: 0.3972 Acc: 0.8633 Pre: 0.4601 Rec: 0.5438 F1: 0.4985\n",
      "TP: 242.0 TN: 2834.0 FP: 284.0 FN: 203.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1525 Acc: 0.9511 Pre: 0.8852 Rec: 0.6429 F1: 0.7448\n",
      "TP: 216.0 TN: 2662.0 FP: 28.0 FN: 120.0\n",
      "val Loss: 0.0900 Acc: 0.9673 Pre: 0.8127 Rec: 0.9167 F1: 0.8615\n",
      "TP: 308.0 TN: 2619.0 FP: 71.0 FN: 28.0\n",
      "test Loss: 0.3801 Acc: 0.8788 Pre: 0.5145 Rec: 0.5169 F1: 0.5157\n",
      "TP: 230.0 TN: 2901.0 FP: 217.0 FN: 215.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1415 Acc: 0.9468 Pre: 0.8755 Rec: 0.6071 F1: 0.7170\n",
      "TP: 204.0 TN: 2661.0 FP: 29.0 FN: 132.0\n",
      "val Loss: 0.0761 Acc: 0.9709 Pre: 0.8523 Rec: 0.8929 F1: 0.8721\n",
      "TP: 300.0 TN: 2638.0 FP: 52.0 FN: 36.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3716 Acc: 0.8869 Pre: 0.5593 Rec: 0.4449 F1: 0.4956\n",
      "TP: 198.0 TN: 2962.0 FP: 156.0 FN: 247.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9428 Pre: 0.8382 Rec: 0.6012 F1: 0.7002\n",
      "TP: 202.0 TN: 2651.0 FP: 39.0 FN: 134.0\n",
      "val Loss: 0.0743 Acc: 0.9719 Pre: 0.8555 Rec: 0.8988 F1: 0.8766\n",
      "TP: 302.0 TN: 2639.0 FP: 51.0 FN: 34.0\n",
      "test Loss: 0.3755 Acc: 0.8838 Pre: 0.5425 Rec: 0.4449 F1: 0.4889\n",
      "TP: 198.0 TN: 2951.0 FP: 167.0 FN: 247.0\n",
      "\n",
      "Training complete in 28m 50s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3398 Acc: 0.8833 Pre: 0.3396 Rec: 0.0536 F1: 0.0925\n",
      "TP: 18.0 TN: 2655.0 FP: 35.0 FN: 318.0\n",
      "val Loss: 0.2919 Acc: 0.8827 Pre: 0.4667 Rec: 0.3958 F1: 0.4283\n",
      "TP: 133.0 TN: 2538.0 FP: 152.0 FN: 203.0\n",
      "test Loss: 0.3461 Acc: 0.8656 Pre: 0.4267 Rec: 0.2225 F1: 0.2925\n",
      "TP: 99.0 TN: 2985.0 FP: 133.0 FN: 346.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2996 Acc: 0.8913 Pre: 0.5321 Rec: 0.1726 F1: 0.2607\n",
      "TP: 58.0 TN: 2639.0 FP: 51.0 FN: 278.0\n",
      "val Loss: 0.2111 Acc: 0.9207 Pre: 0.6472 Rec: 0.6280 F1: 0.6375\n",
      "TP: 211.0 TN: 2575.0 FP: 115.0 FN: 125.0\n",
      "test Loss: 0.3363 Acc: 0.8832 Pre: 0.5707 Rec: 0.2629 F1: 0.3600\n",
      "TP: 117.0 TN: 3030.0 FP: 88.0 FN: 328.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2761 Acc: 0.9002 Pre: 0.5988 Rec: 0.3065 F1: 0.4055\n",
      "TP: 103.0 TN: 2621.0 FP: 69.0 FN: 233.0\n",
      "val Loss: 0.2030 Acc: 0.9270 Pre: 0.6657 Rec: 0.6875 F1: 0.6764\n",
      "TP: 231.0 TN: 2574.0 FP: 116.0 FN: 105.0\n",
      "test Loss: 0.2929 Acc: 0.8861 Pre: 0.5579 Rec: 0.4225 F1: 0.4808\n",
      "TP: 188.0 TN: 2969.0 FP: 149.0 FN: 257.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2626 Acc: 0.9091 Pre: 0.6918 Rec: 0.3274 F1: 0.4444\n",
      "TP: 110.0 TN: 2641.0 FP: 49.0 FN: 226.0\n",
      "val Loss: 0.1441 Acc: 0.9488 Pre: 0.8755 Rec: 0.6280 F1: 0.7314\n",
      "TP: 211.0 TN: 2660.0 FP: 30.0 FN: 125.0\n",
      "test Loss: 0.3442 Acc: 0.8846 Pre: 0.5802 Rec: 0.2764 F1: 0.3744\n",
      "TP: 123.0 TN: 3029.0 FP: 89.0 FN: 322.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2388 Acc: 0.9210 Pre: 0.7650 Rec: 0.4167 F1: 0.5395\n",
      "TP: 140.0 TN: 2647.0 FP: 43.0 FN: 196.0\n",
      "val Loss: 0.1401 Acc: 0.9451 Pre: 0.7310 Rec: 0.8006 F1: 0.7642\n",
      "TP: 269.0 TN: 2591.0 FP: 99.0 FN: 67.0\n",
      "test Loss: 0.3772 Acc: 0.8717 Pre: 0.4858 Rec: 0.4629 F1: 0.4741\n",
      "TP: 206.0 TN: 2900.0 FP: 218.0 FN: 239.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2287 Acc: 0.9247 Pre: 0.7477 Rec: 0.4851 F1: 0.5884\n",
      "TP: 163.0 TN: 2635.0 FP: 55.0 FN: 173.0\n",
      "val Loss: 0.1048 Acc: 0.9636 Pre: 0.8951 Rec: 0.7619 F1: 0.8232\n",
      "TP: 256.0 TN: 2660.0 FP: 30.0 FN: 80.0\n",
      "test Loss: 0.3468 Acc: 0.8995 Pre: 0.7208 Rec: 0.3191 F1: 0.4424\n",
      "TP: 142.0 TN: 3063.0 FP: 55.0 FN: 303.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1913 Acc: 0.9356 Pre: 0.8473 Rec: 0.5119 F1: 0.6382\n",
      "TP: 172.0 TN: 2659.0 FP: 31.0 FN: 164.0\n",
      "val Loss: 0.1389 Acc: 0.9461 Pre: 0.7064 Rec: 0.8810 F1: 0.7841\n",
      "TP: 296.0 TN: 2567.0 FP: 123.0 FN: 40.0\n",
      "test Loss: 0.3395 Acc: 0.8776 Pre: 0.5106 Rec: 0.4854 F1: 0.4977\n",
      "TP: 216.0 TN: 2911.0 FP: 207.0 FN: 229.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1801 Acc: 0.9359 Pre: 0.8142 Rec: 0.5476 F1: 0.6548\n",
      "TP: 184.0 TN: 2648.0 FP: 42.0 FN: 152.0\n",
      "val Loss: 0.1130 Acc: 0.9574 Pre: 0.7688 Rec: 0.8810 F1: 0.8211\n",
      "TP: 296.0 TN: 2601.0 FP: 89.0 FN: 40.0\n",
      "test Loss: 0.3394 Acc: 0.8855 Pre: 0.5483 Rec: 0.4719 F1: 0.5072\n",
      "TP: 210.0 TN: 2945.0 FP: 173.0 FN: 235.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1602 Acc: 0.9442 Pre: 0.8381 Rec: 0.6161 F1: 0.7101\n",
      "TP: 207.0 TN: 2650.0 FP: 40.0 FN: 129.0\n",
      "val Loss: 0.1374 Acc: 0.9468 Pre: 0.7030 Rec: 0.9018 F1: 0.7901\n",
      "TP: 303.0 TN: 2562.0 FP: 128.0 FN: 33.0\n",
      "test Loss: 0.3615 Acc: 0.8754 Pre: 0.5011 Rec: 0.4989 F1: 0.5000\n",
      "TP: 222.0 TN: 2897.0 FP: 221.0 FN: 223.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1719 Acc: 0.9435 Pre: 0.8481 Rec: 0.5982 F1: 0.7016\n",
      "TP: 201.0 TN: 2654.0 FP: 36.0 FN: 135.0\n",
      "val Loss: 0.0992 Acc: 0.9613 Pre: 0.7967 Rec: 0.8750 F1: 0.8340\n",
      "TP: 294.0 TN: 2615.0 FP: 75.0 FN: 42.0\n",
      "test Loss: 0.3492 Acc: 0.8866 Pre: 0.5601 Rec: 0.4292 F1: 0.4860\n",
      "TP: 191.0 TN: 2968.0 FP: 150.0 FN: 254.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1605 Acc: 0.9442 Pre: 0.8646 Rec: 0.5893 F1: 0.7009\n",
      "TP: 198.0 TN: 2659.0 FP: 31.0 FN: 138.0\n",
      "val Loss: 0.0772 Acc: 0.9712 Pre: 0.8673 Rec: 0.8750 F1: 0.8711\n",
      "TP: 294.0 TN: 2645.0 FP: 45.0 FN: 42.0\n",
      "test Loss: 0.3600 Acc: 0.8936 Pre: 0.6241 Rec: 0.3730 F1: 0.4669\n",
      "TP: 166.0 TN: 3018.0 FP: 100.0 FN: 279.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1572 Acc: 0.9451 Pre: 0.8571 Rec: 0.6071 F1: 0.7108\n",
      "TP: 204.0 TN: 2656.0 FP: 34.0 FN: 132.0\n",
      "val Loss: 0.0940 Acc: 0.9630 Pre: 0.7857 Rec: 0.9167 F1: 0.8462\n",
      "TP: 308.0 TN: 2606.0 FP: 84.0 FN: 28.0\n",
      "test Loss: 0.3654 Acc: 0.8804 Pre: 0.5238 Rec: 0.4697 F1: 0.4953\n",
      "TP: 209.0 TN: 2928.0 FP: 190.0 FN: 236.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1605 Acc: 0.9468 Pre: 0.8327 Rec: 0.6518 F1: 0.7312\n",
      "TP: 219.0 TN: 2646.0 FP: 44.0 FN: 117.0\n",
      "val Loss: 0.0912 Acc: 0.9670 Pre: 0.8138 Rec: 0.9107 F1: 0.8596\n",
      "TP: 306.0 TN: 2620.0 FP: 70.0 FN: 30.0\n",
      "test Loss: 0.3513 Acc: 0.8821 Pre: 0.5369 Rec: 0.4090 F1: 0.4643\n",
      "TP: 182.0 TN: 2961.0 FP: 157.0 FN: 263.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1553 Acc: 0.9465 Pre: 0.8919 Rec: 0.5893 F1: 0.7097\n",
      "TP: 198.0 TN: 2666.0 FP: 24.0 FN: 138.0\n",
      "val Loss: 0.0758 Acc: 0.9719 Pre: 0.8575 Rec: 0.8958 F1: 0.8763\n",
      "TP: 301.0 TN: 2640.0 FP: 50.0 FN: 35.0\n",
      "test Loss: 0.3661 Acc: 0.8861 Pre: 0.5652 Rec: 0.3798 F1: 0.4543\n",
      "TP: 169.0 TN: 2988.0 FP: 130.0 FN: 276.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1403 Acc: 0.9508 Pre: 0.8816 Rec: 0.6429 F1: 0.7435\n",
      "TP: 216.0 TN: 2661.0 FP: 29.0 FN: 120.0\n",
      "val Loss: 0.0909 Acc: 0.9656 Pre: 0.8053 Rec: 0.9107 F1: 0.8547\n",
      "TP: 306.0 TN: 2616.0 FP: 74.0 FN: 30.0\n",
      "test Loss: 0.3562 Acc: 0.8816 Pre: 0.5326 Rec: 0.4225 F1: 0.4712\n",
      "TP: 188.0 TN: 2953.0 FP: 165.0 FN: 257.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1520 Acc: 0.9465 Pre: 0.8625 Rec: 0.6161 F1: 0.7187\n",
      "TP: 207.0 TN: 2657.0 FP: 33.0 FN: 129.0\n",
      "val Loss: 0.0754 Acc: 0.9716 Pre: 0.8531 Rec: 0.8988 F1: 0.8754\n",
      "TP: 302.0 TN: 2638.0 FP: 52.0 FN: 34.0\n",
      "test Loss: 0.3539 Acc: 0.8875 Pre: 0.5719 Rec: 0.3933 F1: 0.4660\n",
      "TP: 175.0 TN: 2987.0 FP: 131.0 FN: 270.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1520 Acc: 0.9455 Pre: 0.8251 Rec: 0.6458 F1: 0.7245\n",
      "TP: 217.0 TN: 2644.0 FP: 46.0 FN: 119.0\n",
      "val Loss: 0.0934 Acc: 0.9613 Pre: 0.7744 Rec: 0.9196 F1: 0.8408\n",
      "TP: 309.0 TN: 2600.0 FP: 90.0 FN: 27.0\n",
      "test Loss: 0.3636 Acc: 0.8765 Pre: 0.5063 Rec: 0.4517 F1: 0.4774\n",
      "TP: 201.0 TN: 2922.0 FP: 196.0 FN: 244.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1437 Acc: 0.9471 Pre: 0.8520 Rec: 0.6339 F1: 0.7270\n",
      "TP: 213.0 TN: 2653.0 FP: 37.0 FN: 123.0\n",
      "val Loss: 0.1011 Acc: 0.9577 Pre: 0.7500 Rec: 0.9286 F1: 0.8298\n",
      "TP: 312.0 TN: 2586.0 FP: 104.0 FN: 24.0\n",
      "test Loss: 0.3819 Acc: 0.8684 Pre: 0.4729 Rec: 0.4697 F1: 0.4713\n",
      "TP: 209.0 TN: 2885.0 FP: 233.0 FN: 236.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1418 Acc: 0.9544 Pre: 0.8929 Rec: 0.6696 F1: 0.7653\n",
      "TP: 225.0 TN: 2663.0 FP: 27.0 FN: 111.0\n",
      "val Loss: 0.0657 Acc: 0.9759 Pre: 0.8973 Rec: 0.8839 F1: 0.8906\n",
      "TP: 297.0 TN: 2656.0 FP: 34.0 FN: 39.0\n",
      "test Loss: 0.3707 Acc: 0.8914 Pre: 0.6098 Rec: 0.3618 F1: 0.4542\n",
      "TP: 161.0 TN: 3015.0 FP: 103.0 FN: 284.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1458 Acc: 0.9537 Pre: 0.8798 Rec: 0.6756 F1: 0.7643\n",
      "TP: 227.0 TN: 2659.0 FP: 31.0 FN: 109.0\n",
      "val Loss: 0.0734 Acc: 0.9716 Pre: 0.8531 Rec: 0.8988 F1: 0.8754\n",
      "TP: 302.0 TN: 2638.0 FP: 52.0 FN: 34.0\n",
      "test Loss: 0.3640 Acc: 0.8877 Pre: 0.5719 Rec: 0.4022 F1: 0.4723\n",
      "TP: 179.0 TN: 2984.0 FP: 134.0 FN: 266.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1439 Acc: 0.9521 Pre: 0.8866 Rec: 0.6518 F1: 0.7513\n",
      "TP: 219.0 TN: 2662.0 FP: 28.0 FN: 117.0\n",
      "val Loss: 0.0889 Acc: 0.9630 Pre: 0.7843 Rec: 0.9196 F1: 0.8466\n",
      "TP: 309.0 TN: 2605.0 FP: 85.0 FN: 27.0\n",
      "test Loss: 0.3632 Acc: 0.8799 Pre: 0.5208 Rec: 0.4787 F1: 0.4988\n",
      "TP: 213.0 TN: 2922.0 FP: 196.0 FN: 232.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1560 Acc: 0.9448 Pre: 0.8421 Rec: 0.6190 F1: 0.7136\n",
      "TP: 208.0 TN: 2651.0 FP: 39.0 FN: 128.0\n",
      "val Loss: 0.0647 Acc: 0.9749 Pre: 0.8801 Rec: 0.8958 F1: 0.8879\n",
      "TP: 301.0 TN: 2649.0 FP: 41.0 FN: 35.0\n",
      "test Loss: 0.3773 Acc: 0.8889 Pre: 0.5842 Rec: 0.3820 F1: 0.4620\n",
      "TP: 170.0 TN: 2997.0 FP: 121.0 FN: 275.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1401 Acc: 0.9511 Pre: 0.8852 Rec: 0.6429 F1: 0.7448\n",
      "TP: 216.0 TN: 2662.0 FP: 28.0 FN: 120.0\n",
      "val Loss: 0.0672 Acc: 0.9749 Pre: 0.8869 Rec: 0.8869 F1: 0.8869\n",
      "TP: 298.0 TN: 2652.0 FP: 38.0 FN: 38.0\n",
      "test Loss: 0.3659 Acc: 0.8919 Pre: 0.6087 Rec: 0.3775 F1: 0.4660\n",
      "TP: 168.0 TN: 3010.0 FP: 108.0 FN: 277.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1504 Acc: 0.9471 Pre: 0.8411 Rec: 0.6458 F1: 0.7306\n",
      "TP: 217.0 TN: 2649.0 FP: 41.0 FN: 119.0\n",
      "val Loss: 0.0710 Acc: 0.9712 Pre: 0.8487 Rec: 0.9018 F1: 0.8745\n",
      "TP: 303.0 TN: 2636.0 FP: 54.0 FN: 33.0\n",
      "test Loss: 0.3657 Acc: 0.8855 Pre: 0.5562 Rec: 0.4112 F1: 0.4729\n",
      "TP: 183.0 TN: 2972.0 FP: 146.0 FN: 262.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1499 Acc: 0.9524 Pre: 0.8810 Rec: 0.6607 F1: 0.7551\n",
      "TP: 222.0 TN: 2660.0 FP: 30.0 FN: 114.0\n",
      "val Loss: 0.0652 Acc: 0.9739 Pre: 0.8725 Rec: 0.8958 F1: 0.8840\n",
      "TP: 301.0 TN: 2646.0 FP: 44.0 FN: 35.0\n",
      "test Loss: 0.3763 Acc: 0.8925 Pre: 0.6054 Rec: 0.4000 F1: 0.4817\n",
      "TP: 178.0 TN: 3002.0 FP: 116.0 FN: 267.0\n",
      "\n",
      "Training complete in 28m 5s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3297 Acc: 0.8866 Pre: 0.4286 Rec: 0.0625 F1: 0.1091\n",
      "TP: 21.0 TN: 2662.0 FP: 28.0 FN: 315.0\n",
      "val Loss: 0.2573 Acc: 0.9052 Pre: 0.5698 Rec: 0.5952 F1: 0.5822\n",
      "TP: 200.0 TN: 2539.0 FP: 151.0 FN: 136.0\n",
      "test Loss: 0.3207 Acc: 0.8799 Pre: 0.5275 Rec: 0.3663 F1: 0.4324\n",
      "TP: 163.0 TN: 2972.0 FP: 146.0 FN: 282.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2930 Acc: 0.8995 Pre: 0.6270 Rec: 0.2351 F1: 0.3420\n",
      "TP: 79.0 TN: 2643.0 FP: 47.0 FN: 257.0\n",
      "val Loss: 0.2070 Acc: 0.9283 Pre: 0.7621 Rec: 0.5149 F1: 0.6146\n",
      "TP: 173.0 TN: 2636.0 FP: 54.0 FN: 163.0\n",
      "test Loss: 0.3754 Acc: 0.8788 Pre: 0.5253 Rec: 0.3034 F1: 0.3846\n",
      "TP: 135.0 TN: 2996.0 FP: 122.0 FN: 310.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2841 Acc: 0.8972 Pre: 0.5969 Rec: 0.2292 F1: 0.3312\n",
      "TP: 77.0 TN: 2638.0 FP: 52.0 FN: 259.0\n",
      "val Loss: 0.2548 Acc: 0.9068 Pre: 0.5631 Rec: 0.7173 F1: 0.6309\n",
      "TP: 241.0 TN: 2503.0 FP: 187.0 FN: 95.0\n",
      "test Loss: 0.4029 Acc: 0.8515 Pre: 0.4118 Rec: 0.4404 F1: 0.4256\n",
      "TP: 196.0 TN: 2838.0 FP: 280.0 FN: 249.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2623 Acc: 0.9088 Pre: 0.6667 Rec: 0.3571 F1: 0.4651\n",
      "TP: 120.0 TN: 2630.0 FP: 60.0 FN: 216.0\n",
      "val Loss: 0.1411 Acc: 0.9498 Pre: 0.8309 Rec: 0.6875 F1: 0.7524\n",
      "TP: 231.0 TN: 2643.0 FP: 47.0 FN: 105.0\n",
      "test Loss: 0.2961 Acc: 0.8922 Pre: 0.6142 Rec: 0.3685 F1: 0.4607\n",
      "TP: 164.0 TN: 3015.0 FP: 103.0 FN: 281.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2458 Acc: 0.9121 Pre: 0.6923 Rec: 0.3750 F1: 0.4865\n",
      "TP: 126.0 TN: 2634.0 FP: 56.0 FN: 210.0\n",
      "val Loss: 0.1515 Acc: 0.9445 Pre: 0.7958 Rec: 0.6726 F1: 0.7290\n",
      "TP: 226.0 TN: 2632.0 FP: 58.0 FN: 110.0\n",
      "test Loss: 0.4092 Acc: 0.8802 Pre: 0.5344 Rec: 0.3146 F1: 0.3960\n",
      "TP: 140.0 TN: 2996.0 FP: 122.0 FN: 305.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2400 Acc: 0.9180 Pre: 0.7366 Rec: 0.4077 F1: 0.5249\n",
      "TP: 137.0 TN: 2641.0 FP: 49.0 FN: 199.0\n",
      "val Loss: 0.1494 Acc: 0.9422 Pre: 0.7007 Rec: 0.8363 F1: 0.7626\n",
      "TP: 281.0 TN: 2570.0 FP: 120.0 FN: 55.0\n",
      "test Loss: 0.4042 Acc: 0.8552 Pre: 0.4169 Rec: 0.4000 F1: 0.4083\n",
      "TP: 178.0 TN: 2869.0 FP: 249.0 FN: 267.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1882 Acc: 0.9372 Pre: 0.8349 Rec: 0.5417 F1: 0.6570\n",
      "TP: 182.0 TN: 2654.0 FP: 36.0 FN: 154.0\n",
      "val Loss: 0.0954 Acc: 0.9660 Pre: 0.8698 Rec: 0.8155 F1: 0.8418\n",
      "TP: 274.0 TN: 2649.0 FP: 41.0 FN: 62.0\n",
      "test Loss: 0.3521 Acc: 0.8799 Pre: 0.5294 Rec: 0.3438 F1: 0.4169\n",
      "TP: 153.0 TN: 2982.0 FP: 136.0 FN: 292.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1813 Acc: 0.9385 Pre: 0.8233 Rec: 0.5685 F1: 0.6725\n",
      "TP: 191.0 TN: 2649.0 FP: 41.0 FN: 145.0\n",
      "val Loss: 0.0871 Acc: 0.9686 Pre: 0.8951 Rec: 0.8125 F1: 0.8518\n",
      "TP: 273.0 TN: 2658.0 FP: 32.0 FN: 63.0\n",
      "test Loss: 0.3724 Acc: 0.8889 Pre: 0.6008 Rec: 0.3281 F1: 0.4244\n",
      "TP: 146.0 TN: 3021.0 FP: 97.0 FN: 299.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1742 Acc: 0.9382 Pre: 0.8402 Rec: 0.5476 F1: 0.6631\n",
      "TP: 184.0 TN: 2655.0 FP: 35.0 FN: 152.0\n",
      "val Loss: 0.1087 Acc: 0.9607 Pre: 0.7956 Rec: 0.8690 F1: 0.8307\n",
      "TP: 292.0 TN: 2615.0 FP: 75.0 FN: 44.0\n",
      "test Loss: 0.3618 Acc: 0.8712 Pre: 0.4820 Rec: 0.4202 F1: 0.4490\n",
      "TP: 187.0 TN: 2917.0 FP: 201.0 FN: 258.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1701 Acc: 0.9389 Pre: 0.8213 Rec: 0.5744 F1: 0.6760\n",
      "TP: 193.0 TN: 2648.0 FP: 42.0 FN: 143.0\n",
      "val Loss: 0.0991 Acc: 0.9597 Pre: 0.7801 Rec: 0.8869 F1: 0.8301\n",
      "TP: 298.0 TN: 2606.0 FP: 84.0 FN: 38.0\n",
      "test Loss: 0.3696 Acc: 0.8743 Pre: 0.4960 Rec: 0.4157 F1: 0.4523\n",
      "TP: 185.0 TN: 2930.0 FP: 188.0 FN: 260.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1709 Acc: 0.9425 Pre: 0.8375 Rec: 0.5982 F1: 0.6979\n",
      "TP: 201.0 TN: 2651.0 FP: 39.0 FN: 135.0\n",
      "val Loss: 0.1318 Acc: 0.9537 Pre: 0.7333 Rec: 0.9167 F1: 0.8148\n",
      "TP: 308.0 TN: 2578.0 FP: 112.0 FN: 28.0\n",
      "test Loss: 0.3705 Acc: 0.8656 Pre: 0.4647 Rec: 0.5034 F1: 0.4833\n",
      "TP: 224.0 TN: 2860.0 FP: 258.0 FN: 221.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1638 Acc: 0.9481 Pre: 0.8809 Rec: 0.6161 F1: 0.7250\n",
      "TP: 207.0 TN: 2662.0 FP: 28.0 FN: 129.0\n",
      "val Loss: 0.0996 Acc: 0.9620 Pre: 0.7931 Rec: 0.8899 F1: 0.8387\n",
      "TP: 299.0 TN: 2612.0 FP: 78.0 FN: 37.0\n",
      "test Loss: 0.3902 Acc: 0.8726 Pre: 0.4880 Rec: 0.4112 F1: 0.4463\n",
      "TP: 183.0 TN: 2926.0 FP: 192.0 FN: 262.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1525 Acc: 0.9442 Pre: 0.8523 Rec: 0.6012 F1: 0.7051\n",
      "TP: 202.0 TN: 2655.0 FP: 35.0 FN: 134.0\n",
      "val Loss: 0.0754 Acc: 0.9729 Pre: 0.8780 Rec: 0.8780 F1: 0.8780\n",
      "TP: 295.0 TN: 2649.0 FP: 41.0 FN: 41.0\n",
      "test Loss: 0.3415 Acc: 0.8875 Pre: 0.5786 Rec: 0.3640 F1: 0.4469\n",
      "TP: 162.0 TN: 3000.0 FP: 118.0 FN: 283.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1484 Acc: 0.9481 Pre: 0.8908 Rec: 0.6071 F1: 0.7221\n",
      "TP: 204.0 TN: 2665.0 FP: 25.0 FN: 132.0\n",
      "val Loss: 0.0926 Acc: 0.9653 Pre: 0.8000 Rec: 0.9167 F1: 0.8544\n",
      "TP: 308.0 TN: 2613.0 FP: 77.0 FN: 28.0\n",
      "test Loss: 0.3518 Acc: 0.8799 Pre: 0.5252 Rec: 0.3978 F1: 0.4527\n",
      "TP: 177.0 TN: 2958.0 FP: 160.0 FN: 268.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1561 Acc: 0.9448 Pre: 0.8690 Rec: 0.5923 F1: 0.7044\n",
      "TP: 199.0 TN: 2660.0 FP: 30.0 FN: 137.0\n",
      "val Loss: 0.0638 Acc: 0.9762 Pre: 0.9314 Rec: 0.8482 F1: 0.8879\n",
      "TP: 285.0 TN: 2669.0 FP: 21.0 FN: 51.0\n",
      "test Loss: 0.3691 Acc: 0.8925 Pre: 0.6372 Rec: 0.3236 F1: 0.4292\n",
      "TP: 144.0 TN: 3036.0 FP: 82.0 FN: 301.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1445 Acc: 0.9458 Pre: 0.8359 Rec: 0.6369 F1: 0.7230\n",
      "TP: 214.0 TN: 2648.0 FP: 42.0 FN: 122.0\n",
      "val Loss: 0.0670 Acc: 0.9755 Pre: 0.8899 Rec: 0.8899 F1: 0.8899\n",
      "TP: 299.0 TN: 2653.0 FP: 37.0 FN: 37.0\n",
      "test Loss: 0.3714 Acc: 0.8866 Pre: 0.5751 Rec: 0.3528 F1: 0.4373\n",
      "TP: 157.0 TN: 3002.0 FP: 116.0 FN: 288.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1505 Acc: 0.9461 Pre: 0.8589 Rec: 0.6161 F1: 0.7175\n",
      "TP: 207.0 TN: 2656.0 FP: 34.0 FN: 129.0\n",
      "val Loss: 0.0630 Acc: 0.9759 Pre: 0.9458 Rec: 0.8304 F1: 0.8843\n",
      "TP: 279.0 TN: 2674.0 FP: 16.0 FN: 57.0\n",
      "test Loss: 0.3797 Acc: 0.8939 Pre: 0.6701 Rec: 0.2966 F1: 0.4112\n",
      "TP: 132.0 TN: 3053.0 FP: 65.0 FN: 313.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1480 Acc: 0.9481 Pre: 0.8566 Rec: 0.6399 F1: 0.7325\n",
      "TP: 215.0 TN: 2654.0 FP: 36.0 FN: 121.0\n",
      "val Loss: 0.0759 Acc: 0.9719 Pre: 0.8596 Rec: 0.8929 F1: 0.8759\n",
      "TP: 300.0 TN: 2641.0 FP: 49.0 FN: 36.0\n",
      "test Loss: 0.3565 Acc: 0.8830 Pre: 0.5461 Rec: 0.3730 F1: 0.4433\n",
      "TP: 166.0 TN: 2980.0 FP: 138.0 FN: 279.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1499 Acc: 0.9481 Pre: 0.8683 Rec: 0.6280 F1: 0.7288\n",
      "TP: 211.0 TN: 2658.0 FP: 32.0 FN: 125.0\n",
      "val Loss: 0.0680 Acc: 0.9772 Pre: 0.9211 Rec: 0.8690 F1: 0.8943\n",
      "TP: 292.0 TN: 2665.0 FP: 25.0 FN: 44.0\n",
      "test Loss: 0.3518 Acc: 0.8877 Pre: 0.5896 Rec: 0.3326 F1: 0.4253\n",
      "TP: 148.0 TN: 3015.0 FP: 103.0 FN: 297.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1555 Acc: 0.9468 Pre: 0.8631 Rec: 0.6190 F1: 0.7210\n",
      "TP: 208.0 TN: 2657.0 FP: 33.0 FN: 128.0\n",
      "val Loss: 0.0615 Acc: 0.9752 Pre: 0.9611 Rec: 0.8095 F1: 0.8788\n",
      "TP: 272.0 TN: 2679.0 FP: 11.0 FN: 64.0\n",
      "test Loss: 0.4198 Acc: 0.8919 Pre: 0.6630 Rec: 0.2742 F1: 0.3879\n",
      "TP: 122.0 TN: 3056.0 FP: 62.0 FN: 323.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9501 Pre: 0.8656 Rec: 0.6518 F1: 0.7436\n",
      "TP: 219.0 TN: 2656.0 FP: 34.0 FN: 117.0\n",
      "val Loss: 0.0916 Acc: 0.9630 Pre: 0.7857 Rec: 0.9167 F1: 0.8462\n",
      "TP: 308.0 TN: 2606.0 FP: 84.0 FN: 28.0\n",
      "test Loss: 0.3810 Acc: 0.8743 Pre: 0.4962 Rec: 0.4382 F1: 0.4654\n",
      "TP: 195.0 TN: 2920.0 FP: 198.0 FN: 250.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1519 Acc: 0.9491 Pre: 0.8699 Rec: 0.6369 F1: 0.7354\n",
      "TP: 214.0 TN: 2658.0 FP: 32.0 FN: 122.0\n",
      "val Loss: 0.0660 Acc: 0.9742 Pre: 0.8886 Rec: 0.8780 F1: 0.8832\n",
      "TP: 295.0 TN: 2653.0 FP: 37.0 FN: 41.0\n",
      "test Loss: 0.3773 Acc: 0.8866 Pre: 0.5779 Rec: 0.3416 F1: 0.4294\n",
      "TP: 152.0 TN: 3007.0 FP: 111.0 FN: 293.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1490 Acc: 0.9498 Pre: 0.8680 Rec: 0.6458 F1: 0.7406\n",
      "TP: 217.0 TN: 2657.0 FP: 33.0 FN: 119.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0897 Acc: 0.9670 Pre: 0.8089 Rec: 0.9196 F1: 0.8607\n",
      "TP: 309.0 TN: 2617.0 FP: 73.0 FN: 27.0\n",
      "test Loss: 0.3641 Acc: 0.8762 Pre: 0.5054 Rec: 0.4225 F1: 0.4602\n",
      "TP: 188.0 TN: 2934.0 FP: 184.0 FN: 257.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1388 Acc: 0.9511 Pre: 0.8950 Rec: 0.6339 F1: 0.7422\n",
      "TP: 213.0 TN: 2665.0 FP: 25.0 FN: 123.0\n",
      "val Loss: 0.0714 Acc: 0.9752 Pre: 0.8872 Rec: 0.8899 F1: 0.8886\n",
      "TP: 299.0 TN: 2652.0 FP: 38.0 FN: 37.0\n",
      "test Loss: 0.3662 Acc: 0.8849 Pre: 0.5641 Rec: 0.3461 F1: 0.4290\n",
      "TP: 154.0 TN: 2999.0 FP: 119.0 FN: 291.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1366 Acc: 0.9527 Pre: 0.8845 Rec: 0.6607 F1: 0.7564\n",
      "TP: 222.0 TN: 2661.0 FP: 29.0 FN: 114.0\n",
      "val Loss: 0.0662 Acc: 0.9749 Pre: 0.8916 Rec: 0.8810 F1: 0.8862\n",
      "TP: 296.0 TN: 2654.0 FP: 36.0 FN: 40.0\n",
      "test Loss: 0.3799 Acc: 0.8835 Pre: 0.5532 Rec: 0.3506 F1: 0.4292\n",
      "TP: 156.0 TN: 2992.0 FP: 126.0 FN: 289.0\n",
      "\n",
      "Training complete in 28m 14s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'val_train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.8832 Pre: 0.5472 Rec: 0.3775 F1: 0.4468\n",
      "TP: 168.0 TN: 2979.0 FP: 139.0 FN: 277.0\n",
      "Smoothed stats:\n",
      "(0.8975582374403592, 0.6904761904761905, 0.3258426966292135, 0.4427480916030535, 145, 3053, 65, 300)\n",
      "1\n",
      "Acc: 0.8861 Pre: 0.5549 Rec: 0.4427 F1: 0.4925\n",
      "TP: 197.0 TN: 2960.0 FP: 158.0 FN: 248.0\n",
      "Smoothed stats:\n",
      "(0.9003648610721302, 0.6956521739130435, 0.3595505617977528, 0.4740740740740741, 160, 3048, 70, 285)\n",
      "2\n",
      "Acc: 0.8838 Pre: 0.5425 Rec: 0.4449 F1: 0.4889\n",
      "TP: 198.0 TN: 2951.0 FP: 167.0 FN: 247.0\n",
      "Smoothed stats:\n",
      "(0.9003648610721302, 0.6875, 0.3707865168539326, 0.4817518248175182, 165, 3043, 75, 280)\n",
      "3\n",
      "Acc: 0.8925 Pre: 0.6054 Rec: 0.4000 F1: 0.4817\n",
      "TP: 178.0 TN: 3002.0 FP: 116.0 FN: 267.0\n",
      "Smoothed stats:\n",
      "(0.902610159977547, 0.7474747474747475, 0.3325842696629214, 0.4603421461897356, 148, 3068, 50, 297)\n",
      "4\n",
      "Acc: 0.8835 Pre: 0.5532 Rec: 0.3506 F1: 0.4292\n",
      "TP: 156.0 TN: 2992.0 FP: 126.0 FN: 289.0\n",
      "Smoothed stats:\n",
      "(0.8958742632612967, 0.7283950617283951, 0.2651685393258427, 0.38879736408566723, 118, 3074, 44, 327)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
