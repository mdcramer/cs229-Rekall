{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export All GT Panel Annotations\n",
    "We use the images and train/val/test splits from the Bernie interviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rekall import Interval, IntervalSet, IntervalSetMapping, Bounds3D\n",
    "from rekall.predicates import *\n",
    "from rekall.stdlib import ingest\n",
    "import math\n",
    "import urllib3, requests, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Video Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_COLLECTION_BASEURL = \"http://olimar.stanford.edu/hdd/tvnews-sandbox\"\n",
    "VIDEO_METADATA_FILENAME = \"data/video_meta_sandbox.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME), verify=False)\n",
    "video_collection = req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadata = [\n",
    "    VideoMetadata(v[\"path\"], v[\"id\"], v[\"fps\"], int(v[\"num_frames\"]), v[\"width\"], v[\"height\"])\n",
    "    for v in video_collection\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Val, Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [8220, 59398, 13141, 50164, 33004, 9901, 59122, 12837, 3769, 52075,\n",
    "             10335, 57990, 45655, 57804, 24193, 3459, 37113, 2648, 8697, 57708,\n",
    "             57592, 11003, 7262, 27410, 60186, 17983, 45472, 33387, 50561, 13556,\n",
    "             16542, 40203, 53684, 11555, 37107, 51175, 23181, 49931, 24992, 14482,\n",
    "             4611, 16879, 13827, 32472, 11792, 25463, 31378, 45645, 53355]\n",
    "val_set = [38275, 42756, 52945, 34642, 19959, 37170, 55711, 45698, 20380, 3952,\n",
    "           20450, 52749, 13927, 16215, 57384, 8859, 41725, 10323, 33541, 38420,\n",
    "           23184, 19882, 17458, 34359]\n",
    "test_set = [54377, 26386, 5281, 763, 9499, 24847, 13247, 29001, 9480, 9215, 27188,\n",
    "            13058, 32996, 6185, 36755, 13993, 4143, 3730, 15916, 529, 11579, 48140,\n",
    "            41480, 16693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set + val_set + test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Ground Truth Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANELS_JSON = \"data/panels.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(video_baseurl, json_path):\n",
    "    req = requests.get(os.path.join(video_baseurl, json_path), verify=False)\n",
    "    json_objs = req.json()\n",
    "    ism = ingest.ism_from_iterable_with_schema_bounds3D(\n",
    "        json_objs,\n",
    "        ingest.getter_accessor,\n",
    "        {\n",
    "            'key': 'video_id',\n",
    "            't1': 'start',\n",
    "            't2': 'end'\n",
    "        },\n",
    "        with_payload = lambda item: item,\n",
    "        progress = True\n",
    "    )\n",
    "    return ism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 197155.65it/s]\n"
     ]
    }
   ],
   "source": [
    "panels = load_json(VIDEO_COLLECTION_BASEURL, PANELS_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_by_video = {\n",
    "    video_id: [vm for vm in video_metadata if vm.id == video_id][0]\n",
    "    for video_id in train_set + val_set + test_set\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_second_conversion(c, mode='f2s'):\n",
    "    def second_to_frame(fps):\n",
    "        def map_fn(intrvl):\n",
    "            i2 = intrvl.copy()\n",
    "            curr_bounds = intrvl['bounds'].copy()\n",
    "            curr_bounds['t1'] = int(curr_bounds['t1']*fps)\n",
    "            curr_bounds['t2'] = int(curr_bounds['t2']*fps)\n",
    "            i2['bounds'] = curr_bounds\n",
    "            return i2\n",
    "        return map_fn\n",
    "    \n",
    "    def frame_to_second(fps):\n",
    "        def map_fn(intrvl):\n",
    "            i2 = intrvl.copy()\n",
    "            curr_bounds = intrvl['bounds'].copy()\n",
    "            curr_bounds['t1'] = int(curr_bounds['t1']/fps)\n",
    "            curr_bounds['t2'] = int(curr_bounds['t2']/fps)\n",
    "            i2['bounds'] = curr_bounds\n",
    "            return i2\n",
    "        return map_fn\n",
    "    \n",
    "    if mode=='f2s':\n",
    "        fn = frame_to_second\n",
    "    if mode=='s2f':\n",
    "        fn = second_to_frame\n",
    "    output = {}\n",
    "    for vid, intervals in c.get_grouped_intervals().items():\n",
    "        output[vid] = intervals.map(fn(vm_by_video[vid].fps))\n",
    "    return IntervalSetMapping(output)\n",
    "\n",
    "def frame_to_second_collection(c):\n",
    "    return frame_second_conversion(c, 'f2s')\n",
    "\n",
    "def second_to_frame_collection(c):\n",
    "    return frame_second_conversion(c, 's2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_dict = {}\n",
    "for video_id in train_set + val_set + test_set:\n",
    "    video = vm_by_video[video_id]\n",
    "    iset = IntervalSet([\n",
    "        Interval(Bounds3D(i, i), video.fps)\n",
    "        for i in range(0, video.num_frames) if (i % (\n",
    "            math.floor(video.fps * 3) * (interval / 3)\n",
    "        )) == 0\n",
    "    ])\n",
    "    segs_dict[video_id] = iset\n",
    "    \n",
    "segments = frame_to_second_collection(IntervalSetMapping(segs_dict)).dilate(interval / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_all_negative = segments.map(\n",
    "    lambda intrvl: Interval(intrvl['bounds'], 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_id(ism, valid_ids):\n",
    "    return IntervalSetMapping({\n",
    "        vid: ism.get_grouped_intervals()[vid]\n",
    "        for vid in list(ism.get_grouped_intervals().keys()) if vid in valid_ids\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13058: 11, 4611: 42, 42756: 25, 41480: 25, 9480: 13, 40203: 25, 48140: 7, 52749: 26, 11792: 7, 529: 29, 27410: 22, 26386: 21, 38420: 23, 60186: 14, 9499: 69, 8220: 17, 9215: 12, 11555: 42, 12837: 26, 57384: 7, 6185: 46, 4143: 25, 17458: 37, 37170: 11, 27188: 37, 16693: 11, 34359: 18, 17983: 38, 29001: 14, 45645: 16, 45655: 39, 2648: 36, 10335: 63, 13927: 25, 54377: 21, 33387: 47, 53355: 19, 3952: 44, 25463: 17, 24193: 13, 50561: 17, 38275: 19, 23184: 8, 31378: 13, 36755: 8, 8859: 23, 16542: 16, 45472: 44, 5281: 27, 24992: 19, 13993: 12, 19882: 30, 9901: 18, 52945: 21, 32472: 12, 20450: 12, 32996: 29, 16879: 13, 59122: 24, 37107: 26, 57592: 56, 37113: 108, 11003: 13, 41725: 7, 763: 28}\n",
      "{13058: 124, 13827: 124, 4611: 123, 42756: 124, 59398: 124, 33541: 123, 41480: 123, 9480: 123, 40203: 364, 48140: 123, 52749: 245, 49931: 123, 24847: 123, 11792: 123, 529: 123, 27410: 124, 26386: 123, 38420: 124, 60186: 123, 9499: 366, 8220: 123, 9215: 123, 11555: 123, 12837: 124, 57384: 123, 6185: 123, 15916: 123, 4143: 123, 17458: 123, 37170: 124, 27188: 124, 16693: 123, 34359: 124, 11579: 123, 17983: 124, 29001: 124, 45645: 124, 34642: 124, 10323: 123, 13141: 124, 45655: 124, 2648: 245, 16215: 63, 7262: 123, 10335: 366, 13927: 124, 54377: 124, 33387: 123, 53355: 123, 52075: 124, 57708: 124, 3952: 123, 25463: 123, 24193: 124, 45698: 124, 50561: 123, 38275: 123, 3459: 124, 57990: 124, 23181: 123, 23184: 123, 14482: 124, 31378: 123, 3730: 485, 36755: 123, 8859: 123, 20380: 124, 16542: 123, 55711: 124, 45472: 123, 5281: 123, 24992: 123, 13993: 123, 19882: 124, 9901: 124, 53684: 123, 3769: 124, 13247: 124, 57804: 124, 52945: 124, 32472: 123, 20450: 123, 32996: 123, 51175: 124, 33004: 123, 8697: 124, 16879: 123, 59122: 123, 37107: 123, 13556: 123, 50164: 124, 19959: 124, 57592: 183, 37113: 244, 11003: 124, 41725: 123, 763: 124}\n"
     ]
    }
   ],
   "source": [
    "panel_segments = segments.filter_against(\n",
    "    panels, predicate = overlaps()\n",
    ").map(\n",
    "    lambda intrvl: Interval(intrvl['bounds'], 1)\n",
    ")\n",
    "\n",
    "panel_labels = segments_all_negative.minus(\n",
    "    panel_segments\n",
    ").union(panel_segments)\n",
    "\n",
    "print(panel_segments.size())\n",
    "print(panel_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export GT Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR = 'data'\n",
    "os.makedirs(BASEDIR, exist_ok=True)\n",
    "with open(os.path.join(BASEDIR, 'train.txt'), 'w') as f:\n",
    "    for video_id in train_set:\n",
    "        for i, intrvl in enumerate(interview_labels[video_id].get_intervals()):\n",
    "            f.write('{} {} {}\\n'.format(video_id, i, intrvl['payload']))\n",
    "with open(os.path.join(BASEDIR, 'val.txt'), 'w') as f:\n",
    "    for video_id in val_set:\n",
    "        for i, intrvl in enumerate(interview_labels[video_id].get_intervals()):\n",
    "            f.write('{} {} {}\\n'.format(video_id, i, intrvl['payload']))\n",
    "with open(os.path.join(BASEDIR, 'test.txt'), 'w') as f:\n",
    "    for video_id in test_set:\n",
    "        for i, intrvl in enumerate(interview_labels[video_id].get_intervals()):\n",
    "            f.write('{} {} {}\\n'.format(video_id, i, intrvl['payload']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rekall] *",
   "language": "python",
   "name": "conda-env-rekall-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
