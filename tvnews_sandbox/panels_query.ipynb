{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rekall import Interval, IntervalSet, IntervalSetMapping, Bounds3D\n",
    "from rekall.predicates import *\n",
    "from rekall.stdlib import ingest\n",
    "from vgrid import VGridSpec, VideoMetadata, VideoBlockFormat, FlatFormat\n",
    "from vgrid import SpatialType_Bbox, SpatialType_Caption, Metadata_Generic\n",
    "from vgrid_jupyter import VGridWidget\n",
    "import urllib3, requests, os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_COLLECTION_BASEURL = \"http://olimar.stanford.edu/hdd/tvnews-sandbox\"\n",
    "VIDEO_ENDPOINT = \"http://olimar.stanford.edu/hdd/tvnews-sandbox/videos\"\n",
    "VIDEO_METADATA_FILENAME = \"data/video_meta_sandbox.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME), verify=False)\n",
    "video_collection = req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadata = [\n",
    "    VideoMetadata(v[\"path\"], v[\"id\"], v[\"fps\"], int(v[\"num_frames\"]), v[\"width\"], v[\"height\"])\n",
    "    for v in video_collection\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev, Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = [38275, 42756, 52945, 34642, 19959, 37170, 55711, 45698, 20380, 3952,\n",
    "           20450, 52749, 13927, 16215, 57384, 8859, 41725, 10323, 33541, 38420,\n",
    "           23184, 19882, 17458, 34359]\n",
    "test_set = [54377, 26386, 5281, 763, 9499, 24847, 13247, 29001, 9480, 9215, 27188,\n",
    "            13058, 32996, 6185, 36755, 13993, 4143, 3730, 15916, 529, 11579, 48140,\n",
    "            41480, 16693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_set + test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GT Annotations (Dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_id(ism, valid_ids):\n",
    "    return IntervalSetMapping({\n",
    "        vid: ism.get_grouped_intervals()[vid]\n",
    "        for vid in list(ism.get_grouped_intervals().keys()) if vid in valid_ids\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(video_baseurl, json_path):\n",
    "    req = requests.get(os.path.join(video_baseurl, json_path), verify=False)\n",
    "    json_objs = req.json()\n",
    "    ism = ingest.ism_from_iterable_with_schema_bounds3D(\n",
    "        json_objs,\n",
    "        ingest.getter_accessor,\n",
    "        {\n",
    "            'key': 'video_id',\n",
    "            't1': 'start',\n",
    "            't2': 'end'\n",
    "        },\n",
    "        with_payload = lambda item: item,\n",
    "        progress = True\n",
    "    )\n",
    "    return ism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANELS_JSON = \"data/panels.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 227219.52it/s]\n"
     ]
    }
   ],
   "source": [
    "panels = load_json(VIDEO_COLLECTION_BASEURL, PANELS_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_meta_by_id = {\n",
    "    vm.id: vm\n",
    "    for vm in video_metadata\n",
    "}\n",
    "FACES_JSON = \"data/face_dump.json\"\n",
    "req = requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, FACES_JSON), verify=False)\n",
    "faces_json = req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218006/218006 [00:01<00:00, 117874.16it/s]\n"
     ]
    }
   ],
   "source": [
    "faces_ism = ingest.ism_from_iterable_with_schema_bounds3D(\n",
    "    faces_json,\n",
    "    ingest.getter_accessor,\n",
    "    {\n",
    "        'key': 'video_id',\n",
    "        't1': 'frame_number',\n",
    "        't2': 'frame_number',\n",
    "        'x1': 'x1',\n",
    "        'x2': 'x2',\n",
    "        'y1': 'y1',\n",
    "        'y2': 'y2'\n",
    "    },\n",
    "    with_payload = lambda item: {\n",
    "        'face': item,\n",
    "        'video': video_meta_by_id[item['video_id']]\n",
    "    },\n",
    "    progress = True\n",
    ").filter(\n",
    "    lambda intrvl: (intrvl['t1'] % math.floor(intrvl['payload']['video'].fps * 3)) == 0\n",
    ").map(\n",
    "    lambda face: Interval(\n",
    "        Bounds3D(\n",
    "            face['t1'] / face['payload']['video'].fps - 1.5,\n",
    "            face['t2'] / face['payload']['video'].fps + 1.5,\n",
    "            face['x1'],\n",
    "            face['x2'],\n",
    "            face['y1'],\n",
    "            face['y2']\n",
    "        ),\n",
    "        face['payload']['face']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218006/218006 [00:02<00:00, 89462.25it/s] \n"
     ]
    }
   ],
   "source": [
    "hosts_ism = ingest.ism_from_iterable_with_schema_bounds3D(\n",
    "    faces_json,\n",
    "    ingest.getter_accessor,\n",
    "    {\n",
    "        'key': 'video_id',\n",
    "        't1': 'frame_number',\n",
    "        't2': 'frame_number',\n",
    "        'x1': 'x1',\n",
    "        'x2': 'x2',\n",
    "        'y1': 'y1',\n",
    "        'y2': 'y2'\n",
    "    },\n",
    "    with_payload = lambda item: {\n",
    "        'face': item,\n",
    "        'video': video_meta_by_id[item['video_id']]\n",
    "    },\n",
    "    progress = True\n",
    ").filter(\n",
    "    lambda intrvl: intrvl['payload']['face']['is_host']\n",
    ").map(\n",
    "    lambda face: Interval(\n",
    "        Bounds3D(\n",
    "            face['t1'] / face['payload']['video'].fps - 1.5,\n",
    "            face['t2'] / face['payload']['video'].fps + 1.5,\n",
    "            face['x1'],\n",
    "            face['x2'],\n",
    "            face['y1'],\n",
    "            face['y2']\n",
    "        ),\n",
    "        face['payload']['face']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTIONS_JSON = \"data/captions.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(video_baseurl, json_path):\n",
    "    req = requests.get(os.path.join(video_baseurl, json_path), verify=False)\n",
    "    json_objs = req.json()\n",
    "    ism = ingest.ism_from_iterable_with_schema_bounds3D(\n",
    "        json_objs,\n",
    "        ingest.getter_accessor,\n",
    "        {\n",
    "            'key': 'video_id',\n",
    "            't1': 'start',\n",
    "            't2': 'end'\n",
    "        },\n",
    "        with_payload = lambda item: item,\n",
    "        progress = True\n",
    "    )\n",
    "    return ism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 836546/836546 [00:04<00:00, 182318.41it/s]\n"
     ]
    }
   ],
   "source": [
    "captions = load_json(VIDEO_COLLECTION_BASEURL, CAPTIONS_JSON).map(\n",
    "    lambda caption: Interval(caption['bounds'], caption['payload']['caption'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_vgrid(caption_intrvl):\n",
    "    return Interval(\n",
    "        caption_intrvl['bounds'],\n",
    "        {\n",
    "            'spatial_type': SpatialType_Caption(caption_intrvl['payload']),\n",
    "            'metadata': {}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Precision/Recall/F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_by_video = {\n",
    "    video_id: [vm for vm in video_metadata if vm.id == video_id][0]\n",
    "    for video_id in dev_set + test_set\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_second_conversion(c, mode='f2s'):\n",
    "    def second_to_frame(fps):\n",
    "        def map_fn(intrvl):\n",
    "            i2 = intrvl.copy()\n",
    "            curr_bounds = intrvl['bounds'].copy()\n",
    "            curr_bounds['t1'] = int(curr_bounds['t1']*fps)\n",
    "            curr_bounds['t2'] = int(curr_bounds['t2']*fps)\n",
    "            i2['bounds'] = curr_bounds\n",
    "            return i2\n",
    "        return map_fn\n",
    "    \n",
    "    def frame_to_second(fps):\n",
    "        def map_fn(intrvl):\n",
    "            i2 = intrvl.copy()\n",
    "            curr_bounds = intrvl['bounds'].copy()\n",
    "            curr_bounds['t1'] = int(curr_bounds['t1']/fps)\n",
    "            curr_bounds['t2'] = int(curr_bounds['t2']/fps)\n",
    "            i2['bounds'] = curr_bounds\n",
    "            return i2\n",
    "        return map_fn\n",
    "    \n",
    "    if mode=='f2s':\n",
    "        fn = frame_to_second\n",
    "    if mode=='s2f':\n",
    "        fn = second_to_frame\n",
    "    output = {}\n",
    "    for vid, intervals in c.get_grouped_intervals().items():\n",
    "        output[vid] = intervals.map(fn(vm_by_video[vid].fps))\n",
    "    return IntervalSetMapping(output)\n",
    "\n",
    "def frame_to_second_collection(c):\n",
    "    return frame_second_conversion(c, 'f2s')\n",
    "\n",
    "def second_to_frame_collection(c):\n",
    "    return frame_second_conversion(c, 's2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_dict = {}\n",
    "for video_id in dev_set + test_set:\n",
    "    video = vm_by_video[video_id]\n",
    "    iset = IntervalSet([\n",
    "        Interval(Bounds3D(i, i), video.fps)\n",
    "        for i in range(0, video.num_frames) if (i % (\n",
    "            math.floor(video.fps * 3) * (interval / 3)\n",
    "        )) == 0\n",
    "    ])\n",
    "    segs_dict[video_id] = iset\n",
    "    \n",
    "segments = frame_to_second_collection(IntervalSetMapping(segs_dict)).dilate(interval / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_all_negative = segments.map(\n",
    "    lambda intrvl: Interval(intrvl['bounds'], 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_id(ism, valid_ids):\n",
    "    return IntervalSetMapping({\n",
    "        vid: ism.get_grouped_intervals()[vid]\n",
    "        for vid in list(ism.get_grouped_intervals().keys()) if vid in valid_ids\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{41480: 25, 48140: 7, 52749: 26, 529: 29, 38420: 23, 57384: 7, 6185: 46, 4143: 25, 17458: 37, 27188: 37, 34359: 18, 13927: 25, 54377: 21, 23184: 8, 8859: 23, 5281: 27, 13993: 12, 52945: 21, 32996: 29, 763: 28, 41725: 7, 13058: 11, 42756: 25, 9480: 13, 26386: 21, 9499: 69, 37170: 11, 16693: 11, 29001: 14, 3952: 44, 38275: 19, 36755: 8, 19882: 30, 20450: 12, 9215: 12}\n",
      "{13058: 124, 45698: 124, 38275: 123, 42756: 124, 33541: 123, 9480: 123, 41480: 123, 48140: 123, 52749: 245, 24847: 123, 23184: 123, 529: 123, 26386: 123, 36755: 123, 38420: 124, 3730: 485, 9499: 366, 8859: 123, 20380: 124, 55711: 124, 5281: 123, 57384: 123, 6185: 123, 19882: 124, 13993: 123, 15916: 123, 4143: 123, 37170: 124, 17458: 123, 27188: 124, 16693: 123, 34359: 124, 11579: 123, 13247: 124, 29001: 124, 52945: 124, 34642: 124, 10323: 123, 16215: 63, 20450: 123, 32996: 123, 13927: 124, 54377: 124, 3952: 123, 19959: 124, 763: 124, 41725: 123, 9215: 123}\n"
     ]
    }
   ],
   "source": [
    "panel_segments = segments.filter_against(\n",
    "    panels, predicate = overlaps()\n",
    ").map(\n",
    "    lambda intrvl: Interval(intrvl['bounds'], 1)\n",
    ")\n",
    "\n",
    "panel_labels = segments_all_negative.minus(\n",
    "    panel_segments\n",
    ").union(panel_segments)\n",
    "\n",
    "print(panel_segments.size())\n",
    "print(panel_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(predictions, panel_labels, video_ids):\n",
    "    predictions = filter_by_id(predictions, video_ids)\n",
    "    panel_labels = filter_by_id(panel_labels, video_ids)\n",
    "    \n",
    "    prediction_segments = segments.filter_against(\n",
    "        predictions,\n",
    "        predicate = overlaps()\n",
    "    ).map(lambda intrvl: Interval(intrvl['bounds'], 1))\n",
    "\n",
    "    prediction_labels = segments_all_negative.minus(\n",
    "        prediction_segments\n",
    "    ).union(prediction_segments)\n",
    "\n",
    "    prediction_scores = prediction_labels.join(\n",
    "        panel_labels,\n",
    "        predicate = equal(),\n",
    "        merge_op = lambda i1, i2: Interval(\n",
    "            i1['bounds'],\n",
    "            'tp' if i1['payload'] == i2['payload'] and i1['payload'] == 1 else\n",
    "            'tn' if i1['payload'] == i2['payload'] and i1['payload'] == 0 else\n",
    "            'fp' if i1['payload'] != i2['payload'] and i1['payload'] == 1 else\n",
    "            'fn'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def precision_recall_f1(pred_labels):\n",
    "        def sum_values(obj):\n",
    "            return sum([v for v in list(obj.values())])\n",
    "        tp = sum_values(pred_labels.filter(payload_satisfies(lambda p: p == 'tp')).size())\n",
    "        tn = sum_values(pred_labels.filter(payload_satisfies(lambda p: p == 'tn')).size())\n",
    "        fp = sum_values(pred_labels.filter(payload_satisfies(lambda p: p == 'fp')).size())\n",
    "        fn = sum_values(pred_labels.filter(payload_satisfies(lambda p: p == 'fn')).size())\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "        return (precision, recall, f1, tp, tn, fp, fn)\n",
    "    \n",
    "    return precision_recall_f1(prediction_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15136054421768708,\n",
       " 0.5933333333333334,\n",
       " 0.24119241192411928,\n",
       " 178,\n",
       " 1482,\n",
       " 998,\n",
       " 122)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(filter_by_id(hosts_ism, dev_set), panel_labels, dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_dev = filter_by_id(faces_ism, dev_set)\n",
    "hosts_dev = filter_by_id(hosts_ism, dev_set)\n",
    "captions_dev = filter_by_id(captions, dev_set)\n",
    "panels_dev = filter_by_id(panels, dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('faces', faces_dev.filter(\n",
    "            lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    "        )),\n",
    "        ('hosts', hosts_dev),\n",
    "        ('panel text', captions_dev.filter(\n",
    "            lambda intrvl: ('panel' in intrvl['payload'].lower() or\n",
    "                            'panelist' in intrvl['payload'].lower()\n",
    "                           )\n",
    "        ).dilate(10).map(\n",
    "            lambda intrvl: Interval(\n",
    "                intrvl['bounds'],\n",
    "                { 'spatial_type': SpatialType_Bbox(), 'metadata': {\n",
    "                    'caption': Metadata_Generic(intrvl['payload'])\n",
    "                } }\n",
    "            )\n",
    "        )),\n",
    "        ('panel text2', captions_dev.filter(\n",
    "            lambda intrvl: ('bring' in intrvl['payload'].lower() and\n",
    "                            'bringing' not in intrvl['payload'].lower())\n",
    "        ).join(\n",
    "            captions_dev.filter(\n",
    "                lambda intrvl: ('in' == intrvl['payload'].lower().strip())\n",
    "            ),\n",
    "            predicate = before(max_dist=5),\n",
    "            merge_op = lambda i1, i2: i1,\n",
    "            window = 0.0\n",
    "        ).dilate(10).map(\n",
    "            lambda intrvl: Interval(\n",
    "                intrvl['bounds'],\n",
    "                { 'spatial_type': SpatialType_Bbox(), 'metadata': {\n",
    "                    'caption': Metadata_Generic(intrvl['payload'])\n",
    "                } }\n",
    "            )\n",
    "        )),\n",
    "        ('panel text3', captions_dev.filter(\n",
    "            lambda intrvl: ('joining' in intrvl['payload'].lower())\n",
    "        ).dilate(10).map(\n",
    "            lambda intrvl: Interval(\n",
    "                intrvl['bounds'],\n",
    "                { 'spatial_type': SpatialType_Bbox(), 'metadata': {\n",
    "                    'caption': Metadata_Generic(intrvl['payload'])\n",
    "                } }\n",
    "            )\n",
    "        )),\n",
    "        ('panel text4', captions_dev.filter(\n",
    "            lambda intrvl: ('in' in intrvl['payload'].lower())\n",
    "        ).dilate(10).map(\n",
    "            lambda intrvl: Interval(\n",
    "                intrvl['bounds'],\n",
    "                { 'spatial_type': SpatialType_Bbox(), 'metadata': {\n",
    "                    'caption': Metadata_Generic(intrvl['payload'])\n",
    "                } }\n",
    "            )\n",
    "        )),\n",
    "        ('_captions', captions_dev.coalesce(\n",
    "            ('t1', 't2'),\n",
    "            Bounds3D.span,\n",
    "            lambda p1, p2: p1 + ' ' + p2,\n",
    "            predicate = lambda i1, i2: '>>' not in i2['payload'],\n",
    "            epsilon = 1.0\n",
    "        ).map(for_vgrid))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal from the transcripts: \"panel\" or \"panelist\" or \"bring\" near \"in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5555555555555556,\n",
       " 0.029940119760479042,\n",
       " 0.05681818181818182,\n",
       " 10,\n",
       " 2667,\n",
       " 8,\n",
       " 324)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(\n",
    "    captions_dev.filter(\n",
    "        lambda intrvl: ('panel' in intrvl['payload'].lower() or\n",
    "                        'panelist' in intrvl['payload'].lower())\n",
    "    ).union(\n",
    "        captions_dev.filter(\n",
    "            lambda intrvl: ('bring' in intrvl['payload'].lower() and\n",
    "                            'bringing' not in intrvl['payload'].lower())\n",
    "        ).join(\n",
    "            captions_dev.filter(\n",
    "                lambda intrvl: ('in' == intrvl['payload'].lower().strip())\n",
    "            ),\n",
    "            predicate = overlaps(),\n",
    "            merge_op = lambda i1, i2: i1,\n",
    "            window = 0.0\n",
    "        )\n",
    "    ),\n",
    "    panel_labels, dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('hosts', hosts_dev.coalesce(\n",
    "            ('t1', 't2'),\n",
    "            Bounds3D.span,\n",
    "            epsilon = 120.0\n",
    "        ).filter_size(min_size=60, max_size=1800)),\n",
    "        ('panel text', captions_dev.filter(\n",
    "            lambda intrvl: ('panel' in intrvl['payload'].lower() or\n",
    "                            'panelist' in intrvl['payload'].lower() or\n",
    "                            'thank' in intrvl['payload'].lower())\n",
    "        ))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_segment_with_panel_text = hosts_dev.coalesce(\n",
    "    ('t1', 't2'),\n",
    "    Bounds3D.span,\n",
    "    epsilon = 120.0\n",
    ").filter_size(\n",
    "    min_size=60, max_size=1800\n",
    ").filter_against(\n",
    "    captions_dev.filter(\n",
    "        lambda intrvl: ('panel' in intrvl['payload'].lower() or\n",
    "                        'panelist' in intrvl['payload'].lower())\n",
    "    ).union(\n",
    "        captions_dev.filter(\n",
    "            lambda intrvl: ('bring' in intrvl['payload'].lower() and\n",
    "                            'bringing' not in intrvl['payload'].lower())\n",
    "        ).join(\n",
    "            captions_dev.filter(\n",
    "                lambda intrvl: ('in' == intrvl['payload'].lower().strip())\n",
    "            ),\n",
    "            predicate = overlaps(),\n",
    "            merge_op = lambda i1, i2: i1,\n",
    "            window = 0.0\n",
    "        )\n",
    "    ),\n",
    "    predicate = or_pred(overlaps(), before(max_dist=10.0), after(max_dist=10.0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('panel_query', host_segment_with_panel_text)\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6451612903225806,\n",
       " 0.2994011976047904,\n",
       " 0.40899795501022485,\n",
       " 100,\n",
       " 2621,\n",
       " 55,\n",
       " 234)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(filter_by_id(host_segment_with_panel_text, dev_set), panel_labels, dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal from the number of faces on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_by_frame = faces_dev.filter(\n",
    "    lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    ").group_by_axis(('t1', 't2'), Bounds3D(0, 1, 0, 1, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('panel_query', host_segment_with_panel_text),\n",
    "        ('two faces', faces_by_frame.filter(lambda intrvl: len(intrvl['payload']) >= 2)),\n",
    "        ('three faces', faces_by_frame.filter(lambda intrvl: len(intrvl['payload']) >= 3))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_face_segments = faces_by_frame.filter(\n",
    "    lambda intrvl: len(intrvl['payload']) >= 3\n",
    ").coalesce(\n",
    "    ('t1', 't2'),\n",
    "    Bounds3D.span,\n",
    "    epsilon = 60.0\n",
    ")#.filter_size(min_size=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('panel_query', host_segment_with_panel_text),\n",
    "        ('hosts', hosts_dev.coalesce(\n",
    "            ('t1', 't2'),\n",
    "            Bounds3D.span,\n",
    "            epsilon = 120.0\n",
    "        ).filter_size(min_size=60, max_size=1800)),\n",
    "        ('three faces', three_face_segments)\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('panel_query', host_segment_with_panel_text),\n",
    "        ('three faces', three_face_segments),\n",
    "        ('panels_query2', host_segment_with_panel_text.union(three_face_segments))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2541766109785203,\n",
       " 0.6513761467889908,\n",
       " 0.36566523605150214,\n",
       " 213,\n",
       " 1947,\n",
       " 625,\n",
       " 114)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(host_segment_with_panel_text.union(three_face_segments), panel_labels, dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('_faces', faces_dev.filter(\n",
    "            lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    "        )),\n",
    "        ('panel_query', host_segment_with_panel_text),\n",
    "        ('hosts', hosts_dev.coalesce(\n",
    "            ('t1', 't2'),\n",
    "            Bounds3D.span,\n",
    "            epsilon = 180.0\n",
    "        ).filter_size(min_size=60, max_size=1800)),\n",
    "        ('three faces', three_face_segments),\n",
    "        ('panels_query2', host_segment_with_panel_text.union(\n",
    "            three_face_segments.filter_size(min_size=180)))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5061728395061729,\n",
       " 0.49101796407185627,\n",
       " 0.4984802431610942,\n",
       " 164,\n",
       " 2514,\n",
       " 160,\n",
       " 170)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(\n",
    "    host_segment_with_panel_text.union(three_face_segments.filter_size(min_size=180)),\n",
    "    panel_labels, dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal from faces on screen in certain position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range(lst):\n",
    "    return max(lst) - min(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactly_three_face_segments = faces_dev.filter(\n",
    "    lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn' and intrvl['payload']['score'] > 0.7\n",
    ").group_by_axis(\n",
    "    ('t1', 't2'), Bounds3D(0, 1, 0, 1, 0, 1)\n",
    ").filter(\n",
    "    lambda intrvl: (\n",
    "        len(intrvl['payload']) == 3 and \n",
    "        get_range([face['y1'] for face in intrvl['payload'].get_intervals()]) < 0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('_faces', faces_dev.filter(\n",
    "            lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    "        )),\n",
    "        ('three faces', exactly_three_face_segments.coalesce(\n",
    "            ('t1', 't2'),\n",
    "            Bounds3D.span,\n",
    "            epsilon = 180.0\n",
    "        ).filter_size(min_size=60, max_size=1800)),\n",
    "        ('panels_query2', host_segment_with_panel_text.union(\n",
    "            three_face_segments.filter_size(min_size=180)))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4166666666666667,\n",
       " 0.6756756756756757,\n",
       " 0.5154639175257731,\n",
       " 225,\n",
       " 2352,\n",
       " 315,\n",
       " 108)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(\n",
    "    host_segment_with_panel_text.union(\n",
    "        three_face_segments.filter_size(min_size=180)\n",
    "    ).union(\n",
    "        exactly_three_face_segments.coalesce(\n",
    "            ('t1', 't2'),\n",
    "            Bounds3D.span,\n",
    "            epsilon = 180.0\n",
    "        ).filter_size(min_size=60)\n",
    "    ),\n",
    "    panel_labels, dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_query3 = host_segment_with_panel_text.union(\n",
    "    three_face_segments.filter_size(min_size=180)\n",
    ").union(\n",
    "    exactly_three_face_segments.coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span,\n",
    "        epsilon = 180.0\n",
    "    ).filter_size(min_size=60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('_faces', faces_dev.filter(\n",
    "            lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    "        )),\n",
    "        ('panels_query3', panels_query3)\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_three_faces = three_face_segments.filter_size(min_size=180).union(\n",
    "    exactly_three_face_segments.coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span,\n",
    "        epsilon = 180.0\n",
    "    ).filter_size(min_size=60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('_faces', faces_dev.filter(\n",
    "            lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    "        )),\n",
    "        ('three_faces_loose', three_face_segments.filter_size(min_size=180)),\n",
    "        ('three_faces_strict',\n",
    "            exactly_three_face_segments.coalesce(\n",
    "                ('t1', 't2'),\n",
    "                Bounds3D.span,\n",
    "                epsilon = 180.0\n",
    "            ).filter_size(min_size=60)),\n",
    "        ('three_faces', query_three_faces),\n",
    "        ('panels_query3', panels_query3)\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore presidential candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidential_candidates = [\n",
    "    'donald trump',\n",
    "    'hillary clinton',\n",
    "    'bernie sanders',\n",
    "    'barack obama'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_presidential_candidate(face):\n",
    "    for identity in face['identities']:\n",
    "        if identity['score'] > .75 and identity['identity'] in presidential_candidates:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Interval t1:-1.5 t2:1.5 x1:0.260848045349121 x2:0.563493549823761 y1:0.15109895169735 y2:0.760732710361481 payload:{'genders': [{'labeler': 'knn-gender', 'gender': 'M', 'score': 1.0}, {'labeler': 'rudecarnie', 'gender': 'M', 'score': 0.999956130981445}], 'labeler': 'mtcnn', 'y2': 0.760732710361481, 'score': 1.0, 'frame_number': 0, 'x2': 0.563493549823761, 'id': 307400923, 'video_id': 38275, 'y1': 0.15109895169735, 'is_host': False, 'x1': 0.260848045349121, 'identities': [{'labeler': 'face-identity-rekognition', 'identity': 'géza m. tóth', 'score': 0.61}]}>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_dev[38275].get_intervals()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactly_three_face_segments_non_pres = faces_dev.filter(\n",
    "    lambda intrvl: (\n",
    "        intrvl['payload']['labeler'] == 'mtcnn' and\n",
    "        intrvl['payload']['score'] > 0.7 and\n",
    "        not_presidential_candidate(intrvl['payload'])\n",
    "    )\n",
    ").group_by_axis(\n",
    "    ('t1', 't2'), Bounds3D(0, 1, 0, 1, 0, 1)\n",
    ").filter(\n",
    "    lambda intrvl: (\n",
    "        len(intrvl['payload']) == 3 and \n",
    "        get_range([face['y1'] for face in intrvl['payload'].get_intervals()]) < 0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_three_faces2 = three_face_segments.filter_size(min_size=180).union(\n",
    "    exactly_three_face_segments_non_pres.coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span,\n",
    "        epsilon = 180.0\n",
    "    ).filter_size(min_size=60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4376237623762376,\n",
       " 0.6636636636636637,\n",
       " 0.5274463007159904,\n",
       " 221,\n",
       " 2385,\n",
       " 284,\n",
       " 112)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(\n",
    "    host_segment_with_panel_text.union(query_three_faces2),\n",
    "    panel_labels, dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for long segments where multiple people appear contiguously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likeliest_identity(face):\n",
    "    top_identity = None\n",
    "    top_identity_score = 0\n",
    "    \n",
    "    for identity in face['identities']:\n",
    "        if 'rekognition' not in identity['labeler']:\n",
    "            continue\n",
    "        if identity['score'] > top_identity_score and identity['score'] > .9:\n",
    "            top_identity = identity['identity']\n",
    "            top_identity_score = identity['score']\n",
    "            \n",
    "    return top_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_amazon_identities(face):\n",
    "    for identity in face['identities']:\n",
    "        if 'rekognition' in identity['labeler'] and identity['score'] > .9:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_same_person = faces_dev.filter(\n",
    "    lambda intrvl: (\n",
    "        intrvl['y2'] - intrvl['y1'] > .25 and\n",
    "        has_amazon_identities(intrvl['payload']) and\n",
    "        get_likeliest_identity(intrvl['payload']) not in presidential_candidates\n",
    "    )\n",
    ").coalesce(\n",
    "    ('t1', 't2'),\n",
    "    Bounds3D.span,\n",
    "    predicate = lambda f1, f2:\n",
    "        get_likeliest_identity(f1['payload']) == get_likeliest_identity(f2['payload']),\n",
    "    epsilon = 180\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{19882: 23,\n",
       " 34642: 24,\n",
       " 45698: 36,\n",
       " 8859: 30,\n",
       " 34359: 36,\n",
       " 57384: 24,\n",
       " 38420: 31,\n",
       " 17458: 33,\n",
       " 41725: 38,\n",
       " 52749: 69,\n",
       " 3952: 43,\n",
       " 52945: 17,\n",
       " 23184: 44,\n",
       " 19959: 8,\n",
       " 20450: 30,\n",
       " 33541: 37,\n",
       " 20380: 33,\n",
       " 38275: 27,\n",
       " 42756: 31,\n",
       " 55711: 36,\n",
       " 16215: 21,\n",
       " 13927: 46,\n",
       " 10323: 31,\n",
       " 37170: 42}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_same_person.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('_faces', faces_dev.filter(\n",
    "            lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    "        )),\n",
    "        ('faces_same_person', faces_same_person.filter_size(min_size=60))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_faces_same_person = faces_same_person.filter_size(\n",
    "    min_size=60\n",
    ").join(\n",
    "    faces_same_person.filter_size(min_size=60),\n",
    "    predicate = and_pred(\n",
    "        overlaps(),\n",
    "        lambda f1, f2:\n",
    "            get_likeliest_identity(f1['payload']) != get_likeliest_identity(f2['payload']),\n",
    "    ),\n",
    "    merge_op = lambda f1, f2: Interval(\n",
    "        Bounds3D.intersect_time_span_space(f1['bounds'], f2['bounds']),\n",
    "        (f1['payload'], f2['payload'])\n",
    "    )\n",
    ").filter_size(min_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{45698: 10,\n",
       " 38275: 6,\n",
       " 42756: 14,\n",
       " 33541: 18,\n",
       " 19959: 2,\n",
       " 52749: 2,\n",
       " 23184: 8,\n",
       " 52945: 16,\n",
       " 34642: 14,\n",
       " 10323: 12,\n",
       " 38420: 10,\n",
       " 8859: 8,\n",
       " 20380: 8,\n",
       " 55711: 6,\n",
       " 20450: 8,\n",
       " 13927: 36,\n",
       " 57384: 8,\n",
       " 19882: 8,\n",
       " 3952: 28,\n",
       " 17458: 4,\n",
       " 37170: 16,\n",
       " 34359: 10,\n",
       " 41725: 14}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_faces_same_person.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_faces_same_person = two_faces_same_person.join(\n",
    "    faces_same_person.filter_size(min_size=60),\n",
    "    predicate = and_pred(\n",
    "        overlaps(),\n",
    "        lambda f1, f2: (\n",
    "            get_likeliest_identity(f1['payload'][0]) != get_likeliest_identity(f2['payload']) and\n",
    "            get_likeliest_identity(f1['payload'][1]) != get_likeliest_identity(f2['payload'])\n",
    "        ),\n",
    "    ),\n",
    "    merge_op = lambda f1, f2: Interval(\n",
    "        Bounds3D.intersect_time_span_space(f1['bounds'], f2['bounds']),\n",
    "        (f1['payload'][0], f1['payload'][1], f2['payload'])\n",
    "    )\n",
    ").filter_size(min_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{45698: 6,\n",
       " 42756: 6,\n",
       " 33541: 6,\n",
       " 52945: 24,\n",
       " 34642: 12,\n",
       " 13927: 36,\n",
       " 3952: 18,\n",
       " 37170: 6,\n",
       " 41725: 6}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_faces_same_person.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('_faces', faces_dev.filter(\n",
    "            lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    "        )),\n",
    "        ('faces_same_person', faces_same_person.filter_size(min_size=60).map(\n",
    "            lambda intrvl: Interval(\n",
    "                intrvl['bounds'],\n",
    "                { 'spatial_type': SpatialType_Bbox(), 'metadata': {\n",
    "                    'faces1': Metadata_Generic(get_likeliest_identity(intrvl['payload']))\n",
    "                } }\n",
    "            )\n",
    "        )),\n",
    "        ('two_faces_same_person', two_faces_same_person.filter_size(min_size=60).map(\n",
    "            lambda intrvl: Interval(\n",
    "                intrvl['bounds'],\n",
    "                { 'spatial_type': SpatialType_Bbox(), 'metadata': {\n",
    "                    'faces2': Metadata_Generic((\n",
    "                        get_likeliest_identity(intrvl['payload'][0]),\n",
    "                        get_likeliest_identity(intrvl['payload'][1])\n",
    "                    ))\n",
    "                } }\n",
    "            )\n",
    "        )),\n",
    "        ('three_faces_same_person', three_faces_same_person.filter_size(min_size=60).map(\n",
    "            lambda intrvl: Interval(\n",
    "                intrvl['bounds'],\n",
    "                { 'spatial_type': SpatialType_Bbox(), 'metadata': {\n",
    "                    'faces3': Metadata_Generic((\n",
    "                        get_likeliest_identity(intrvl['payload'][0]),\n",
    "                        get_likeliest_identity(intrvl['payload'][1]),\n",
    "                        get_likeliest_identity(intrvl['payload'][2])\n",
    "                    ))\n",
    "                } }\n",
    "            )\n",
    "        )),\n",
    "        ('query', host_segment_with_panel_text.union(query_three_faces2))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4489795918367347,\n",
       " 0.7245508982035929,\n",
       " 0.5544100801832761,\n",
       " 242,\n",
       " 2374,\n",
       " 297,\n",
       " 92)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(\n",
    "    host_segment_with_panel_text.union(query_three_faces2).union(three_faces_same_person),\n",
    "    panel_labels, dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('panels', panels_dev),\n",
    "        ('_faces', faces_dev.filter(\n",
    "            lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    "        )),\n",
    "        ('query', host_segment_with_panel_text.union(\n",
    "            query_three_faces2\n",
    "        ).union(\n",
    "            three_faces_same_person\n",
    "        ))\n",
    "    ]),\n",
    "    video_endpoint = os.path.join(VIDEO_COLLECTION_BASEURL, 'videos')\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_test = filter_by_id(faces_ism, test_set)\n",
    "hosts_test = filter_by_id(hosts_ism, test_set)\n",
    "captions_test = filter_by_id(captions, test_set)\n",
    "panels_test = filter_by_id(panels, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_segment_with_panel_text_test = hosts_test.coalesce(\n",
    "    ('t1', 't2'),\n",
    "    Bounds3D.span,\n",
    "    epsilon = 120.0\n",
    ").filter_size(\n",
    "    min_size=60, max_size=1800\n",
    ").filter_against(\n",
    "    captions_test.filter(\n",
    "        lambda intrvl: ('panel' in intrvl['payload'].lower() or\n",
    "                        'panelist' in intrvl['payload'].lower())\n",
    "    ).union(\n",
    "        captions_dev.filter(\n",
    "            lambda intrvl: ('bring' in intrvl['payload'].lower() and\n",
    "                            'bringing' not in intrvl['payload'].lower())\n",
    "        ).join(\n",
    "            captions_dev.filter(\n",
    "                lambda intrvl: ('in' == intrvl['payload'].lower().strip())\n",
    "            ),\n",
    "            predicate = overlaps(),\n",
    "            merge_op = lambda i1, i2: i1,\n",
    "            window = 0.0\n",
    "        )\n",
    "    ),\n",
    "    predicate = or_pred(overlaps(), before(max_dist=10.0), after(max_dist=10.0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_by_frame_test = faces_test.filter(\n",
    "    lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn'\n",
    ").group_by_axis(('t1', 't2'), Bounds3D(0, 1, 0, 1, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_face_segments_test = faces_by_frame_test.filter(\n",
    "    lambda intrvl: len(intrvl['payload']) >= 3\n",
    ").coalesce(\n",
    "    ('t1', 't2'),\n",
    "    Bounds3D.span,\n",
    "    epsilon = 60.0\n",
    ")#.filter_size(min_size=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactly_three_face_segments_test = faces_test.filter(\n",
    "    lambda intrvl: intrvl['payload']['labeler'] == 'mtcnn' and intrvl['payload']['score'] > 0.7\n",
    ").group_by_axis(\n",
    "    ('t1', 't2'), Bounds3D(0, 1, 0, 1, 0, 1)\n",
    ").filter(\n",
    "    lambda intrvl: (\n",
    "        len(intrvl['payload']) == 3 and \n",
    "        get_range([face['y1'] for face in intrvl['payload'].get_intervals()]) < 0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactly_three_face_segments_non_pres_test = faces_test.filter(\n",
    "    lambda intrvl: (\n",
    "        intrvl['payload']['labeler'] == 'mtcnn' and\n",
    "        intrvl['payload']['score'] > 0.7 and\n",
    "        not_presidential_candidate(intrvl['payload'])\n",
    "    )\n",
    ").group_by_axis(\n",
    "    ('t1', 't2'), Bounds3D(0, 1, 0, 1, 0, 1)\n",
    ").filter(\n",
    "    lambda intrvl: (\n",
    "        len(intrvl['payload']) == 3 and \n",
    "        get_range([face['y1'] for face in intrvl['payload'].get_intervals()]) < 0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_three_faces_test = three_face_segments_test.filter_size(min_size=180).union(\n",
    "    exactly_three_face_segments_non_pres_test.coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span,\n",
    "        epsilon = 180.0\n",
    "    ).filter_size(min_size=60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_same_person_test = faces_test.filter(\n",
    "    lambda intrvl: (\n",
    "        intrvl['y2'] - intrvl['y1'] > .25 and\n",
    "        has_amazon_identities(intrvl['payload']) and\n",
    "        get_likeliest_identity(intrvl['payload']) not in presidential_candidates\n",
    "    )\n",
    ").coalesce(\n",
    "    ('t1', 't2'),\n",
    "    Bounds3D.span,\n",
    "    predicate = lambda f1, f2:\n",
    "        get_likeliest_identity(f1['payload']) == get_likeliest_identity(f2['payload']),\n",
    "    epsilon = 180\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_faces_same_person_test = faces_same_person_test.filter_size(\n",
    "    min_size=60\n",
    ").join(\n",
    "    faces_same_person_test.filter_size(min_size=60),\n",
    "    predicate = and_pred(\n",
    "        overlaps(),\n",
    "        lambda f1, f2:\n",
    "            get_likeliest_identity(f1['payload']) != get_likeliest_identity(f2['payload']),\n",
    "    ),\n",
    "    merge_op = lambda f1, f2: Interval(\n",
    "        Bounds3D.intersect_time_span_space(f1['bounds'], f2['bounds']),\n",
    "        (f1['payload'], f2['payload'])\n",
    "    )\n",
    ").filter_size(min_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_faces_same_person_test = two_faces_same_person_test.join(\n",
    "    faces_same_person_test.filter_size(min_size=60),\n",
    "    predicate = and_pred(\n",
    "        overlaps(),\n",
    "        lambda f1, f2: (\n",
    "            get_likeliest_identity(f1['payload'][0]) != get_likeliest_identity(f2['payload']) and\n",
    "            get_likeliest_identity(f1['payload'][1]) != get_likeliest_identity(f2['payload'])\n",
    "        ),\n",
    "    ),\n",
    "    merge_op = lambda f1, f2: Interval(\n",
    "        Bounds3D.intersect_time_span_space(f1['bounds'], f2['bounds']),\n",
    "        (f1['payload'][0], f1['payload'][1], f2['payload'])\n",
    "    )\n",
    ").filter_size(min_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3927789934354486,\n",
       " 0.8122171945701357,\n",
       " 0.5294985250737463,\n",
       " 359,\n",
       " 2526,\n",
       " 555,\n",
       " 83)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(\n",
    "    host_segment_with_panel_text_test.union(\n",
    "        query_three_faces_test\n",
    "    ).union(\n",
    "        three_faces_same_person_test\n",
    "    ),\n",
    "    panel_labels, test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rekall] *",
   "language": "python",
   "name": "conda-env-rekall-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
