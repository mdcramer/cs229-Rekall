{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'conversation_export/data/train.txt'\n",
    "val_file = 'conversation_export/data/val.txt'\n",
    "test_file = 'conversation_export/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('conversation_export/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3673, 'val_train': 550, 'val': 550, 'test': 657}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7291 Acc: 0.6164 Pre: 0.6685 Rec: 0.7305 F1: 0.6981\n",
      "TP: 244.0 TN: 95.0 FP: 121.0 FN: 90.0\n",
      "val Loss: 0.8596 Acc: 0.5545 Pre: 0.8938 Rec: 0.3024 F1: 0.4519\n",
      "TP: 101.0 TN: 204.0 FP: 12.0 FN: 233.0\n",
      "test Loss: 0.9269 Acc: 0.5160 Pre: 0.6538 Rec: 0.2374 F1: 0.3484\n",
      "TP: 85.0 TN: 254.0 FP: 45.0 FN: 273.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6511 Acc: 0.6691 Pre: 0.7099 Rec: 0.7695 F1: 0.7385\n",
      "TP: 257.0 TN: 111.0 FP: 105.0 FN: 77.0\n",
      "val Loss: 0.4896 Acc: 0.7527 Pre: 0.8133 Rec: 0.7695 F1: 0.7908\n",
      "TP: 257.0 TN: 157.0 FP: 59.0 FN: 77.0\n",
      "test Loss: 0.7332 Acc: 0.5875 Pre: 0.6160 Rec: 0.6453 F1: 0.6303\n",
      "TP: 231.0 TN: 155.0 FP: 144.0 FN: 127.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.6636 Pre: 0.7110 Rec: 0.7515 F1: 0.7307\n",
      "TP: 251.0 TN: 114.0 FP: 102.0 FN: 83.0\n",
      "val Loss: 0.4556 Acc: 0.7945 Pre: 0.7576 Rec: 0.9731 F1: 0.8519\n",
      "TP: 325.0 TN: 112.0 FP: 104.0 FN: 9.0\n",
      "test Loss: 0.8876 Acc: 0.5495 Pre: 0.5527 Rec: 0.9078 F1: 0.6871\n",
      "TP: 325.0 TN: 36.0 FP: 263.0 FN: 33.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5883 Acc: 0.6891 Pre: 0.7221 Rec: 0.7934 F1: 0.7561\n",
      "TP: 265.0 TN: 114.0 FP: 102.0 FN: 69.0\n",
      "val Loss: 0.3887 Acc: 0.8309 Pre: 0.8163 Rec: 0.9311 F1: 0.8699\n",
      "TP: 311.0 TN: 146.0 FP: 70.0 FN: 23.0\n",
      "test Loss: 0.9058 Acc: 0.5738 Pre: 0.5677 Rec: 0.9134 F1: 0.7002\n",
      "TP: 327.0 TN: 50.0 FP: 249.0 FN: 31.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.5880 Acc: 0.7109 Pre: 0.7384 Rec: 0.8114 F1: 0.7732\n",
      "TP: 271.0 TN: 120.0 FP: 96.0 FN: 63.0\n",
      "val Loss: 0.5137 Acc: 0.7600 Pre: 0.7295 Rec: 0.9611 F1: 0.8295\n",
      "TP: 321.0 TN: 97.0 FP: 119.0 FN: 13.0\n",
      "test Loss: 1.0321 Acc: 0.5738 Pre: 0.5627 Rec: 0.9777 F1: 0.7143\n",
      "TP: 350.0 TN: 27.0 FP: 272.0 FN: 8.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.6229 Acc: 0.6455 Pre: 0.7038 Rec: 0.7186 F1: 0.7111\n",
      "TP: 240.0 TN: 115.0 FP: 101.0 FN: 94.0\n",
      "val Loss: 0.3856 Acc: 0.8164 Pre: 0.8026 Rec: 0.9251 F1: 0.8595\n",
      "TP: 309.0 TN: 140.0 FP: 76.0 FN: 25.0\n",
      "test Loss: 0.8377 Acc: 0.6164 Pre: 0.6011 Rec: 0.8799 F1: 0.7143\n",
      "TP: 315.0 TN: 90.0 FP: 209.0 FN: 43.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.4922 Acc: 0.7818 Pre: 0.7956 Rec: 0.8623 F1: 0.8276\n",
      "TP: 288.0 TN: 142.0 FP: 74.0 FN: 46.0\n",
      "val Loss: 0.3294 Acc: 0.8600 Pre: 0.8599 Rec: 0.9192 F1: 0.8886\n",
      "TP: 307.0 TN: 166.0 FP: 50.0 FN: 27.0\n",
      "test Loss: 0.7633 Acc: 0.6119 Pre: 0.6020 Rec: 0.8492 F1: 0.7045\n",
      "TP: 304.0 TN: 98.0 FP: 201.0 FN: 54.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.4741 Acc: 0.7818 Pre: 0.8057 Rec: 0.8443 F1: 0.8246\n",
      "TP: 282.0 TN: 148.0 FP: 68.0 FN: 52.0\n",
      "val Loss: 0.3408 Acc: 0.8673 Pre: 0.9091 Rec: 0.8683 F1: 0.8882\n",
      "TP: 290.0 TN: 187.0 FP: 29.0 FN: 44.0\n",
      "test Loss: 0.7023 Acc: 0.6286 Pre: 0.6425 Rec: 0.7179 F1: 0.6781\n",
      "TP: 257.0 TN: 156.0 FP: 143.0 FN: 101.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.4705 Acc: 0.7782 Pre: 0.7912 Rec: 0.8623 F1: 0.8252\n",
      "TP: 288.0 TN: 140.0 FP: 76.0 FN: 46.0\n",
      "val Loss: 0.3148 Acc: 0.8636 Pre: 0.8587 Rec: 0.9281 F1: 0.8921\n",
      "TP: 310.0 TN: 165.0 FP: 51.0 FN: 24.0\n",
      "test Loss: 0.7461 Acc: 0.6043 Pre: 0.6047 Rec: 0.7905 F1: 0.6852\n",
      "TP: 283.0 TN: 114.0 FP: 185.0 FN: 75.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.5138 Acc: 0.7164 Pre: 0.7572 Rec: 0.7844 F1: 0.7706\n",
      "TP: 262.0 TN: 132.0 FP: 84.0 FN: 72.0\n",
      "val Loss: 0.2978 Acc: 0.8745 Pre: 0.8478 Rec: 0.9671 F1: 0.9035\n",
      "TP: 323.0 TN: 158.0 FP: 58.0 FN: 11.0\n",
      "test Loss: 0.8237 Acc: 0.5753 Pre: 0.5733 Rec: 0.8631 F1: 0.6890\n",
      "TP: 309.0 TN: 69.0 FP: 230.0 FN: 49.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.4676 Acc: 0.7927 Pre: 0.8005 Rec: 0.8772 F1: 0.8371\n",
      "TP: 293.0 TN: 143.0 FP: 73.0 FN: 41.0\n",
      "val Loss: 0.2838 Acc: 0.8927 Pre: 0.9056 Rec: 0.9192 F1: 0.9123\n",
      "TP: 307.0 TN: 184.0 FP: 32.0 FN: 27.0\n",
      "test Loss: 0.7391 Acc: 0.6043 Pre: 0.6134 Rec: 0.7402 F1: 0.6709\n",
      "TP: 265.0 TN: 132.0 FP: 167.0 FN: 93.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.4727 Acc: 0.7818 Pre: 0.7989 Rec: 0.8563 F1: 0.8266\n",
      "TP: 286.0 TN: 144.0 FP: 72.0 FN: 48.0\n",
      "val Loss: 0.2724 Acc: 0.8982 Pre: 0.9017 Rec: 0.9341 F1: 0.9176\n",
      "TP: 312.0 TN: 182.0 FP: 34.0 FN: 22.0\n",
      "test Loss: 0.7609 Acc: 0.6119 Pre: 0.6137 Rec: 0.7765 F1: 0.6856\n",
      "TP: 278.0 TN: 124.0 FP: 175.0 FN: 80.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.4379 Acc: 0.7891 Pre: 0.8132 Rec: 0.8473 F1: 0.8299\n",
      "TP: 283.0 TN: 151.0 FP: 65.0 FN: 51.0\n",
      "val Loss: 0.2667 Acc: 0.8909 Pre: 0.8870 Rec: 0.9401 F1: 0.9128\n",
      "TP: 314.0 TN: 176.0 FP: 40.0 FN: 20.0\n",
      "test Loss: 0.7537 Acc: 0.6088 Pre: 0.6091 Rec: 0.7877 F1: 0.6870\n",
      "TP: 282.0 TN: 118.0 FP: 181.0 FN: 76.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.4578 Acc: 0.7927 Pre: 0.8143 Rec: 0.8533 F1: 0.8333\n",
      "TP: 285.0 TN: 151.0 FP: 65.0 FN: 49.0\n",
      "val Loss: 0.2853 Acc: 0.8964 Pre: 0.9086 Rec: 0.9222 F1: 0.9153\n",
      "TP: 308.0 TN: 185.0 FP: 31.0 FN: 26.0\n",
      "test Loss: 0.7421 Acc: 0.6043 Pre: 0.6129 Rec: 0.7430 F1: 0.6717\n",
      "TP: 266.0 TN: 131.0 FP: 168.0 FN: 92.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.4647 Acc: 0.7764 Pre: 0.7989 Rec: 0.8443 F1: 0.8210\n",
      "TP: 282.0 TN: 145.0 FP: 71.0 FN: 52.0\n",
      "val Loss: 0.2608 Acc: 0.8982 Pre: 0.9017 Rec: 0.9341 F1: 0.9176\n",
      "TP: 312.0 TN: 182.0 FP: 34.0 FN: 22.0\n",
      "test Loss: 0.7554 Acc: 0.6195 Pre: 0.6205 Rec: 0.7765 F1: 0.6898\n",
      "TP: 278.0 TN: 129.0 FP: 170.0 FN: 80.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.4903 Acc: 0.7836 Pre: 0.7978 Rec: 0.8623 F1: 0.8288\n",
      "TP: 288.0 TN: 143.0 FP: 73.0 FN: 46.0\n",
      "val Loss: 0.2778 Acc: 0.8891 Pre: 0.8621 Rec: 0.9731 F1: 0.9142\n",
      "TP: 325.0 TN: 164.0 FP: 52.0 FN: 9.0\n",
      "test Loss: 0.8402 Acc: 0.5799 Pre: 0.5779 Rec: 0.8492 F1: 0.6878\n",
      "TP: 304.0 TN: 77.0 FP: 222.0 FN: 54.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.4537 Acc: 0.7673 Pre: 0.8012 Rec: 0.8204 F1: 0.8107\n",
      "TP: 274.0 TN: 148.0 FP: 68.0 FN: 60.0\n",
      "val Loss: 0.2636 Acc: 0.9127 Pre: 0.9133 Rec: 0.9461 F1: 0.9294\n",
      "TP: 316.0 TN: 186.0 FP: 30.0 FN: 18.0\n",
      "test Loss: 0.7822 Acc: 0.6012 Pre: 0.6039 Rec: 0.7793 F1: 0.6805\n",
      "TP: 279.0 TN: 116.0 FP: 183.0 FN: 79.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.4789 Acc: 0.7727 Pre: 0.7911 Rec: 0.8503 F1: 0.8196\n",
      "TP: 284.0 TN: 141.0 FP: 75.0 FN: 50.0\n",
      "val Loss: 0.2648 Acc: 0.8909 Pre: 0.8743 Rec: 0.9581 F1: 0.9143\n",
      "TP: 320.0 TN: 170.0 FP: 46.0 FN: 14.0\n",
      "test Loss: 0.7780 Acc: 0.6058 Pre: 0.6012 Rec: 0.8212 F1: 0.6942\n",
      "TP: 294.0 TN: 104.0 FP: 195.0 FN: 64.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.4483 Acc: 0.8018 Pre: 0.8319 Rec: 0.8443 F1: 0.8380\n",
      "TP: 282.0 TN: 159.0 FP: 57.0 FN: 52.0\n",
      "val Loss: 0.2550 Acc: 0.9018 Pre: 0.9046 Rec: 0.9371 F1: 0.9206\n",
      "TP: 313.0 TN: 183.0 FP: 33.0 FN: 21.0\n",
      "test Loss: 0.7659 Acc: 0.6088 Pre: 0.6105 Rec: 0.7793 F1: 0.6847\n",
      "TP: 279.0 TN: 121.0 FP: 178.0 FN: 79.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.4718 Acc: 0.7564 Pre: 0.7857 Rec: 0.8234 F1: 0.8041\n",
      "TP: 275.0 TN: 141.0 FP: 75.0 FN: 59.0\n",
      "val Loss: 0.2576 Acc: 0.9018 Pre: 0.9046 Rec: 0.9371 F1: 0.9206\n",
      "TP: 313.0 TN: 183.0 FP: 33.0 FN: 21.0\n",
      "test Loss: 0.7485 Acc: 0.6134 Pre: 0.6166 Rec: 0.7682 F1: 0.6841\n",
      "TP: 275.0 TN: 128.0 FP: 171.0 FN: 83.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.4480 Acc: 0.7836 Pre: 0.8080 Rec: 0.8443 F1: 0.8258\n",
      "TP: 282.0 TN: 149.0 FP: 67.0 FN: 52.0\n",
      "val Loss: 0.2557 Acc: 0.9018 Pre: 0.8911 Rec: 0.9551 F1: 0.9220\n",
      "TP: 319.0 TN: 177.0 FP: 39.0 FN: 15.0\n",
      "test Loss: 0.7771 Acc: 0.6088 Pre: 0.6063 Rec: 0.8045 F1: 0.6915\n",
      "TP: 288.0 TN: 112.0 FP: 187.0 FN: 70.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.5002 Acc: 0.7655 Pre: 0.7839 Rec: 0.8473 F1: 0.8144\n",
      "TP: 283.0 TN: 138.0 FP: 78.0 FN: 51.0\n",
      "val Loss: 0.2484 Acc: 0.9055 Pre: 0.8961 Rec: 0.9551 F1: 0.9246\n",
      "TP: 319.0 TN: 179.0 FP: 37.0 FN: 15.0\n",
      "test Loss: 0.7969 Acc: 0.6027 Pre: 0.6025 Rec: 0.7961 F1: 0.6859\n",
      "TP: 285.0 TN: 111.0 FP: 188.0 FN: 73.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.4457 Acc: 0.8000 Pre: 0.8182 Rec: 0.8623 F1: 0.8397\n",
      "TP: 288.0 TN: 152.0 FP: 64.0 FN: 46.0\n",
      "val Loss: 0.2597 Acc: 0.9036 Pre: 0.8936 Rec: 0.9551 F1: 0.9233\n",
      "TP: 319.0 TN: 178.0 FP: 38.0 FN: 15.0\n",
      "test Loss: 0.7681 Acc: 0.6164 Pre: 0.6100 Rec: 0.8212 F1: 0.7000\n",
      "TP: 294.0 TN: 111.0 FP: 188.0 FN: 64.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.4467 Acc: 0.7855 Pre: 0.8086 Rec: 0.8473 F1: 0.8275\n",
      "TP: 283.0 TN: 149.0 FP: 67.0 FN: 51.0\n",
      "val Loss: 0.2669 Acc: 0.8836 Pre: 0.8590 Rec: 0.9671 F1: 0.9099\n",
      "TP: 323.0 TN: 163.0 FP: 53.0 FN: 11.0\n",
      "test Loss: 0.8313 Acc: 0.5784 Pre: 0.5763 Rec: 0.8547 F1: 0.6884\n",
      "TP: 306.0 TN: 74.0 FP: 225.0 FN: 52.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.4873 Acc: 0.7709 Pre: 0.7889 Rec: 0.8503 F1: 0.8184\n",
      "TP: 284.0 TN: 140.0 FP: 76.0 FN: 50.0\n",
      "val Loss: 0.2626 Acc: 0.9127 Pre: 0.9133 Rec: 0.9461 F1: 0.9294\n",
      "TP: 316.0 TN: 186.0 FP: 30.0 FN: 18.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7590 Acc: 0.6088 Pre: 0.6120 Rec: 0.7709 F1: 0.6823\n",
      "TP: 276.0 TN: 124.0 FP: 175.0 FN: 82.0\n",
      "\n",
      "Training complete in 11m 47s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.]).to(device))\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'val_train', 'val', test_dl='test', num_epochs=25,\n",
    "                               verbose=True, log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
