{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'conversation_export/data/train.txt'\n",
    "val_file = 'conversation_export/data/val.txt'\n",
    "test_file = 'conversation_export/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('conversation_export/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 32410, 'val_train': 4710, 'val': 4710, 'test': 5230}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.6764 Pre: 0.7303 Rec: 0.8083 F1: 0.7673\n",
      "TP: 2513.0 TN: 673.0 FP: 928.0 FN: 596.0\n",
      "val Loss: 0.6833 Acc: 0.7314 Pre: 0.7184 Rec: 0.9756 F1: 0.8274\n",
      "TP: 3033.0 TN: 412.0 FP: 1189.0 FN: 76.0\n",
      "test Loss: 1.0575 Acc: 0.6455 Pre: 0.6393 Rec: 0.9761 F1: 0.7726\n",
      "TP: 3150.0 TN: 226.0 FP: 1777.0 FN: 77.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5754 Acc: 0.7246 Pre: 0.7737 Rec: 0.8237 F1: 0.7979\n",
      "TP: 2561.0 TN: 852.0 FP: 749.0 FN: 548.0\n",
      "val Loss: 0.3983 Acc: 0.8306 Pre: 0.9111 Rec: 0.8237 F1: 0.8652\n",
      "TP: 2561.0 TN: 1351.0 FP: 250.0 FN: 548.0\n",
      "test Loss: 0.7704 Acc: 0.6224 Pre: 0.7598 Rec: 0.5674 F1: 0.6496\n",
      "TP: 1831.0 TN: 1424.0 FP: 579.0 FN: 1396.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5266 Acc: 0.7558 Pre: 0.7964 Rec: 0.8466 F1: 0.8207\n",
      "TP: 2632.0 TN: 928.0 FP: 673.0 FN: 477.0\n",
      "val Loss: 0.3222 Acc: 0.8665 Pre: 0.8894 Rec: 0.9109 F1: 0.9000\n",
      "TP: 2832.0 TN: 1249.0 FP: 352.0 FN: 277.0\n",
      "test Loss: 0.7753 Acc: 0.6400 Pre: 0.7309 Rec: 0.6591 F1: 0.6932\n",
      "TP: 2127.0 TN: 1220.0 FP: 783.0 FN: 1100.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4990 Acc: 0.7735 Pre: 0.8119 Rec: 0.8549 F1: 0.8328\n",
      "TP: 2658.0 TN: 985.0 FP: 616.0 FN: 451.0\n",
      "val Loss: 0.2832 Acc: 0.8783 Pre: 0.8772 Rec: 0.9485 F1: 0.9115\n",
      "TP: 2949.0 TN: 1188.0 FP: 413.0 FN: 160.0\n",
      "test Loss: 0.6447 Acc: 0.6776 Pre: 0.7055 Rec: 0.8196 F1: 0.7583\n",
      "TP: 2645.0 TN: 899.0 FP: 1104.0 FN: 582.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4681 Acc: 0.7796 Pre: 0.8185 Rec: 0.8559 F1: 0.8368\n",
      "TP: 2661.0 TN: 1011.0 FP: 590.0 FN: 448.0\n",
      "val Loss: 0.2769 Acc: 0.8885 Pre: 0.9065 Rec: 0.9267 F1: 0.9165\n",
      "TP: 2881.0 TN: 1304.0 FP: 297.0 FN: 228.0\n",
      "test Loss: 0.8170 Acc: 0.5990 Pre: 0.7231 Rec: 0.5674 F1: 0.6359\n",
      "TP: 1831.0 TN: 1302.0 FP: 701.0 FN: 1396.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4577 Acc: 0.7934 Pre: 0.8311 Rec: 0.8623 F1: 0.8464\n",
      "TP: 2681.0 TN: 1056.0 FP: 545.0 FN: 428.0\n",
      "val Loss: 0.4802 Acc: 0.8679 Pre: 0.9346 Rec: 0.8601 F1: 0.8958\n",
      "TP: 2674.0 TN: 1414.0 FP: 187.0 FN: 435.0\n",
      "test Loss: 0.8033 Acc: 0.6101 Pre: 0.7352 Rec: 0.5755 F1: 0.6456\n",
      "TP: 1857.0 TN: 1334.0 FP: 669.0 FN: 1370.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3800 Acc: 0.8378 Pre: 0.8609 Rec: 0.8996 F1: 0.8798\n",
      "TP: 2797.0 TN: 1149.0 FP: 452.0 FN: 312.0\n",
      "val Loss: 0.2367 Acc: 0.9076 Pre: 0.9341 Rec: 0.9254 F1: 0.9297\n",
      "TP: 2877.0 TN: 1398.0 FP: 203.0 FN: 232.0\n",
      "test Loss: 0.7948 Acc: 0.6067 Pre: 0.7255 Rec: 0.5832 F1: 0.6466\n",
      "TP: 1882.0 TN: 1291.0 FP: 712.0 FN: 1345.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3713 Acc: 0.8342 Pre: 0.8637 Rec: 0.8890 F1: 0.8762\n",
      "TP: 2764.0 TN: 1165.0 FP: 436.0 FN: 345.0\n",
      "val Loss: 0.2178 Acc: 0.9142 Pre: 0.9306 Rec: 0.9402 F1: 0.9354\n",
      "TP: 2923.0 TN: 1383.0 FP: 218.0 FN: 186.0\n",
      "test Loss: 0.7848 Acc: 0.6377 Pre: 0.7214 Rec: 0.6725 F1: 0.6961\n",
      "TP: 2170.0 TN: 1165.0 FP: 838.0 FN: 1057.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3535 Acc: 0.8514 Pre: 0.8723 Rec: 0.9077 F1: 0.8897\n",
      "TP: 2822.0 TN: 1188.0 FP: 413.0 FN: 287.0\n",
      "val Loss: 0.1864 Acc: 0.9323 Pre: 0.9503 Rec: 0.9469 F1: 0.9486\n",
      "TP: 2944.0 TN: 1447.0 FP: 154.0 FN: 165.0\n",
      "test Loss: 0.7963 Acc: 0.6229 Pre: 0.7245 Rec: 0.6275 F1: 0.6725\n",
      "TP: 2025.0 TN: 1233.0 FP: 770.0 FN: 1202.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3402 Acc: 0.8537 Pre: 0.8730 Rec: 0.9109 F1: 0.8915\n",
      "TP: 2832.0 TN: 1189.0 FP: 412.0 FN: 277.0\n",
      "val Loss: 0.2040 Acc: 0.9238 Pre: 0.9602 Rec: 0.9228 F1: 0.9411\n",
      "TP: 2869.0 TN: 1482.0 FP: 119.0 FN: 240.0\n",
      "test Loss: 0.8604 Acc: 0.6006 Pre: 0.7493 Rec: 0.5299 F1: 0.6208\n",
      "TP: 1710.0 TN: 1431.0 FP: 572.0 FN: 1517.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3328 Acc: 0.8633 Pre: 0.8843 Rec: 0.9122 F1: 0.8980\n",
      "TP: 2836.0 TN: 1230.0 FP: 371.0 FN: 273.0\n",
      "val Loss: 0.2104 Acc: 0.9268 Pre: 0.9591 Rec: 0.9286 F1: 0.9436\n",
      "TP: 2887.0 TN: 1478.0 FP: 123.0 FN: 222.0\n",
      "test Loss: 0.8067 Acc: 0.6205 Pre: 0.7207 Rec: 0.6284 F1: 0.6714\n",
      "TP: 2028.0 TN: 1217.0 FP: 786.0 FN: 1199.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3350 Acc: 0.8569 Pre: 0.8785 Rec: 0.9090 F1: 0.8935\n",
      "TP: 2826.0 TN: 1210.0 FP: 391.0 FN: 283.0\n",
      "val Loss: 0.1763 Acc: 0.9312 Pre: 0.9696 Rec: 0.9247 F1: 0.9467\n",
      "TP: 2875.0 TN: 1511.0 FP: 90.0 FN: 234.0\n",
      "test Loss: 0.8666 Acc: 0.6027 Pre: 0.7446 Rec: 0.5420 F1: 0.6273\n",
      "TP: 1749.0 TN: 1403.0 FP: 600.0 FN: 1478.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3199 Acc: 0.8684 Pre: 0.8876 Rec: 0.9167 F1: 0.9019\n",
      "TP: 2850.0 TN: 1240.0 FP: 361.0 FN: 259.0\n",
      "val Loss: 0.1726 Acc: 0.9357 Pre: 0.9491 Rec: 0.9537 F1: 0.9514\n",
      "TP: 2965.0 TN: 1442.0 FP: 159.0 FN: 144.0\n",
      "test Loss: 0.8395 Acc: 0.6277 Pre: 0.7061 Rec: 0.6796 F1: 0.6926\n",
      "TP: 2193.0 TN: 1090.0 FP: 913.0 FN: 1034.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3042 Acc: 0.8781 Pre: 0.8938 Rec: 0.9254 F1: 0.9093\n",
      "TP: 2877.0 TN: 1259.0 FP: 342.0 FN: 232.0\n",
      "val Loss: 0.1653 Acc: 0.9378 Pre: 0.9592 Rec: 0.9460 F1: 0.9526\n",
      "TP: 2941.0 TN: 1476.0 FP: 125.0 FN: 168.0\n",
      "test Loss: 0.8679 Acc: 0.6115 Pre: 0.7224 Rec: 0.6015 F1: 0.6564\n",
      "TP: 1941.0 TN: 1257.0 FP: 746.0 FN: 1286.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3103 Acc: 0.8684 Pre: 0.8893 Rec: 0.9144 F1: 0.9017\n",
      "TP: 2843.0 TN: 1247.0 FP: 354.0 FN: 266.0\n",
      "val Loss: 0.1468 Acc: 0.9450 Pre: 0.9621 Rec: 0.9543 F1: 0.9582\n",
      "TP: 2967.0 TN: 1484.0 FP: 117.0 FN: 142.0\n",
      "test Loss: 0.8773 Acc: 0.5927 Pre: 0.7207 Rec: 0.5550 F1: 0.6271\n",
      "TP: 1791.0 TN: 1309.0 FP: 694.0 FN: 1436.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3031 Acc: 0.8752 Pre: 0.8943 Rec: 0.9196 F1: 0.9068\n",
      "TP: 2859.0 TN: 1263.0 FP: 338.0 FN: 250.0\n",
      "val Loss: 0.1564 Acc: 0.9427 Pre: 0.9516 Rec: 0.9620 F1: 0.9568\n",
      "TP: 2991.0 TN: 1449.0 FP: 152.0 FN: 118.0\n",
      "test Loss: 0.8617 Acc: 0.6157 Pre: 0.7065 Rec: 0.6452 F1: 0.6744\n",
      "TP: 2082.0 TN: 1138.0 FP: 865.0 FN: 1145.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3183 Acc: 0.8713 Pre: 0.8898 Rec: 0.9189 F1: 0.9041\n",
      "TP: 2857.0 TN: 1247.0 FP: 354.0 FN: 252.0\n",
      "val Loss: 0.1381 Acc: 0.9495 Pre: 0.9614 Rec: 0.9620 F1: 0.9617\n",
      "TP: 2991.0 TN: 1481.0 FP: 120.0 FN: 118.0\n",
      "test Loss: 0.8654 Acc: 0.6115 Pre: 0.7199 Rec: 0.6061 F1: 0.6581\n",
      "TP: 1956.0 TN: 1242.0 FP: 761.0 FN: 1271.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.3082 Acc: 0.8715 Pre: 0.8893 Rec: 0.9199 F1: 0.9043\n",
      "TP: 2860.0 TN: 1245.0 FP: 356.0 FN: 249.0\n",
      "val Loss: 0.1737 Acc: 0.9355 Pre: 0.9667 Rec: 0.9344 F1: 0.9503\n",
      "TP: 2905.0 TN: 1501.0 FP: 100.0 FN: 204.0\n",
      "test Loss: 0.8727 Acc: 0.5889 Pre: 0.7377 Rec: 0.5178 F1: 0.6085\n",
      "TP: 1671.0 TN: 1409.0 FP: 594.0 FN: 1556.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2976 Acc: 0.8820 Pre: 0.8970 Rec: 0.9276 F1: 0.9121\n",
      "TP: 2884.0 TN: 1270.0 FP: 331.0 FN: 225.0\n",
      "val Loss: 0.1363 Acc: 0.9507 Pre: 0.9497 Rec: 0.9772 F1: 0.9632\n",
      "TP: 3038.0 TN: 1440.0 FP: 161.0 FN: 71.0\n",
      "test Loss: 0.8249 Acc: 0.6262 Pre: 0.7058 Rec: 0.6759 F1: 0.6905\n",
      "TP: 2181.0 TN: 1094.0 FP: 909.0 FN: 1046.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3162 Acc: 0.8732 Pre: 0.8952 Rec: 0.9151 F1: 0.9050\n",
      "TP: 2845.0 TN: 1268.0 FP: 333.0 FN: 264.0\n",
      "val Loss: 0.1613 Acc: 0.9401 Pre: 0.9515 Rec: 0.9582 F1: 0.9548\n",
      "TP: 2979.0 TN: 1449.0 FP: 152.0 FN: 130.0\n",
      "test Loss: 0.8211 Acc: 0.6168 Pre: 0.7079 Rec: 0.6452 F1: 0.6751\n",
      "TP: 2082.0 TN: 1144.0 FP: 859.0 FN: 1145.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3087 Acc: 0.8764 Pre: 0.8952 Rec: 0.9206 F1: 0.9077\n",
      "TP: 2862.0 TN: 1266.0 FP: 335.0 FN: 247.0\n",
      "val Loss: 0.1665 Acc: 0.9361 Pre: 0.9443 Rec: 0.9598 F1: 0.9520\n",
      "TP: 2984.0 TN: 1425.0 FP: 176.0 FN: 125.0\n",
      "test Loss: 0.8606 Acc: 0.6298 Pre: 0.7075 Rec: 0.6821 F1: 0.6945\n",
      "TP: 2201.0 TN: 1093.0 FP: 910.0 FN: 1026.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3022 Acc: 0.8745 Pre: 0.8972 Rec: 0.9148 F1: 0.9059\n",
      "TP: 2844.0 TN: 1275.0 FP: 326.0 FN: 265.0\n",
      "val Loss: 0.1381 Acc: 0.9476 Pre: 0.9643 Rec: 0.9559 F1: 0.9601\n",
      "TP: 2972.0 TN: 1491.0 FP: 110.0 FN: 137.0\n",
      "test Loss: 0.8925 Acc: 0.5927 Pre: 0.7321 Rec: 0.5361 F1: 0.6190\n",
      "TP: 1730.0 TN: 1370.0 FP: 633.0 FN: 1497.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.3050 Acc: 0.8749 Pre: 0.8947 Rec: 0.9186 F1: 0.9065\n",
      "TP: 2856.0 TN: 1265.0 FP: 336.0 FN: 253.0\n",
      "val Loss: 0.1505 Acc: 0.9416 Pre: 0.9501 Rec: 0.9620 F1: 0.9560\n",
      "TP: 2991.0 TN: 1444.0 FP: 157.0 FN: 118.0\n",
      "test Loss: 0.8274 Acc: 0.6205 Pre: 0.7067 Rec: 0.6579 F1: 0.6814\n",
      "TP: 2123.0 TN: 1122.0 FP: 881.0 FN: 1104.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2949 Acc: 0.8807 Pre: 0.8971 Rec: 0.9254 F1: 0.9110\n",
      "TP: 2877.0 TN: 1271.0 FP: 330.0 FN: 232.0\n",
      "val Loss: 0.1690 Acc: 0.9365 Pre: 0.9460 Rec: 0.9585 F1: 0.9522\n",
      "TP: 2980.0 TN: 1431.0 FP: 170.0 FN: 129.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8433 Acc: 0.6314 Pre: 0.6997 Rec: 0.7053 F1: 0.7025\n",
      "TP: 2276.0 TN: 1026.0 FP: 977.0 FN: 951.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3075 Acc: 0.8749 Pre: 0.8920 Rec: 0.9222 F1: 0.9068\n",
      "TP: 2867.0 TN: 1254.0 FP: 347.0 FN: 242.0\n",
      "val Loss: 0.1664 Acc: 0.9355 Pre: 0.9494 Rec: 0.9530 F1: 0.9512\n",
      "TP: 2963.0 TN: 1443.0 FP: 158.0 FN: 146.0\n",
      "test Loss: 0.8701 Acc: 0.6117 Pre: 0.7095 Rec: 0.6275 F1: 0.6660\n",
      "TP: 2025.0 TN: 1174.0 FP: 829.0 FN: 1202.0\n",
      "\n",
      "Training complete in 92m 17s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.]).to(device))\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'val_train', 'val', test_dl='test', num_epochs=25,\n",
    "                               verbose=True, log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += max(window, key=window.count)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.6117 Pre: 0.7095 Rec: 0.6275 F1: 0.6660\n",
      "TP: 2025.0 TN: 1174.0 FP: 829.0 FN: 1202.0\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed stats:\n",
      "(0.6252390057361377, 0.7205012182387748, 0.641462658816238, 0.6786885245901639, 2070, 1200, 803, 1157)\n"
     ]
    }
   ],
   "source": [
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
