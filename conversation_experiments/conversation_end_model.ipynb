{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'conversation_export/data/train.txt'\n",
    "val_file = 'conversation_export/data/val.txt'\n",
    "test_file = 'conversation_export/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('conversation_export/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3673, 'val_train': 550, 'val': 550, 'test': 657}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /afs/cs.stanford.edu/u/danfu/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "100%|██████████| 102502400/102502400 [00:01<00:00, 97360495.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6958 Acc: 0.6273 Pre: 0.6757 Rec: 0.7425 F1: 0.7076\n",
      "TP: 248.0 TN: 97.0 FP: 119.0 FN: 86.0\n",
      "val Loss: 0.4875 Acc: 0.7782 Pre: 0.8272 Rec: 0.8024 F1: 0.8146\n",
      "TP: 268.0 TN: 160.0 FP: 56.0 FN: 66.0\n",
      "test Loss: 0.6583 Acc: 0.6317 Pre: 0.6450 Rec: 0.7207 F1: 0.6807\n",
      "TP: 258.0 TN: 157.0 FP: 142.0 FN: 100.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.6491 Pre: 0.6997 Rec: 0.7395 F1: 0.7191\n",
      "TP: 247.0 TN: 110.0 FP: 106.0 FN: 87.0\n",
      "val Loss: 0.4275 Acc: 0.8182 Pre: 0.8482 Rec: 0.8533 F1: 0.8507\n",
      "TP: 285.0 TN: 165.0 FP: 51.0 FN: 49.0\n",
      "test Loss: 0.7058 Acc: 0.6271 Pre: 0.6205 Rec: 0.8128 F1: 0.7037\n",
      "TP: 291.0 TN: 121.0 FP: 178.0 FN: 67.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5634 Acc: 0.7382 Pre: 0.7582 Rec: 0.8353 F1: 0.7949\n",
      "TP: 279.0 TN: 127.0 FP: 89.0 FN: 55.0\n",
      "val Loss: 0.4642 Acc: 0.7709 Pre: 0.7353 Rec: 0.9731 F1: 0.8376\n",
      "TP: 325.0 TN: 99.0 FP: 117.0 FN: 9.0\n",
      "test Loss: 0.7737 Acc: 0.6271 Pre: 0.6052 Rec: 0.9078 F1: 0.7263\n",
      "TP: 325.0 TN: 87.0 FP: 212.0 FN: 33.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5953 Acc: 0.6818 Pre: 0.7304 Rec: 0.7545 F1: 0.7423\n",
      "TP: 252.0 TN: 123.0 FP: 93.0 FN: 82.0\n",
      "val Loss: 0.4097 Acc: 0.8382 Pre: 0.8635 Rec: 0.8713 F1: 0.8674\n",
      "TP: 291.0 TN: 170.0 FP: 46.0 FN: 43.0\n",
      "test Loss: 0.8268 Acc: 0.5525 Pre: 0.5816 Rec: 0.6369 F1: 0.6080\n",
      "TP: 228.0 TN: 135.0 FP: 164.0 FN: 130.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.6982 Pre: 0.7400 Rec: 0.7754 F1: 0.7573\n",
      "TP: 259.0 TN: 125.0 FP: 91.0 FN: 75.0\n",
      "val Loss: 0.5330 Acc: 0.7236 Pre: 0.6888 Rec: 0.9940 F1: 0.8137\n",
      "TP: 332.0 TN: 66.0 FP: 150.0 FN: 2.0\n",
      "test Loss: 1.0229 Acc: 0.5753 Pre: 0.5644 Rec: 0.9665 F1: 0.7127\n",
      "TP: 346.0 TN: 32.0 FP: 267.0 FN: 12.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.5433 Acc: 0.7382 Pre: 0.7568 Rec: 0.8383 F1: 0.7955\n",
      "TP: 280.0 TN: 126.0 FP: 90.0 FN: 54.0\n",
      "val Loss: 0.2560 Acc: 0.8873 Pre: 0.8953 Rec: 0.9222 F1: 0.9086\n",
      "TP: 308.0 TN: 180.0 FP: 36.0 FN: 26.0\n",
      "test Loss: 0.8415 Acc: 0.6012 Pre: 0.6096 Rec: 0.7458 F1: 0.6709\n",
      "TP: 267.0 TN: 128.0 FP: 171.0 FN: 91.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.4697 Acc: 0.7618 Pre: 0.8012 Rec: 0.8084 F1: 0.8048\n",
      "TP: 270.0 TN: 149.0 FP: 67.0 FN: 64.0\n",
      "val Loss: 0.2499 Acc: 0.9091 Pre: 0.8859 Rec: 0.9760 F1: 0.9288\n",
      "TP: 326.0 TN: 174.0 FP: 42.0 FN: 8.0\n",
      "test Loss: 0.9286 Acc: 0.6027 Pre: 0.6000 Rec: 0.8128 F1: 0.6904\n",
      "TP: 291.0 TN: 105.0 FP: 194.0 FN: 67.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.4588 Acc: 0.8127 Pre: 0.8329 Rec: 0.8653 F1: 0.8488\n",
      "TP: 289.0 TN: 158.0 FP: 58.0 FN: 45.0\n",
      "val Loss: 0.2117 Acc: 0.9273 Pre: 0.9153 Rec: 0.9701 F1: 0.9419\n",
      "TP: 324.0 TN: 186.0 FP: 30.0 FN: 10.0\n",
      "test Loss: 0.8321 Acc: 0.5875 Pre: 0.6005 Rec: 0.7263 F1: 0.6574\n",
      "TP: 260.0 TN: 126.0 FP: 173.0 FN: 98.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.4564 Acc: 0.7927 Pre: 0.8107 Rec: 0.8593 F1: 0.8343\n",
      "TP: 287.0 TN: 149.0 FP: 67.0 FN: 47.0\n",
      "val Loss: 0.2197 Acc: 0.9236 Pre: 0.9424 Rec: 0.9311 F1: 0.9367\n",
      "TP: 311.0 TN: 197.0 FP: 19.0 FN: 23.0\n",
      "test Loss: 0.8109 Acc: 0.6012 Pre: 0.6200 Rec: 0.6927 F1: 0.6544\n",
      "TP: 248.0 TN: 147.0 FP: 152.0 FN: 110.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.4391 Acc: 0.7764 Pre: 0.8040 Rec: 0.8353 F1: 0.8194\n",
      "TP: 279.0 TN: 148.0 FP: 68.0 FN: 55.0\n",
      "val Loss: 0.2307 Acc: 0.9200 Pre: 0.8856 Rec: 0.9970 F1: 0.9380\n",
      "TP: 333.0 TN: 173.0 FP: 43.0 FN: 1.0\n",
      "test Loss: 0.9312 Acc: 0.5784 Pre: 0.5808 Rec: 0.8128 F1: 0.6775\n",
      "TP: 291.0 TN: 89.0 FP: 210.0 FN: 67.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.4365 Acc: 0.8055 Pre: 0.8197 Rec: 0.8713 F1: 0.8447\n",
      "TP: 291.0 TN: 152.0 FP: 64.0 FN: 43.0\n",
      "val Loss: 0.2046 Acc: 0.9182 Pre: 0.9003 Rec: 0.9731 F1: 0.9353\n",
      "TP: 325.0 TN: 180.0 FP: 36.0 FN: 9.0\n",
      "test Loss: 0.8879 Acc: 0.5890 Pre: 0.5965 Rec: 0.7598 F1: 0.6683\n",
      "TP: 272.0 TN: 115.0 FP: 184.0 FN: 86.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.4655 Acc: 0.7745 Pre: 0.8035 Rec: 0.8323 F1: 0.8176\n",
      "TP: 278.0 TN: 148.0 FP: 68.0 FN: 56.0\n",
      "val Loss: 0.1978 Acc: 0.9255 Pre: 0.8970 Rec: 0.9910 F1: 0.9417\n",
      "TP: 331.0 TN: 178.0 FP: 38.0 FN: 3.0\n",
      "test Loss: 0.8778 Acc: 0.5906 Pre: 0.5991 Rec: 0.7514 F1: 0.6667\n",
      "TP: 269.0 TN: 119.0 FP: 180.0 FN: 89.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.4073 Acc: 0.8309 Pre: 0.8493 Rec: 0.8772 F1: 0.8630\n",
      "TP: 293.0 TN: 164.0 FP: 52.0 FN: 41.0\n",
      "val Loss: 0.1795 Acc: 0.9455 Pre: 0.9343 Rec: 0.9790 F1: 0.9561\n",
      "TP: 327.0 TN: 193.0 FP: 23.0 FN: 7.0\n",
      "test Loss: 0.9176 Acc: 0.5723 Pre: 0.6043 Rec: 0.6229 F1: 0.6135\n",
      "TP: 223.0 TN: 153.0 FP: 146.0 FN: 135.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.4403 Acc: 0.8145 Pre: 0.8432 Rec: 0.8533 F1: 0.8482\n",
      "TP: 285.0 TN: 163.0 FP: 53.0 FN: 49.0\n",
      "val Loss: 0.1877 Acc: 0.9364 Pre: 0.9489 Rec: 0.9461 F1: 0.9475\n",
      "TP: 316.0 TN: 199.0 FP: 17.0 FN: 18.0\n",
      "test Loss: 0.8724 Acc: 0.5738 Pre: 0.6196 Rec: 0.5642 F1: 0.5906\n",
      "TP: 202.0 TN: 175.0 FP: 124.0 FN: 156.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.4267 Acc: 0.8127 Pre: 0.8329 Rec: 0.8653 F1: 0.8488\n",
      "TP: 289.0 TN: 158.0 FP: 58.0 FN: 45.0\n",
      "val Loss: 0.1892 Acc: 0.9382 Pre: 0.9190 Rec: 0.9850 F1: 0.9509\n",
      "TP: 329.0 TN: 187.0 FP: 29.0 FN: 5.0\n",
      "test Loss: 0.9146 Acc: 0.6027 Pre: 0.6075 Rec: 0.7654 F1: 0.6774\n",
      "TP: 274.0 TN: 122.0 FP: 177.0 FN: 84.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.4102 Acc: 0.8182 Pre: 0.8382 Rec: 0.8683 F1: 0.8529\n",
      "TP: 290.0 TN: 160.0 FP: 56.0 FN: 44.0\n",
      "val Loss: 0.1905 Acc: 0.9364 Pre: 0.9118 Rec: 0.9910 F1: 0.9498\n",
      "TP: 331.0 TN: 184.0 FP: 32.0 FN: 3.0\n",
      "test Loss: 0.9340 Acc: 0.5936 Pre: 0.5978 Rec: 0.7765 F1: 0.6756\n",
      "TP: 278.0 TN: 112.0 FP: 187.0 FN: 80.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.4399 Acc: 0.8000 Pre: 0.8237 Rec: 0.8533 F1: 0.8382\n",
      "TP: 285.0 TN: 155.0 FP: 61.0 FN: 49.0\n",
      "val Loss: 0.1775 Acc: 0.9455 Pre: 0.9497 Rec: 0.9611 F1: 0.9554\n",
      "TP: 321.0 TN: 199.0 FP: 17.0 FN: 13.0\n",
      "test Loss: 0.8658 Acc: 0.5784 Pre: 0.6167 Rec: 0.5978 F1: 0.6071\n",
      "TP: 214.0 TN: 166.0 FP: 133.0 FN: 144.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.4030 Acc: 0.8127 Pre: 0.8309 Rec: 0.8683 F1: 0.8492\n",
      "TP: 290.0 TN: 157.0 FP: 59.0 FN: 44.0\n",
      "val Loss: 0.1796 Acc: 0.9455 Pre: 0.9497 Rec: 0.9611 F1: 0.9554\n",
      "TP: 321.0 TN: 199.0 FP: 17.0 FN: 13.0\n",
      "test Loss: 0.8766 Acc: 0.5693 Pre: 0.6106 Rec: 0.5782 F1: 0.5940\n",
      "TP: 207.0 TN: 167.0 FP: 132.0 FN: 151.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.4164 Acc: 0.8127 Pre: 0.8489 Rec: 0.8413 F1: 0.8451\n",
      "TP: 281.0 TN: 166.0 FP: 50.0 FN: 53.0\n",
      "val Loss: 0.1842 Acc: 0.9400 Pre: 0.9337 Rec: 0.9701 F1: 0.9515\n",
      "TP: 324.0 TN: 193.0 FP: 23.0 FN: 10.0\n",
      "test Loss: 0.8540 Acc: 0.5997 Pre: 0.6102 Rec: 0.7346 F1: 0.6667\n",
      "TP: 263.0 TN: 131.0 FP: 168.0 FN: 95.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3970 Acc: 0.8309 Pre: 0.8453 Rec: 0.8832 F1: 0.8638\n",
      "TP: 295.0 TN: 162.0 FP: 54.0 FN: 39.0\n",
      "val Loss: 0.1968 Acc: 0.9273 Pre: 0.8995 Rec: 0.9910 F1: 0.9430\n",
      "TP: 331.0 TN: 179.0 FP: 37.0 FN: 3.0\n",
      "test Loss: 0.9052 Acc: 0.5875 Pre: 0.5944 Rec: 0.7654 F1: 0.6691\n",
      "TP: 274.0 TN: 112.0 FP: 187.0 FN: 84.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.4203 Acc: 0.8255 Pre: 0.8287 Rec: 0.8982 F1: 0.8621\n",
      "TP: 300.0 TN: 154.0 FP: 62.0 FN: 34.0\n",
      "val Loss: 0.1791 Acc: 0.9455 Pre: 0.9294 Rec: 0.9850 F1: 0.9564\n",
      "TP: 329.0 TN: 191.0 FP: 25.0 FN: 5.0\n",
      "test Loss: 0.9144 Acc: 0.6012 Pre: 0.6048 Rec: 0.7737 F1: 0.6789\n",
      "TP: 277.0 TN: 118.0 FP: 181.0 FN: 81.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.4243 Acc: 0.8000 Pre: 0.8237 Rec: 0.8533 F1: 0.8382\n",
      "TP: 285.0 TN: 155.0 FP: 61.0 FN: 49.0\n",
      "val Loss: 0.1791 Acc: 0.9400 Pre: 0.9239 Rec: 0.9820 F1: 0.9521\n",
      "TP: 328.0 TN: 189.0 FP: 27.0 FN: 6.0\n",
      "test Loss: 0.9122 Acc: 0.5723 Pre: 0.5937 Rec: 0.6816 F1: 0.6346\n",
      "TP: 244.0 TN: 132.0 FP: 167.0 FN: 114.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.4010 Acc: 0.8291 Pre: 0.8371 Rec: 0.8922 F1: 0.8638\n",
      "TP: 298.0 TN: 158.0 FP: 58.0 FN: 36.0\n",
      "val Loss: 0.1811 Acc: 0.9418 Pre: 0.9242 Rec: 0.9850 F1: 0.9536\n",
      "TP: 329.0 TN: 189.0 FP: 27.0 FN: 5.0\n",
      "test Loss: 0.8914 Acc: 0.5799 Pre: 0.5940 Rec: 0.7235 F1: 0.6524\n",
      "TP: 259.0 TN: 122.0 FP: 177.0 FN: 99.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.4233 Acc: 0.8145 Pre: 0.8295 Rec: 0.8743 F1: 0.8513\n",
      "TP: 292.0 TN: 156.0 FP: 60.0 FN: 42.0\n",
      "val Loss: 0.1833 Acc: 0.9364 Pre: 0.9164 Rec: 0.9850 F1: 0.9495\n",
      "TP: 329.0 TN: 186.0 FP: 30.0 FN: 5.0\n",
      "test Loss: 0.8921 Acc: 0.5814 Pre: 0.5981 Rec: 0.7067 F1: 0.6479\n",
      "TP: 253.0 TN: 129.0 FP: 170.0 FN: 105.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3958 Acc: 0.8291 Pre: 0.8390 Rec: 0.8892 F1: 0.8634\n",
      "TP: 297.0 TN: 159.0 FP: 57.0 FN: 37.0\n",
      "val Loss: 0.1765 Acc: 0.9455 Pre: 0.9318 Rec: 0.9820 F1: 0.9563\n",
      "TP: 328.0 TN: 192.0 FP: 24.0 FN: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.9019 Acc: 0.5845 Pre: 0.6034 Rec: 0.6927 F1: 0.6450\n",
      "TP: 248.0 TN: 136.0 FP: 163.0 FN: 110.0\n",
      "\n",
      "Training complete in 11m 54s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.]).to(device))\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'val_train', 'val', test_dl='test', num_epochs=25,\n",
    "                               verbose=True, log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
