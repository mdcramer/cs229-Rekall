{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'conversation_export/data/train.txt'\n",
    "val_file = 'conversation_export/data/val.txt'\n",
    "test_file = 'conversation_export/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('conversation_export/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 32410, 'val_train': 4710, 'val': 4710, 'test': 5230}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6486 Acc: 0.6726 Pre: 0.7286 Rec: 0.8032 F1: 0.7641\n",
      "TP: 2497.0 TN: 671.0 FP: 930.0 FN: 612.0\n",
      "val Loss: 0.6799 Acc: 0.7187 Pre: 0.7024 Rec: 0.9958 F1: 0.8237\n",
      "TP: 3096.0 TN: 289.0 FP: 1312.0 FN: 13.0\n",
      "test Loss: 1.0372 Acc: 0.6310 Pre: 0.6261 Rec: 0.9975 F1: 0.7694\n",
      "TP: 3219.0 TN: 81.0 FP: 1922.0 FN: 8.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5703 Acc: 0.7225 Pre: 0.7712 Rec: 0.8241 F1: 0.7968\n",
      "TP: 2562.0 TN: 841.0 FP: 760.0 FN: 547.0\n",
      "val Loss: 0.4794 Acc: 0.7760 Pre: 0.9161 Rec: 0.7272 F1: 0.8108\n",
      "TP: 2261.0 TN: 1394.0 FP: 207.0 FN: 848.0\n",
      "test Loss: 0.8110 Acc: 0.5736 Pre: 0.7151 Rec: 0.5135 F1: 0.5978\n",
      "TP: 1657.0 TN: 1343.0 FP: 660.0 FN: 1570.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5274 Acc: 0.7529 Pre: 0.7962 Rec: 0.8408 F1: 0.8179\n",
      "TP: 2614.0 TN: 932.0 FP: 669.0 FN: 495.0\n",
      "val Loss: 0.3528 Acc: 0.8669 Pre: 0.8733 Rec: 0.9337 F1: 0.9025\n",
      "TP: 2903.0 TN: 1180.0 FP: 421.0 FN: 206.0\n",
      "test Loss: 1.0453 Acc: 0.6141 Pre: 0.6998 Rec: 0.6560 F1: 0.6772\n",
      "TP: 2117.0 TN: 1095.0 FP: 908.0 FN: 1110.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4992 Acc: 0.7677 Pre: 0.8063 Rec: 0.8530 F1: 0.8290\n",
      "TP: 2652.0 TN: 964.0 FP: 637.0 FN: 457.0\n",
      "val Loss: 0.2800 Acc: 0.8845 Pre: 0.8796 Rec: 0.9559 F1: 0.9162\n",
      "TP: 2972.0 TN: 1194.0 FP: 407.0 FN: 137.0\n",
      "test Loss: 0.8223 Acc: 0.6279 Pre: 0.7015 Rec: 0.6910 F1: 0.6962\n",
      "TP: 2230.0 TN: 1054.0 FP: 949.0 FN: 997.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4566 Acc: 0.7921 Pre: 0.8263 Rec: 0.8675 F1: 0.8464\n",
      "TP: 2697.0 TN: 1034.0 FP: 567.0 FN: 412.0\n",
      "val Loss: 0.2816 Acc: 0.8936 Pre: 0.8966 Rec: 0.9482 F1: 0.9217\n",
      "TP: 2948.0 TN: 1261.0 FP: 340.0 FN: 161.0\n",
      "test Loss: 0.8313 Acc: 0.5979 Pre: 0.6868 Rec: 0.6402 F1: 0.6627\n",
      "TP: 2066.0 TN: 1061.0 FP: 942.0 FN: 1161.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4440 Acc: 0.8042 Pre: 0.8389 Rec: 0.8707 F1: 0.8545\n",
      "TP: 2707.0 TN: 1081.0 FP: 520.0 FN: 402.0\n",
      "val Loss: 0.2124 Acc: 0.9193 Pre: 0.9395 Rec: 0.9382 F1: 0.9388\n",
      "TP: 2917.0 TN: 1413.0 FP: 188.0 FN: 192.0\n",
      "test Loss: 0.7958 Acc: 0.6033 Pre: 0.7098 Rec: 0.6040 F1: 0.6526\n",
      "TP: 1949.0 TN: 1206.0 FP: 797.0 FN: 1278.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3684 Acc: 0.8414 Pre: 0.8625 Rec: 0.9038 F1: 0.8827\n",
      "TP: 2810.0 TN: 1153.0 FP: 448.0 FN: 299.0\n",
      "val Loss: 0.1669 Acc: 0.9420 Pre: 0.9456 Rec: 0.9678 F1: 0.9566\n",
      "TP: 3009.0 TN: 1428.0 FP: 173.0 FN: 100.0\n",
      "test Loss: 0.8574 Acc: 0.5904 Pre: 0.7062 Rec: 0.5758 F1: 0.6343\n",
      "TP: 1858.0 TN: 1230.0 FP: 773.0 FN: 1369.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3480 Acc: 0.8503 Pre: 0.8724 Rec: 0.9058 F1: 0.8887\n",
      "TP: 2816.0 TN: 1189.0 FP: 412.0 FN: 293.0\n",
      "val Loss: 0.1601 Acc: 0.9380 Pre: 0.9338 Rec: 0.9752 F1: 0.9541\n",
      "TP: 3032.0 TN: 1386.0 FP: 215.0 FN: 77.0\n",
      "test Loss: 0.8390 Acc: 0.6220 Pre: 0.7092 Rec: 0.6566 F1: 0.6819\n",
      "TP: 2119.0 TN: 1134.0 FP: 869.0 FN: 1108.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3297 Acc: 0.8654 Pre: 0.8844 Rec: 0.9157 F1: 0.8998\n",
      "TP: 2847.0 TN: 1229.0 FP: 372.0 FN: 262.0\n",
      "val Loss: 0.1513 Acc: 0.9433 Pre: 0.9435 Rec: 0.9723 F1: 0.9577\n",
      "TP: 3023.0 TN: 1420.0 FP: 181.0 FN: 86.0\n",
      "test Loss: 0.8774 Acc: 0.6088 Pre: 0.7150 Rec: 0.6086 F1: 0.6575\n",
      "TP: 1964.0 TN: 1220.0 FP: 783.0 FN: 1263.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3143 Acc: 0.8703 Pre: 0.8864 Rec: 0.9215 F1: 0.9036\n",
      "TP: 2865.0 TN: 1234.0 FP: 367.0 FN: 244.0\n",
      "val Loss: 0.1514 Acc: 0.9476 Pre: 0.9704 Rec: 0.9495 F1: 0.9598\n",
      "TP: 2952.0 TN: 1511.0 FP: 90.0 FN: 157.0\n",
      "test Loss: 1.0021 Acc: 0.5537 Pre: 0.7275 Rec: 0.4425 F1: 0.5503\n",
      "TP: 1428.0 TN: 1468.0 FP: 535.0 FN: 1799.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3106 Acc: 0.8711 Pre: 0.8924 Rec: 0.9151 F1: 0.9036\n",
      "TP: 2845.0 TN: 1258.0 FP: 343.0 FN: 264.0\n",
      "val Loss: 0.1335 Acc: 0.9520 Pre: 0.9604 Rec: 0.9672 F1: 0.9638\n",
      "TP: 3007.0 TN: 1477.0 FP: 124.0 FN: 102.0\n",
      "test Loss: 0.8368 Acc: 0.5964 Pre: 0.7207 Rec: 0.5646 F1: 0.6332\n",
      "TP: 1822.0 TN: 1297.0 FP: 706.0 FN: 1405.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3054 Acc: 0.8654 Pre: 0.8847 Rec: 0.9154 F1: 0.8998\n",
      "TP: 2846.0 TN: 1230.0 FP: 371.0 FN: 263.0\n",
      "val Loss: 0.1268 Acc: 0.9539 Pre: 0.9671 Rec: 0.9630 F1: 0.9650\n",
      "TP: 2994.0 TN: 1499.0 FP: 102.0 FN: 115.0\n",
      "test Loss: 0.9084 Acc: 0.5946 Pre: 0.7313 Rec: 0.5423 F1: 0.6228\n",
      "TP: 1750.0 TN: 1360.0 FP: 643.0 FN: 1477.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.2922 Acc: 0.8805 Pre: 0.8988 Rec: 0.9228 F1: 0.9106\n",
      "TP: 2869.0 TN: 1278.0 FP: 323.0 FN: 240.0\n",
      "val Loss: 0.1257 Acc: 0.9539 Pre: 0.9539 Rec: 0.9775 F1: 0.9655\n",
      "TP: 3039.0 TN: 1454.0 FP: 147.0 FN: 70.0\n",
      "test Loss: 0.8778 Acc: 0.6264 Pre: 0.7074 Rec: 0.6728 F1: 0.6896\n",
      "TP: 2171.0 TN: 1105.0 FP: 898.0 FN: 1056.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2744 Acc: 0.8875 Pre: 0.9056 Rec: 0.9260 F1: 0.9157\n",
      "TP: 2879.0 TN: 1301.0 FP: 300.0 FN: 230.0\n",
      "val Loss: 0.1213 Acc: 0.9590 Pre: 0.9658 Rec: 0.9723 F1: 0.9691\n",
      "TP: 3023.0 TN: 1494.0 FP: 107.0 FN: 86.0\n",
      "test Loss: 0.8914 Acc: 0.6098 Pre: 0.7221 Rec: 0.5975 F1: 0.6539\n",
      "TP: 1928.0 TN: 1261.0 FP: 742.0 FN: 1299.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2773 Acc: 0.8849 Pre: 0.9030 Rec: 0.9251 F1: 0.9139\n",
      "TP: 2876.0 TN: 1292.0 FP: 309.0 FN: 233.0\n",
      "val Loss: 0.1271 Acc: 0.9575 Pre: 0.9690 Rec: 0.9665 F1: 0.9678\n",
      "TP: 3005.0 TN: 1505.0 FP: 96.0 FN: 104.0\n",
      "test Loss: 0.9429 Acc: 0.5847 Pre: 0.7360 Rec: 0.5098 F1: 0.6023\n",
      "TP: 1645.0 TN: 1413.0 FP: 590.0 FN: 1582.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2705 Acc: 0.8960 Pre: 0.9093 Rec: 0.9357 F1: 0.9223\n",
      "TP: 2909.0 TN: 1311.0 FP: 290.0 FN: 200.0\n",
      "val Loss: 0.1191 Acc: 0.9565 Pre: 0.9633 Rec: 0.9711 F1: 0.9672\n",
      "TP: 3019.0 TN: 1486.0 FP: 115.0 FN: 90.0\n",
      "test Loss: 0.9065 Acc: 0.6023 Pre: 0.7207 Rec: 0.5804 F1: 0.6430\n",
      "TP: 1873.0 TN: 1277.0 FP: 726.0 FN: 1354.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2863 Acc: 0.8817 Pre: 0.9015 Rec: 0.9215 F1: 0.9114\n",
      "TP: 2865.0 TN: 1288.0 FP: 313.0 FN: 244.0\n",
      "val Loss: 0.1211 Acc: 0.9573 Pre: 0.9687 Rec: 0.9665 F1: 0.9676\n",
      "TP: 3005.0 TN: 1504.0 FP: 97.0 FN: 104.0\n",
      "test Loss: 0.9169 Acc: 0.6008 Pre: 0.7259 Rec: 0.5671 F1: 0.6367\n",
      "TP: 1830.0 TN: 1312.0 FP: 691.0 FN: 1397.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2743 Acc: 0.8875 Pre: 0.9054 Rec: 0.9263 F1: 0.9157\n",
      "TP: 2880.0 TN: 1300.0 FP: 301.0 FN: 229.0\n",
      "val Loss: 0.1214 Acc: 0.9573 Pre: 0.9712 Rec: 0.9640 F1: 0.9676\n",
      "TP: 2997.0 TN: 1512.0 FP: 89.0 FN: 112.0\n",
      "test Loss: 0.9065 Acc: 0.5962 Pre: 0.7355 Rec: 0.5395 F1: 0.6225\n",
      "TP: 1741.0 TN: 1377.0 FP: 626.0 FN: 1486.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2726 Acc: 0.8879 Pre: 0.9004 Rec: 0.9334 F1: 0.9166\n",
      "TP: 2902.0 TN: 1280.0 FP: 321.0 FN: 207.0\n",
      "val Loss: 0.1181 Acc: 0.9577 Pre: 0.9652 Rec: 0.9711 F1: 0.9681\n",
      "TP: 3019.0 TN: 1492.0 FP: 109.0 FN: 90.0\n",
      "test Loss: 0.8829 Acc: 0.6048 Pre: 0.7236 Rec: 0.5817 F1: 0.6449\n",
      "TP: 1877.0 TN: 1286.0 FP: 717.0 FN: 1350.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2802 Acc: 0.8845 Pre: 0.9024 Rec: 0.9251 F1: 0.9136\n",
      "TP: 2876.0 TN: 1290.0 FP: 311.0 FN: 233.0\n",
      "val Loss: 0.1202 Acc: 0.9594 Pre: 0.9620 Rec: 0.9772 F1: 0.9695\n",
      "TP: 3038.0 TN: 1481.0 FP: 120.0 FN: 71.0\n",
      "test Loss: 0.8619 Acc: 0.6052 Pre: 0.7166 Rec: 0.5956 F1: 0.6505\n",
      "TP: 1922.0 TN: 1243.0 FP: 760.0 FN: 1305.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2749 Acc: 0.8900 Pre: 0.9050 Rec: 0.9312 F1: 0.9179\n",
      "TP: 2895.0 TN: 1297.0 FP: 304.0 FN: 214.0\n",
      "val Loss: 0.1176 Acc: 0.9558 Pre: 0.9566 Rec: 0.9775 F1: 0.9669\n",
      "TP: 3039.0 TN: 1463.0 FP: 138.0 FN: 70.0\n",
      "test Loss: 0.8696 Acc: 0.6174 Pre: 0.7174 Rec: 0.6269 F1: 0.6691\n",
      "TP: 2023.0 TN: 1206.0 FP: 797.0 FN: 1204.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2675 Acc: 0.8953 Pre: 0.9082 Rec: 0.9360 F1: 0.9219\n",
      "TP: 2910.0 TN: 1307.0 FP: 294.0 FN: 199.0\n",
      "val Loss: 0.1218 Acc: 0.9588 Pre: 0.9743 Rec: 0.9630 F1: 0.9686\n",
      "TP: 2994.0 TN: 1522.0 FP: 79.0 FN: 115.0\n",
      "test Loss: 0.9389 Acc: 0.5855 Pre: 0.7426 Rec: 0.5023 F1: 0.5993\n",
      "TP: 1621.0 TN: 1441.0 FP: 562.0 FN: 1606.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2712 Acc: 0.8915 Pre: 0.9052 Rec: 0.9334 F1: 0.9191\n",
      "TP: 2902.0 TN: 1297.0 FP: 304.0 FN: 207.0\n",
      "val Loss: 0.1182 Acc: 0.9561 Pre: 0.9549 Rec: 0.9797 F1: 0.9671\n",
      "TP: 3046.0 TN: 1457.0 FP: 144.0 FN: 63.0\n",
      "test Loss: 0.8661 Acc: 0.6172 Pre: 0.7064 Rec: 0.6495 F1: 0.6768\n",
      "TP: 2096.0 TN: 1132.0 FP: 871.0 FN: 1131.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2569 Acc: 0.8955 Pre: 0.9126 Rec: 0.9308 F1: 0.9217\n",
      "TP: 2894.0 TN: 1324.0 FP: 277.0 FN: 215.0\n",
      "val Loss: 0.1188 Acc: 0.9567 Pre: 0.9607 Rec: 0.9743 F1: 0.9674\n",
      "TP: 3029.0 TN: 1477.0 FP: 124.0 FN: 80.0\n",
      "test Loss: 0.8951 Acc: 0.6099 Pre: 0.7070 Rec: 0.6281 F1: 0.6652\n",
      "TP: 2027.0 TN: 1163.0 FP: 840.0 FN: 1200.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2654 Acc: 0.8930 Pre: 0.9069 Rec: 0.9337 F1: 0.9201\n",
      "TP: 2903.0 TN: 1303.0 FP: 298.0 FN: 206.0\n",
      "val Loss: 0.1185 Acc: 0.9590 Pre: 0.9655 Rec: 0.9727 F1: 0.9691\n",
      "TP: 3024.0 TN: 1493.0 FP: 108.0 FN: 85.0\n",
      "test Loss: 0.9156 Acc: 0.5990 Pre: 0.7280 Rec: 0.5590 F1: 0.6324\n",
      "TP: 1804.0 TN: 1329.0 FP: 674.0 FN: 1423.0\n",
      "\n",
      "Training complete in 119m 4s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.6864 Pre: 0.7326 Rec: 0.8266 F1: 0.7768\n",
      "TP: 2570.0 TN: 663.0 FP: 938.0 FN: 539.0\n",
      "val Loss: 0.4078 Acc: 0.8166 Pre: 0.8245 Rec: 0.9173 F1: 0.8685\n",
      "TP: 2852.0 TN: 994.0 FP: 607.0 FN: 257.0\n",
      "test Loss: 0.6344 Acc: 0.6728 Pre: 0.6944 Rec: 0.8392 F1: 0.7599\n",
      "TP: 2708.0 TN: 811.0 FP: 1192.0 FN: 519.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5569 Acc: 0.7312 Pre: 0.7773 Rec: 0.8308 F1: 0.8032\n",
      "TP: 2583.0 TN: 861.0 FP: 740.0 FN: 526.0\n",
      "val Loss: 0.3671 Acc: 0.8369 Pre: 0.8862 Rec: 0.8639 F1: 0.8749\n",
      "TP: 2686.0 TN: 1256.0 FP: 345.0 FN: 423.0\n",
      "test Loss: 0.7037 Acc: 0.6757 Pre: 0.7257 Rec: 0.7626 F1: 0.7437\n",
      "TP: 2461.0 TN: 1073.0 FP: 930.0 FN: 766.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5172 Acc: 0.7616 Pre: 0.8009 Rec: 0.8501 F1: 0.8248\n",
      "TP: 2643.0 TN: 944.0 FP: 657.0 FN: 466.0\n",
      "val Loss: 0.3104 Acc: 0.8641 Pre: 0.8891 Rec: 0.9074 F1: 0.8981\n",
      "TP: 2821.0 TN: 1249.0 FP: 352.0 FN: 288.0\n",
      "test Loss: 0.9655 Acc: 0.5706 Pre: 0.6705 Rec: 0.5978 F1: 0.6320\n",
      "TP: 1929.0 TN: 1055.0 FP: 948.0 FN: 1298.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5128 Acc: 0.7677 Pre: 0.8097 Rec: 0.8472 F1: 0.8280\n",
      "TP: 2634.0 TN: 982.0 FP: 619.0 FN: 475.0\n",
      "val Loss: 0.3047 Acc: 0.8856 Pre: 0.8740 Rec: 0.9659 F1: 0.9176\n",
      "TP: 3003.0 TN: 1168.0 FP: 433.0 FN: 106.0\n",
      "test Loss: 0.8136 Acc: 0.6553 Pre: 0.6904 Rec: 0.8001 F1: 0.7412\n",
      "TP: 2582.0 TN: 845.0 FP: 1158.0 FN: 645.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4718 Acc: 0.7885 Pre: 0.8250 Rec: 0.8627 F1: 0.8434\n",
      "TP: 2682.0 TN: 1032.0 FP: 569.0 FN: 427.0\n",
      "val Loss: 0.2667 Acc: 0.8949 Pre: 0.9331 Rec: 0.9058 F1: 0.9192\n",
      "TP: 2816.0 TN: 1399.0 FP: 202.0 FN: 293.0\n",
      "test Loss: 0.7305 Acc: 0.6256 Pre: 0.7157 Rec: 0.6523 F1: 0.6826\n",
      "TP: 2105.0 TN: 1167.0 FP: 836.0 FN: 1122.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4241 Acc: 0.8106 Pre: 0.8393 Rec: 0.8820 F1: 0.8601\n",
      "TP: 2742.0 TN: 1076.0 FP: 525.0 FN: 367.0\n",
      "val Loss: 0.2943 Acc: 0.8803 Pre: 0.8588 Rec: 0.9797 F1: 0.9153\n",
      "TP: 3046.0 TN: 1100.0 FP: 501.0 FN: 63.0\n",
      "test Loss: 0.8006 Acc: 0.6545 Pre: 0.6746 Rec: 0.8500 F1: 0.7522\n",
      "TP: 2743.0 TN: 680.0 FP: 1323.0 FN: 484.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3792 Acc: 0.8323 Pre: 0.8545 Rec: 0.8990 F1: 0.8762\n",
      "TP: 2795.0 TN: 1125.0 FP: 476.0 FN: 314.0\n",
      "val Loss: 0.1837 Acc: 0.9323 Pre: 0.9365 Rec: 0.9627 F1: 0.9494\n",
      "TP: 2993.0 TN: 1398.0 FP: 203.0 FN: 116.0\n",
      "test Loss: 0.7993 Acc: 0.6189 Pre: 0.7117 Rec: 0.6427 F1: 0.6755\n",
      "TP: 2074.0 TN: 1163.0 FP: 840.0 FN: 1153.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3414 Acc: 0.8548 Pre: 0.8760 Rec: 0.9087 F1: 0.8920\n",
      "TP: 2825.0 TN: 1201.0 FP: 400.0 FN: 284.0\n",
      "val Loss: 0.1596 Acc: 0.9425 Pre: 0.9534 Rec: 0.9598 F1: 0.9566\n",
      "TP: 2984.0 TN: 1455.0 FP: 146.0 FN: 125.0\n",
      "test Loss: 0.8363 Acc: 0.6249 Pre: 0.7306 Rec: 0.6210 F1: 0.6714\n",
      "TP: 2004.0 TN: 1264.0 FP: 739.0 FN: 1223.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3323 Acc: 0.8607 Pre: 0.8773 Rec: 0.9173 F1: 0.8969\n",
      "TP: 2852.0 TN: 1202.0 FP: 399.0 FN: 257.0\n",
      "val Loss: 0.1518 Acc: 0.9469 Pre: 0.9435 Rec: 0.9781 F1: 0.9605\n",
      "TP: 3041.0 TN: 1419.0 FP: 182.0 FN: 68.0\n",
      "test Loss: 0.8875 Acc: 0.6172 Pre: 0.7032 Rec: 0.6570 F1: 0.6793\n",
      "TP: 2120.0 TN: 1108.0 FP: 895.0 FN: 1107.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3340 Acc: 0.8573 Pre: 0.8804 Rec: 0.9070 F1: 0.8935\n",
      "TP: 2820.0 TN: 1218.0 FP: 383.0 FN: 289.0\n",
      "val Loss: 0.1418 Acc: 0.9522 Pre: 0.9532 Rec: 0.9756 F1: 0.9642\n",
      "TP: 3033.0 TN: 1452.0 FP: 149.0 FN: 76.0\n",
      "test Loss: 0.8030 Acc: 0.6216 Pre: 0.7134 Rec: 0.6464 F1: 0.6783\n",
      "TP: 2086.0 TN: 1165.0 FP: 838.0 FN: 1141.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3037 Acc: 0.8701 Pre: 0.8883 Rec: 0.9186 F1: 0.9032\n",
      "TP: 2856.0 TN: 1242.0 FP: 359.0 FN: 253.0\n",
      "val Loss: 0.1309 Acc: 0.9558 Pre: 0.9714 Rec: 0.9614 F1: 0.9664\n",
      "TP: 2989.0 TN: 1513.0 FP: 88.0 FN: 120.0\n",
      "test Loss: 0.9587 Acc: 0.5769 Pre: 0.7313 Rec: 0.4967 F1: 0.5916\n",
      "TP: 1603.0 TN: 1414.0 FP: 589.0 FN: 1624.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3159 Acc: 0.8679 Pre: 0.8899 Rec: 0.9128 F1: 0.9012\n",
      "TP: 2838.0 TN: 1250.0 FP: 351.0 FN: 271.0\n",
      "val Loss: 0.1470 Acc: 0.9495 Pre: 0.9397 Rec: 0.9868 F1: 0.9627\n",
      "TP: 3068.0 TN: 1404.0 FP: 197.0 FN: 41.0\n",
      "test Loss: 0.8727 Acc: 0.6380 Pre: 0.6870 Rec: 0.7592 F1: 0.7213\n",
      "TP: 2450.0 TN: 887.0 FP: 1116.0 FN: 777.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3104 Acc: 0.8679 Pre: 0.8870 Rec: 0.9167 F1: 0.9016\n",
      "TP: 2850.0 TN: 1238.0 FP: 363.0 FN: 259.0\n",
      "val Loss: 0.1213 Acc: 0.9558 Pre: 0.9630 Rec: 0.9704 F1: 0.9667\n",
      "TP: 3017.0 TN: 1485.0 FP: 116.0 FN: 92.0\n",
      "test Loss: 0.9009 Acc: 0.6134 Pre: 0.7281 Rec: 0.5959 F1: 0.6554\n",
      "TP: 1923.0 TN: 1285.0 FP: 718.0 FN: 1304.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2996 Acc: 0.8805 Pre: 0.8981 Rec: 0.9238 F1: 0.9107\n",
      "TP: 2872.0 TN: 1275.0 FP: 326.0 FN: 237.0\n",
      "val Loss: 0.1164 Acc: 0.9584 Pre: 0.9634 Rec: 0.9739 F1: 0.9686\n",
      "TP: 3028.0 TN: 1486.0 FP: 115.0 FN: 81.0\n",
      "test Loss: 0.9396 Acc: 0.6105 Pre: 0.7301 Rec: 0.5851 F1: 0.6496\n",
      "TP: 1888.0 TN: 1305.0 FP: 698.0 FN: 1339.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2889 Acc: 0.8866 Pre: 0.8992 Rec: 0.9328 F1: 0.9157\n",
      "TP: 2900.0 TN: 1276.0 FP: 325.0 FN: 209.0\n",
      "val Loss: 0.1155 Acc: 0.9592 Pre: 0.9691 Rec: 0.9691 F1: 0.9691\n",
      "TP: 3013.0 TN: 1505.0 FP: 96.0 FN: 96.0\n",
      "test Loss: 0.9419 Acc: 0.6017 Pre: 0.7275 Rec: 0.5668 F1: 0.6372\n",
      "TP: 1829.0 TN: 1318.0 FP: 685.0 FN: 1398.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3046 Acc: 0.8779 Pre: 0.8954 Rec: 0.9228 F1: 0.9089\n",
      "TP: 2869.0 TN: 1266.0 FP: 335.0 FN: 240.0\n",
      "val Loss: 0.1185 Acc: 0.9586 Pre: 0.9694 Rec: 0.9678 F1: 0.9686\n",
      "TP: 3009.0 TN: 1506.0 FP: 95.0 FN: 100.0\n",
      "test Loss: 0.9168 Acc: 0.5956 Pre: 0.7217 Rec: 0.5609 F1: 0.6312\n",
      "TP: 1810.0 TN: 1305.0 FP: 698.0 FN: 1417.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2929 Acc: 0.8813 Pre: 0.8982 Rec: 0.9251 F1: 0.9114\n",
      "TP: 2876.0 TN: 1275.0 FP: 326.0 FN: 233.0\n",
      "val Loss: 0.1211 Acc: 0.9575 Pre: 0.9752 Rec: 0.9601 F1: 0.9676\n",
      "TP: 2985.0 TN: 1525.0 FP: 76.0 FN: 124.0\n",
      "test Loss: 1.0212 Acc: 0.5734 Pre: 0.7533 Rec: 0.4589 F1: 0.5704\n",
      "TP: 1481.0 TN: 1518.0 FP: 485.0 FN: 1746.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2994 Acc: 0.8762 Pre: 0.8974 Rec: 0.9173 F1: 0.9073\n",
      "TP: 2852.0 TN: 1275.0 FP: 326.0 FN: 257.0\n",
      "val Loss: 0.1158 Acc: 0.9605 Pre: 0.9698 Rec: 0.9704 F1: 0.9701\n",
      "TP: 3017.0 TN: 1507.0 FP: 94.0 FN: 92.0\n",
      "test Loss: 0.9335 Acc: 0.5887 Pre: 0.7227 Rec: 0.5411 F1: 0.6188\n",
      "TP: 1746.0 TN: 1333.0 FP: 670.0 FN: 1481.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3058 Acc: 0.8745 Pre: 0.8912 Rec: 0.9225 F1: 0.9066\n",
      "TP: 2868.0 TN: 1251.0 FP: 350.0 FN: 241.0\n",
      "val Loss: 0.1196 Acc: 0.9601 Pre: 0.9743 Rec: 0.9649 F1: 0.9696\n",
      "TP: 3000.0 TN: 1522.0 FP: 79.0 FN: 109.0\n",
      "test Loss: 0.9197 Acc: 0.5818 Pre: 0.7263 Rec: 0.5172 F1: 0.6042\n",
      "TP: 1669.0 TN: 1374.0 FP: 629.0 FN: 1558.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2932 Acc: 0.8807 Pre: 0.8896 Rec: 0.9353 F1: 0.9119\n",
      "TP: 2908.0 TN: 1240.0 FP: 361.0 FN: 201.0\n",
      "val Loss: 0.1158 Acc: 0.9592 Pre: 0.9743 Rec: 0.9637 F1: 0.9690\n",
      "TP: 2996.0 TN: 1522.0 FP: 79.0 FN: 113.0\n",
      "test Loss: 0.9327 Acc: 0.5895 Pre: 0.7312 Rec: 0.5293 F1: 0.6141\n",
      "TP: 1708.0 TN: 1375.0 FP: 628.0 FN: 1519.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2887 Acc: 0.8841 Pre: 0.9039 Rec: 0.9225 F1: 0.9131\n",
      "TP: 2868.0 TN: 1296.0 FP: 305.0 FN: 241.0\n",
      "val Loss: 0.1172 Acc: 0.9582 Pre: 0.9740 Rec: 0.9624 F1: 0.9681\n",
      "TP: 2992.0 TN: 1521.0 FP: 80.0 FN: 117.0\n",
      "test Loss: 0.9361 Acc: 0.5912 Pre: 0.7469 Rec: 0.5104 F1: 0.6064\n",
      "TP: 1647.0 TN: 1445.0 FP: 558.0 FN: 1580.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2959 Acc: 0.8837 Pre: 0.8995 Rec: 0.9273 F1: 0.9132\n",
      "TP: 2883.0 TN: 1279.0 FP: 322.0 FN: 226.0\n",
      "val Loss: 0.1373 Acc: 0.9527 Pre: 0.9424 Rec: 0.9887 F1: 0.9650\n",
      "TP: 3074.0 TN: 1413.0 FP: 188.0 FN: 35.0\n",
      "test Loss: 0.9428 Acc: 0.6229 Pre: 0.6777 Rec: 0.7416 F1: 0.7082\n",
      "TP: 2393.0 TN: 865.0 FP: 1138.0 FN: 834.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2886 Acc: 0.8847 Pre: 0.8982 Rec: 0.9308 F1: 0.9142\n",
      "TP: 2894.0 TN: 1273.0 FP: 328.0 FN: 215.0\n",
      "val Loss: 0.1109 Acc: 0.9624 Pre: 0.9726 Rec: 0.9704 F1: 0.9715\n",
      "TP: 3017.0 TN: 1516.0 FP: 85.0 FN: 92.0\n",
      "test Loss: 0.9598 Acc: 0.5958 Pre: 0.7200 Rec: 0.5643 F1: 0.6327\n",
      "TP: 1821.0 TN: 1295.0 FP: 708.0 FN: 1406.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2979 Acc: 0.8775 Pre: 0.8984 Rec: 0.9183 F1: 0.9082\n",
      "TP: 2855.0 TN: 1278.0 FP: 323.0 FN: 254.0\n",
      "val Loss: 0.1161 Acc: 0.9603 Pre: 0.9600 Rec: 0.9807 F1: 0.9702\n",
      "TP: 3049.0 TN: 1474.0 FP: 127.0 FN: 60.0\n",
      "test Loss: 0.8857 Acc: 0.6159 Pre: 0.7056 Rec: 0.6477 F1: 0.6754\n",
      "TP: 2090.0 TN: 1131.0 FP: 872.0 FN: 1137.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2882 Acc: 0.8883 Pre: 0.9047 Rec: 0.9286 F1: 0.9165\n",
      "TP: 2887.0 TN: 1297.0 FP: 304.0 FN: 222.0\n",
      "val Loss: 0.1155 Acc: 0.9588 Pre: 0.9715 Rec: 0.9659 F1: 0.9687\n",
      "TP: 3003.0 TN: 1513.0 FP: 88.0 FN: 106.0\n",
      "test Loss: 0.9364 Acc: 0.5897 Pre: 0.7276 Rec: 0.5355 F1: 0.6169\n",
      "TP: 1728.0 TN: 1356.0 FP: 647.0 FN: 1499.0\n",
      "\n",
      "Training complete in 91m 43s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6247 Acc: 0.6815 Pre: 0.7323 Rec: 0.8157 F1: 0.7718\n",
      "TP: 2536.0 TN: 674.0 FP: 927.0 FN: 573.0\n",
      "val Loss: 0.5190 Acc: 0.7318 Pre: 0.8320 Rec: 0.7440 F1: 0.7855\n",
      "TP: 2313.0 TN: 1134.0 FP: 467.0 FN: 796.0\n",
      "test Loss: 0.7055 Acc: 0.6434 Pre: 0.7077 Rec: 0.7189 F1: 0.7133\n",
      "TP: 2320.0 TN: 1045.0 FP: 958.0 FN: 907.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5812 Acc: 0.7115 Pre: 0.7614 Rec: 0.8199 F1: 0.7895\n",
      "TP: 2549.0 TN: 802.0 FP: 799.0 FN: 560.0\n",
      "val Loss: 0.3399 Acc: 0.8662 Pre: 0.9007 Rec: 0.8961 F1: 0.8984\n",
      "TP: 2786.0 TN: 1294.0 FP: 307.0 FN: 323.0\n",
      "test Loss: 0.7137 Acc: 0.6365 Pre: 0.7241 Rec: 0.6638 F1: 0.6926\n",
      "TP: 2142.0 TN: 1187.0 FP: 816.0 FN: 1085.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5066 Acc: 0.7705 Pre: 0.8091 Rec: 0.8537 F1: 0.8308\n",
      "TP: 2654.0 TN: 975.0 FP: 626.0 FN: 455.0\n",
      "val Loss: 0.3389 Acc: 0.8828 Pre: 0.8861 Rec: 0.9437 F1: 0.9140\n",
      "TP: 2934.0 TN: 1224.0 FP: 377.0 FN: 175.0\n",
      "test Loss: 0.9618 Acc: 0.6857 Pre: 0.7038 Rec: 0.8469 F1: 0.7688\n",
      "TP: 2733.0 TN: 853.0 FP: 1150.0 FN: 494.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5075 Acc: 0.7677 Pre: 0.8088 Rec: 0.8488 F1: 0.8283\n",
      "TP: 2639.0 TN: 977.0 FP: 624.0 FN: 470.0\n",
      "val Loss: 0.2683 Acc: 0.9036 Pre: 0.9205 Rec: 0.9347 F1: 0.9275\n",
      "TP: 2906.0 TN: 1350.0 FP: 251.0 FN: 203.0\n",
      "test Loss: 0.7892 Acc: 0.6558 Pre: 0.7340 Rec: 0.6935 F1: 0.7132\n",
      "TP: 2238.0 TN: 1192.0 FP: 811.0 FN: 989.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4531 Acc: 0.7970 Pre: 0.8346 Rec: 0.8636 F1: 0.8489\n",
      "TP: 2685.0 TN: 1069.0 FP: 532.0 FN: 424.0\n",
      "val Loss: 0.2398 Acc: 0.9140 Pre: 0.9228 Rec: 0.9492 F1: 0.9358\n",
      "TP: 2951.0 TN: 1354.0 FP: 247.0 FN: 158.0\n",
      "test Loss: 0.7528 Acc: 0.6426 Pre: 0.7020 Rec: 0.7313 F1: 0.7163\n",
      "TP: 2360.0 TN: 1001.0 FP: 1002.0 FN: 867.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4364 Acc: 0.8002 Pre: 0.8346 Rec: 0.8697 F1: 0.8518\n",
      "TP: 2704.0 TN: 1065.0 FP: 536.0 FN: 405.0\n",
      "val Loss: 0.2270 Acc: 0.9210 Pre: 0.9273 Rec: 0.9553 F1: 0.9411\n",
      "TP: 2970.0 TN: 1368.0 FP: 233.0 FN: 139.0\n",
      "test Loss: 0.7486 Acc: 0.6751 Pre: 0.7089 Rec: 0.8035 F1: 0.7532\n",
      "TP: 2593.0 TN: 938.0 FP: 1065.0 FN: 634.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3606 Acc: 0.8527 Pre: 0.8667 Rec: 0.9180 F1: 0.8916\n",
      "TP: 2854.0 TN: 1162.0 FP: 439.0 FN: 255.0\n",
      "val Loss: 0.1936 Acc: 0.9316 Pre: 0.9604 Rec: 0.9350 F1: 0.9475\n",
      "TP: 2907.0 TN: 1481.0 FP: 120.0 FN: 202.0\n",
      "test Loss: 0.8205 Acc: 0.6151 Pre: 0.7246 Rec: 0.6068 F1: 0.6605\n",
      "TP: 1958.0 TN: 1259.0 FP: 744.0 FN: 1269.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3419 Acc: 0.8510 Pre: 0.8757 Rec: 0.9022 F1: 0.8888\n",
      "TP: 2805.0 TN: 1203.0 FP: 398.0 FN: 304.0\n",
      "val Loss: 0.1705 Acc: 0.9412 Pre: 0.9621 Rec: 0.9482 F1: 0.9551\n",
      "TP: 2948.0 TN: 1485.0 FP: 116.0 FN: 161.0\n",
      "test Loss: 0.7987 Acc: 0.6254 Pre: 0.7440 Rec: 0.5990 F1: 0.6637\n",
      "TP: 1933.0 TN: 1338.0 FP: 665.0 FN: 1294.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3313 Acc: 0.8658 Pre: 0.8850 Rec: 0.9157 F1: 0.9001\n",
      "TP: 2847.0 TN: 1231.0 FP: 370.0 FN: 262.0\n",
      "val Loss: 0.1560 Acc: 0.9414 Pre: 0.9601 Rec: 0.9508 F1: 0.9554\n",
      "TP: 2956.0 TN: 1478.0 FP: 123.0 FN: 153.0\n",
      "test Loss: 0.8140 Acc: 0.6379 Pre: 0.7416 Rec: 0.6340 F1: 0.6836\n",
      "TP: 2046.0 TN: 1290.0 FP: 713.0 FN: 1181.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3196 Acc: 0.8713 Pre: 0.8924 Rec: 0.9154 F1: 0.9038\n",
      "TP: 2846.0 TN: 1258.0 FP: 343.0 FN: 263.0\n",
      "val Loss: 0.1542 Acc: 0.9522 Pre: 0.9572 Rec: 0.9711 F1: 0.9641\n",
      "TP: 3019.0 TN: 1466.0 FP: 135.0 FN: 90.0\n",
      "test Loss: 0.8460 Acc: 0.6396 Pre: 0.7226 Rec: 0.6749 F1: 0.6980\n",
      "TP: 2178.0 TN: 1167.0 FP: 836.0 FN: 1049.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3137 Acc: 0.8732 Pre: 0.8879 Rec: 0.9247 F1: 0.9059\n",
      "TP: 2875.0 TN: 1238.0 FP: 363.0 FN: 234.0\n",
      "val Loss: 0.1460 Acc: 0.9527 Pre: 0.9575 Rec: 0.9714 F1: 0.9644\n",
      "TP: 3020.0 TN: 1467.0 FP: 134.0 FN: 89.0\n",
      "test Loss: 0.8382 Acc: 0.6564 Pre: 0.7204 Rec: 0.7242 F1: 0.7223\n",
      "TP: 2337.0 TN: 1096.0 FP: 907.0 FN: 890.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3093 Acc: 0.8769 Pre: 0.8950 Rec: 0.9215 F1: 0.9081\n",
      "TP: 2865.0 TN: 1265.0 FP: 336.0 FN: 244.0\n",
      "val Loss: 0.1317 Acc: 0.9563 Pre: 0.9636 Rec: 0.9704 F1: 0.9670\n",
      "TP: 3017.0 TN: 1487.0 FP: 114.0 FN: 92.0\n",
      "test Loss: 0.8556 Acc: 0.6199 Pre: 0.7158 Rec: 0.6368 F1: 0.6740\n",
      "TP: 2055.0 TN: 1187.0 FP: 816.0 FN: 1172.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3118 Acc: 0.8709 Pre: 0.8892 Rec: 0.9189 F1: 0.9038\n",
      "TP: 2857.0 TN: 1245.0 FP: 356.0 FN: 252.0\n",
      "val Loss: 0.1332 Acc: 0.9548 Pre: 0.9594 Rec: 0.9727 F1: 0.9660\n",
      "TP: 3024.0 TN: 1473.0 FP: 128.0 FN: 85.0\n",
      "test Loss: 0.8219 Acc: 0.6545 Pre: 0.7210 Rec: 0.7177 F1: 0.7194\n",
      "TP: 2316.0 TN: 1107.0 FP: 896.0 FN: 911.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2852 Acc: 0.8877 Pre: 0.9057 Rec: 0.9263 F1: 0.9159\n",
      "TP: 2880.0 TN: 1301.0 FP: 300.0 FN: 229.0\n",
      "val Loss: 0.1267 Acc: 0.9563 Pre: 0.9657 Rec: 0.9682 F1: 0.9669\n",
      "TP: 3010.0 TN: 1494.0 FP: 107.0 FN: 99.0\n",
      "test Loss: 0.8316 Acc: 0.6298 Pre: 0.7328 Rec: 0.6297 F1: 0.6773\n",
      "TP: 2032.0 TN: 1262.0 FP: 741.0 FN: 1195.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2811 Acc: 0.8883 Pre: 0.9022 Rec: 0.9318 F1: 0.9168\n",
      "TP: 2897.0 TN: 1287.0 FP: 314.0 FN: 212.0\n",
      "val Loss: 0.1286 Acc: 0.9561 Pre: 0.9678 Rec: 0.9656 F1: 0.9667\n",
      "TP: 3002.0 TN: 1501.0 FP: 100.0 FN: 107.0\n",
      "test Loss: 0.8296 Acc: 0.6296 Pre: 0.7357 Rec: 0.6238 F1: 0.6752\n",
      "TP: 2013.0 TN: 1280.0 FP: 723.0 FN: 1214.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2957 Acc: 0.8847 Pre: 0.8987 Rec: 0.9302 F1: 0.9142\n",
      "TP: 2892.0 TN: 1275.0 FP: 326.0 FN: 217.0\n",
      "val Loss: 0.1283 Acc: 0.9569 Pre: 0.9705 Rec: 0.9640 F1: 0.9672\n",
      "TP: 2997.0 TN: 1510.0 FP: 91.0 FN: 112.0\n",
      "test Loss: 0.8420 Acc: 0.6233 Pre: 0.7422 Rec: 0.5968 F1: 0.6616\n",
      "TP: 1926.0 TN: 1334.0 FP: 669.0 FN: 1301.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2854 Acc: 0.8902 Pre: 0.9086 Rec: 0.9270 F1: 0.9177\n",
      "TP: 2882.0 TN: 1311.0 FP: 290.0 FN: 227.0\n",
      "val Loss: 0.1261 Acc: 0.9565 Pre: 0.9657 Rec: 0.9685 F1: 0.9671\n",
      "TP: 3011.0 TN: 1494.0 FP: 107.0 FN: 98.0\n",
      "test Loss: 0.8530 Acc: 0.6419 Pre: 0.7330 Rec: 0.6601 F1: 0.6946\n",
      "TP: 2130.0 TN: 1227.0 FP: 776.0 FN: 1097.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2878 Acc: 0.8892 Pre: 0.9013 Rec: 0.9344 F1: 0.9176\n",
      "TP: 2905.0 TN: 1283.0 FP: 318.0 FN: 204.0\n",
      "val Loss: 0.1362 Acc: 0.9516 Pre: 0.9737 Rec: 0.9524 F1: 0.9629\n",
      "TP: 2961.0 TN: 1521.0 FP: 80.0 FN: 148.0\n",
      "test Loss: 0.9238 Acc: 0.6044 Pre: 0.7425 Rec: 0.5494 F1: 0.6315\n",
      "TP: 1773.0 TN: 1388.0 FP: 615.0 FN: 1454.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2752 Acc: 0.8877 Pre: 0.9021 Rec: 0.9308 F1: 0.9163\n",
      "TP: 2894.0 TN: 1287.0 FP: 314.0 FN: 215.0\n",
      "val Loss: 0.1343 Acc: 0.9546 Pre: 0.9741 Rec: 0.9566 F1: 0.9653\n",
      "TP: 2974.0 TN: 1522.0 FP: 79.0 FN: 135.0\n",
      "test Loss: 0.8634 Acc: 0.6086 Pre: 0.7434 Rec: 0.5584 F1: 0.6378\n",
      "TP: 1802.0 TN: 1381.0 FP: 622.0 FN: 1425.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2875 Acc: 0.8843 Pre: 0.8969 Rec: 0.9318 F1: 0.9140\n",
      "TP: 2897.0 TN: 1268.0 FP: 333.0 FN: 212.0\n",
      "val Loss: 0.1249 Acc: 0.9588 Pre: 0.9640 Rec: 0.9739 F1: 0.9690\n",
      "TP: 3028.0 TN: 1488.0 FP: 113.0 FN: 81.0\n",
      "test Loss: 0.8438 Acc: 0.6354 Pre: 0.7270 Rec: 0.6551 F1: 0.6892\n",
      "TP: 2114.0 TN: 1209.0 FP: 794.0 FN: 1113.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2889 Acc: 0.8858 Pre: 0.9016 Rec: 0.9283 F1: 0.9147\n",
      "TP: 2886.0 TN: 1286.0 FP: 315.0 FN: 223.0\n",
      "val Loss: 0.1232 Acc: 0.9567 Pre: 0.9708 Rec: 0.9633 F1: 0.9671\n",
      "TP: 2995.0 TN: 1511.0 FP: 90.0 FN: 114.0\n",
      "test Loss: 0.8722 Acc: 0.6207 Pre: 0.7368 Rec: 0.5993 F1: 0.6610\n",
      "TP: 1934.0 TN: 1312.0 FP: 691.0 FN: 1293.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2856 Acc: 0.8866 Pre: 0.9005 Rec: 0.9312 F1: 0.9156\n",
      "TP: 2895.0 TN: 1281.0 FP: 320.0 FN: 214.0\n",
      "val Loss: 0.1265 Acc: 0.9539 Pre: 0.9662 Rec: 0.9640 F1: 0.9651\n",
      "TP: 2997.0 TN: 1496.0 FP: 105.0 FN: 112.0\n",
      "test Loss: 0.8305 Acc: 0.6342 Pre: 0.7343 Rec: 0.6381 F1: 0.6828\n",
      "TP: 2059.0 TN: 1258.0 FP: 745.0 FN: 1168.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2887 Acc: 0.8834 Pre: 0.9000 Rec: 0.9263 F1: 0.9130\n",
      "TP: 2880.0 TN: 1281.0 FP: 320.0 FN: 229.0\n",
      "val Loss: 0.1402 Acc: 0.9552 Pre: 0.9770 Rec: 0.9546 F1: 0.9657\n",
      "TP: 2968.0 TN: 1531.0 FP: 70.0 FN: 141.0\n",
      "test Loss: 0.9149 Acc: 0.5943 Pre: 0.7454 Rec: 0.5200 F1: 0.6126\n",
      "TP: 1678.0 TN: 1430.0 FP: 573.0 FN: 1549.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2900 Acc: 0.8849 Pre: 0.8963 Rec: 0.9337 F1: 0.9146\n",
      "TP: 2903.0 TN: 1265.0 FP: 336.0 FN: 206.0\n",
      "val Loss: 0.1314 Acc: 0.9565 Pre: 0.9730 Rec: 0.9608 F1: 0.9668\n",
      "TP: 2987.0 TN: 1518.0 FP: 83.0 FN: 122.0\n",
      "test Loss: 0.8505 Acc: 0.6052 Pre: 0.7360 Rec: 0.5615 F1: 0.6370\n",
      "TP: 1812.0 TN: 1353.0 FP: 650.0 FN: 1415.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2980 Acc: 0.8786 Pre: 0.8909 Rec: 0.9299 F1: 0.9100\n",
      "TP: 2891.0 TN: 1247.0 FP: 354.0 FN: 218.0\n",
      "val Loss: 0.1237 Acc: 0.9561 Pre: 0.9624 Rec: 0.9714 F1: 0.9669\n",
      "TP: 3020.0 TN: 1483.0 FP: 118.0 FN: 89.0\n",
      "test Loss: 0.7886 Acc: 0.6400 Pre: 0.7264 Rec: 0.6681 F1: 0.6960\n",
      "TP: 2156.0 TN: 1191.0 FP: 812.0 FN: 1071.0\n",
      "\n",
      "Training complete in 92m 53s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6042 Acc: 0.6962 Pre: 0.7430 Rec: 0.8250 F1: 0.7819\n",
      "TP: 2565.0 TN: 714.0 FP: 887.0 FN: 544.0\n",
      "val Loss: 0.4516 Acc: 0.8074 Pre: 0.8753 Rec: 0.8260 F1: 0.8499\n",
      "TP: 2568.0 TN: 1235.0 FP: 366.0 FN: 541.0\n",
      "test Loss: 0.6467 Acc: 0.6652 Pre: 0.7628 Rec: 0.6638 F1: 0.7099\n",
      "TP: 2142.0 TN: 1337.0 FP: 666.0 FN: 1085.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5747 Acc: 0.7223 Pre: 0.7736 Rec: 0.8189 F1: 0.7956\n",
      "TP: 2546.0 TN: 856.0 FP: 745.0 FN: 563.0\n",
      "val Loss: 0.4821 Acc: 0.8053 Pre: 0.7871 Rec: 0.9665 F1: 0.8676\n",
      "TP: 3005.0 TN: 788.0 FP: 813.0 FN: 104.0\n",
      "test Loss: 0.9141 Acc: 0.6633 Pre: 0.6632 Rec: 0.9231 F1: 0.7719\n",
      "TP: 2979.0 TN: 490.0 FP: 1513.0 FN: 248.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5322 Acc: 0.7531 Pre: 0.7977 Rec: 0.8385 F1: 0.8176\n",
      "TP: 2607.0 TN: 940.0 FP: 661.0 FN: 502.0\n",
      "val Loss: 0.3011 Acc: 0.8866 Pre: 0.9131 Rec: 0.9154 F1: 0.9142\n",
      "TP: 2846.0 TN: 1330.0 FP: 271.0 FN: 263.0\n",
      "test Loss: 0.8247 Acc: 0.6860 Pre: 0.7052 Rec: 0.8441 F1: 0.7684\n",
      "TP: 2724.0 TN: 864.0 FP: 1139.0 FN: 503.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4847 Acc: 0.7811 Pre: 0.8241 Rec: 0.8498 F1: 0.8367\n",
      "TP: 2642.0 TN: 1037.0 FP: 564.0 FN: 467.0\n",
      "val Loss: 0.2880 Acc: 0.8887 Pre: 0.9228 Rec: 0.9074 F1: 0.9150\n",
      "TP: 2821.0 TN: 1365.0 FP: 236.0 FN: 288.0\n",
      "test Loss: 0.8067 Acc: 0.5889 Pre: 0.7124 Rec: 0.5597 F1: 0.6269\n",
      "TP: 1806.0 TN: 1274.0 FP: 729.0 FN: 1421.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4797 Acc: 0.7839 Pre: 0.8214 Rec: 0.8594 F1: 0.8400\n",
      "TP: 2672.0 TN: 1020.0 FP: 581.0 FN: 437.0\n",
      "val Loss: 0.5266 Acc: 0.7843 Pre: 0.9560 Rec: 0.7057 F1: 0.8120\n",
      "TP: 2194.0 TN: 1500.0 FP: 101.0 FN: 915.0\n",
      "test Loss: 1.3698 Acc: 0.4686 Pre: 0.7419 Rec: 0.2129 F1: 0.3308\n",
      "TP: 687.0 TN: 1764.0 FP: 239.0 FN: 2540.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4556 Acc: 0.7977 Pre: 0.8329 Rec: 0.8675 F1: 0.8499\n",
      "TP: 2697.0 TN: 1060.0 FP: 541.0 FN: 412.0\n",
      "val Loss: 0.2248 Acc: 0.9210 Pre: 0.9299 Rec: 0.9521 F1: 0.9409\n",
      "TP: 2960.0 TN: 1378.0 FP: 223.0 FN: 149.0\n",
      "test Loss: 0.7679 Acc: 0.6623 Pre: 0.6957 Rec: 0.8048 F1: 0.7463\n",
      "TP: 2597.0 TN: 867.0 FP: 1136.0 FN: 630.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3726 Acc: 0.8378 Pre: 0.8609 Rec: 0.8996 F1: 0.8798\n",
      "TP: 2797.0 TN: 1149.0 FP: 452.0 FN: 312.0\n",
      "val Loss: 0.1819 Acc: 0.9327 Pre: 0.9486 Rec: 0.9495 F1: 0.9490\n",
      "TP: 2952.0 TN: 1441.0 FP: 160.0 FN: 157.0\n",
      "test Loss: 0.7835 Acc: 0.6270 Pre: 0.7191 Rec: 0.6489 F1: 0.6822\n",
      "TP: 2094.0 TN: 1185.0 FP: 818.0 FN: 1133.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3485 Acc: 0.8499 Pre: 0.8714 Rec: 0.9064 F1: 0.8885\n",
      "TP: 2818.0 TN: 1185.0 FP: 416.0 FN: 291.0\n",
      "val Loss: 0.1637 Acc: 0.9363 Pre: 0.9379 Rec: 0.9675 F1: 0.9525\n",
      "TP: 3008.0 TN: 1402.0 FP: 199.0 FN: 101.0\n",
      "test Loss: 0.7901 Acc: 0.6549 Pre: 0.7157 Rec: 0.7310 F1: 0.7233\n",
      "TP: 2359.0 TN: 1066.0 FP: 937.0 FN: 868.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3378 Acc: 0.8588 Pre: 0.8836 Rec: 0.9054 F1: 0.8944\n",
      "TP: 2815.0 TN: 1230.0 FP: 371.0 FN: 294.0\n",
      "val Loss: 0.1616 Acc: 0.9427 Pre: 0.9601 Rec: 0.9527 F1: 0.9564\n",
      "TP: 2962.0 TN: 1478.0 FP: 123.0 FN: 147.0\n",
      "test Loss: 0.8179 Acc: 0.6044 Pre: 0.7099 Rec: 0.6068 F1: 0.6543\n",
      "TP: 1958.0 TN: 1203.0 FP: 800.0 FN: 1269.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3238 Acc: 0.8586 Pre: 0.8785 Rec: 0.9119 F1: 0.8949\n",
      "TP: 2835.0 TN: 1209.0 FP: 392.0 FN: 274.0\n",
      "val Loss: 0.1462 Acc: 0.9488 Pre: 0.9434 Rec: 0.9813 F1: 0.9620\n",
      "TP: 3051.0 TN: 1418.0 FP: 183.0 FN: 58.0\n",
      "test Loss: 0.8614 Acc: 0.6610 Pre: 0.6995 Rec: 0.7899 F1: 0.7420\n",
      "TP: 2549.0 TN: 908.0 FP: 1095.0 FN: 678.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3067 Acc: 0.8705 Pre: 0.8938 Rec: 0.9122 F1: 0.9029\n",
      "TP: 2836.0 TN: 1264.0 FP: 337.0 FN: 273.0\n",
      "val Loss: 0.1559 Acc: 0.9403 Pre: 0.9685 Rec: 0.9402 F1: 0.9541\n",
      "TP: 2923.0 TN: 1506.0 FP: 95.0 FN: 186.0\n",
      "test Loss: 0.8753 Acc: 0.6033 Pre: 0.7219 Rec: 0.5807 F1: 0.6437\n",
      "TP: 1874.0 TN: 1281.0 FP: 722.0 FN: 1353.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3144 Acc: 0.8737 Pre: 0.8911 Rec: 0.9212 F1: 0.9059\n",
      "TP: 2864.0 TN: 1251.0 FP: 350.0 FN: 245.0\n",
      "val Loss: 0.2397 Acc: 0.9221 Pre: 0.9567 Rec: 0.9238 F1: 0.9399\n",
      "TP: 2872.0 TN: 1471.0 FP: 130.0 FN: 237.0\n",
      "test Loss: 0.8307 Acc: 0.6342 Pre: 0.7100 Rec: 0.6883 F1: 0.6990\n",
      "TP: 2221.0 TN: 1096.0 FP: 907.0 FN: 1006.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.2932 Acc: 0.8783 Pre: 0.8975 Rec: 0.9209 F1: 0.9090\n",
      "TP: 2863.0 TN: 1274.0 FP: 327.0 FN: 246.0\n",
      "val Loss: 0.1363 Acc: 0.9476 Pre: 0.9689 Rec: 0.9511 F1: 0.9599\n",
      "TP: 2957.0 TN: 1506.0 FP: 95.0 FN: 152.0\n",
      "test Loss: 0.8771 Acc: 0.5948 Pre: 0.7236 Rec: 0.5556 F1: 0.6286\n",
      "TP: 1793.0 TN: 1318.0 FP: 685.0 FN: 1434.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2954 Acc: 0.8790 Pre: 0.8949 Rec: 0.9254 F1: 0.9099\n",
      "TP: 2877.0 TN: 1263.0 FP: 338.0 FN: 232.0\n",
      "val Loss: 0.1268 Acc: 0.9546 Pre: 0.9638 Rec: 0.9675 F1: 0.9657\n",
      "TP: 3008.0 TN: 1488.0 FP: 113.0 FN: 101.0\n",
      "test Loss: 0.8016 Acc: 0.6082 Pre: 0.7278 Rec: 0.5832 F1: 0.6475\n",
      "TP: 1882.0 TN: 1299.0 FP: 704.0 FN: 1345.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3032 Acc: 0.8798 Pre: 0.8938 Rec: 0.9283 F1: 0.9107\n",
      "TP: 2886.0 TN: 1258.0 FP: 343.0 FN: 223.0\n",
      "val Loss: 0.2093 Acc: 0.9270 Pre: 0.9743 Rec: 0.9135 F1: 0.9429\n",
      "TP: 2840.0 TN: 1526.0 FP: 75.0 FN: 269.0\n",
      "test Loss: 0.9331 Acc: 0.5711 Pre: 0.7249 Rec: 0.4915 F1: 0.5858\n",
      "TP: 1586.0 TN: 1401.0 FP: 602.0 FN: 1641.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2899 Acc: 0.8826 Pre: 0.8996 Rec: 0.9254 F1: 0.9123\n",
      "TP: 2877.0 TN: 1280.0 FP: 321.0 FN: 232.0\n",
      "val Loss: 0.1712 Acc: 0.9327 Pre: 0.9778 Rec: 0.9189 F1: 0.9474\n",
      "TP: 2857.0 TN: 1536.0 FP: 65.0 FN: 252.0\n",
      "test Loss: 0.9261 Acc: 0.5732 Pre: 0.7377 Rec: 0.4785 F1: 0.5805\n",
      "TP: 1544.0 TN: 1454.0 FP: 549.0 FN: 1683.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3008 Acc: 0.8792 Pre: 0.8949 Rec: 0.9257 F1: 0.9100\n",
      "TP: 2878.0 TN: 1263.0 FP: 338.0 FN: 231.0\n",
      "val Loss: 0.2968 Acc: 0.9163 Pre: 0.9600 Rec: 0.9112 F1: 0.9350\n",
      "TP: 2833.0 TN: 1483.0 FP: 118.0 FN: 276.0\n",
      "test Loss: 0.8323 Acc: 0.6178 Pre: 0.7122 Rec: 0.6387 F1: 0.6734\n",
      "TP: 2061.0 TN: 1170.0 FP: 833.0 FN: 1166.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2889 Acc: 0.8826 Pre: 0.8976 Rec: 0.9280 F1: 0.9125\n",
      "TP: 2885.0 TN: 1272.0 FP: 329.0 FN: 224.0\n",
      "val Loss: 0.2520 Acc: 0.9255 Pre: 0.9600 Rec: 0.9257 F1: 0.9425\n",
      "TP: 2878.0 TN: 1481.0 FP: 120.0 FN: 231.0\n",
      "test Loss: 0.8100 Acc: 0.6325 Pre: 0.7035 Rec: 0.6991 F1: 0.7013\n",
      "TP: 2256.0 TN: 1052.0 FP: 951.0 FN: 971.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2814 Acc: 0.8813 Pre: 0.9009 Rec: 0.9215 F1: 0.9111\n",
      "TP: 2865.0 TN: 1286.0 FP: 315.0 FN: 244.0\n",
      "val Loss: 0.1423 Acc: 0.9461 Pre: 0.9710 Rec: 0.9466 F1: 0.9586\n",
      "TP: 2943.0 TN: 1513.0 FP: 88.0 FN: 166.0\n",
      "test Loss: 0.8473 Acc: 0.6052 Pre: 0.7259 Rec: 0.5786 F1: 0.6439\n",
      "TP: 1867.0 TN: 1298.0 FP: 705.0 FN: 1360.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2906 Acc: 0.8830 Pre: 0.8957 Rec: 0.9312 F1: 0.9131\n",
      "TP: 2895.0 TN: 1264.0 FP: 337.0 FN: 214.0\n",
      "val Loss: 0.1624 Acc: 0.9399 Pre: 0.9729 Rec: 0.9350 F1: 0.9536\n",
      "TP: 2907.0 TN: 1520.0 FP: 81.0 FN: 202.0\n",
      "test Loss: 0.8447 Acc: 0.6153 Pre: 0.7218 Rec: 0.6126 F1: 0.6628\n",
      "TP: 1977.0 TN: 1241.0 FP: 762.0 FN: 1250.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2936 Acc: 0.8822 Pre: 0.8993 Rec: 0.9251 F1: 0.9120\n",
      "TP: 2876.0 TN: 1279.0 FP: 322.0 FN: 233.0\n",
      "val Loss: 0.2189 Acc: 0.9263 Pre: 0.9726 Rec: 0.9141 F1: 0.9425\n",
      "TP: 2842.0 TN: 1521.0 FP: 80.0 FN: 267.0\n",
      "test Loss: 0.8829 Acc: 0.5925 Pre: 0.7147 Rec: 0.5652 F1: 0.6313\n",
      "TP: 1824.0 TN: 1275.0 FP: 728.0 FN: 1403.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2894 Acc: 0.8832 Pre: 0.9005 Rec: 0.9254 F1: 0.9128\n",
      "TP: 2877.0 TN: 1283.0 FP: 318.0 FN: 232.0\n",
      "val Loss: 0.1495 Acc: 0.9418 Pre: 0.9742 Rec: 0.9366 F1: 0.9551\n",
      "TP: 2912.0 TN: 1524.0 FP: 77.0 FN: 197.0\n",
      "test Loss: 0.8610 Acc: 0.6000 Pre: 0.7232 Rec: 0.5699 F1: 0.6374\n",
      "TP: 1839.0 TN: 1299.0 FP: 704.0 FN: 1388.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2879 Acc: 0.8851 Pre: 0.8983 Rec: 0.9315 F1: 0.9146\n",
      "TP: 2896.0 TN: 1273.0 FP: 328.0 FN: 213.0\n",
      "val Loss: 0.1435 Acc: 0.9463 Pre: 0.9789 Rec: 0.9389 F1: 0.9585\n",
      "TP: 2919.0 TN: 1538.0 FP: 63.0 FN: 190.0\n",
      "test Loss: 0.9617 Acc: 0.5665 Pre: 0.7353 Rec: 0.4648 F1: 0.5696\n",
      "TP: 1500.0 TN: 1463.0 FP: 540.0 FN: 1727.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2806 Acc: 0.8856 Pre: 0.8971 Rec: 0.9337 F1: 0.9151\n",
      "TP: 2903.0 TN: 1268.0 FP: 333.0 FN: 206.0\n",
      "val Loss: 0.3397 Acc: 0.9161 Pre: 0.9572 Rec: 0.9138 F1: 0.9350\n",
      "TP: 2841.0 TN: 1474.0 FP: 127.0 FN: 268.0\n",
      "test Loss: 0.8461 Acc: 0.6424 Pre: 0.7168 Rec: 0.6951 F1: 0.7058\n",
      "TP: 2243.0 TN: 1117.0 FP: 886.0 FN: 984.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2769 Acc: 0.8896 Pre: 0.9036 Rec: 0.9321 F1: 0.9177\n",
      "TP: 2898.0 TN: 1292.0 FP: 309.0 FN: 211.0\n",
      "val Loss: 0.1345 Acc: 0.9471 Pre: 0.9726 Rec: 0.9466 F1: 0.9594\n",
      "TP: 2943.0 TN: 1518.0 FP: 83.0 FN: 166.0\n",
      "test Loss: 0.8763 Acc: 0.5966 Pre: 0.7242 Rec: 0.5590 F1: 0.6310\n",
      "TP: 1804.0 TN: 1316.0 FP: 687.0 FN: 1423.0\n",
      "\n",
      "Training complete in 92m 40s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6284 Acc: 0.6760 Pre: 0.7294 Rec: 0.8096 F1: 0.7674\n",
      "TP: 2517.0 TN: 667.0 FP: 934.0 FN: 592.0\n",
      "val Loss: 0.5069 Acc: 0.7338 Pre: 0.9260 Rec: 0.6484 F1: 0.7628\n",
      "TP: 2016.0 TN: 1440.0 FP: 161.0 FN: 1093.0\n",
      "test Loss: 0.6668 Acc: 0.6193 Pre: 0.7614 Rec: 0.5578 F1: 0.6439\n",
      "TP: 1800.0 TN: 1439.0 FP: 564.0 FN: 1427.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5680 Acc: 0.7272 Pre: 0.7767 Rec: 0.8234 F1: 0.7994\n",
      "TP: 2560.0 TN: 865.0 FP: 736.0 FN: 549.0\n",
      "val Loss: 0.3973 Acc: 0.8208 Pre: 0.8362 Rec: 0.9061 F1: 0.8697\n",
      "TP: 2817.0 TN: 1049.0 FP: 552.0 FN: 292.0\n",
      "test Loss: 0.6721 Acc: 0.6889 Pre: 0.7061 Rec: 0.8494 F1: 0.7711\n",
      "TP: 2741.0 TN: 862.0 FP: 1141.0 FN: 486.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5410 Acc: 0.7376 Pre: 0.7874 Rec: 0.8253 F1: 0.8059\n",
      "TP: 2566.0 TN: 908.0 FP: 693.0 FN: 543.0\n",
      "val Loss: 0.3134 Acc: 0.8769 Pre: 0.8945 Rec: 0.9222 F1: 0.9081\n",
      "TP: 2867.0 TN: 1263.0 FP: 338.0 FN: 242.0\n",
      "test Loss: 0.7841 Acc: 0.6507 Pre: 0.6896 Rec: 0.7890 F1: 0.7359\n",
      "TP: 2546.0 TN: 857.0 FP: 1146.0 FN: 681.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4954 Acc: 0.7760 Pre: 0.8156 Rec: 0.8537 F1: 0.8342\n",
      "TP: 2654.0 TN: 1001.0 FP: 600.0 FN: 455.0\n",
      "val Loss: 0.2533 Acc: 0.9051 Pre: 0.9215 Rec: 0.9360 F1: 0.9287\n",
      "TP: 2910.0 TN: 1353.0 FP: 248.0 FN: 199.0\n",
      "test Loss: 0.7252 Acc: 0.6644 Pre: 0.7606 Rec: 0.6656 F1: 0.7100\n",
      "TP: 2148.0 TN: 1327.0 FP: 676.0 FN: 1079.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4689 Acc: 0.7904 Pre: 0.8281 Rec: 0.8614 F1: 0.8444\n",
      "TP: 2678.0 TN: 1045.0 FP: 556.0 FN: 431.0\n",
      "val Loss: 0.4127 Acc: 0.8671 Pre: 0.8473 Rec: 0.9743 F1: 0.9063\n",
      "TP: 3029.0 TN: 1055.0 FP: 546.0 FN: 80.0\n",
      "test Loss: 0.7725 Acc: 0.6707 Pre: 0.6980 Rec: 0.8221 F1: 0.7550\n",
      "TP: 2653.0 TN: 855.0 FP: 1148.0 FN: 574.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4559 Acc: 0.8059 Pre: 0.8370 Rec: 0.8768 F1: 0.8564\n",
      "TP: 2726.0 TN: 1070.0 FP: 531.0 FN: 383.0\n",
      "val Loss: 0.3182 Acc: 0.8631 Pre: 0.9611 Rec: 0.8260 F1: 0.8884\n",
      "TP: 2568.0 TN: 1497.0 FP: 104.0 FN: 541.0\n",
      "test Loss: 0.8408 Acc: 0.5763 Pre: 0.7205 Rec: 0.5119 F1: 0.5986\n",
      "TP: 1652.0 TN: 1362.0 FP: 641.0 FN: 1575.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3812 Acc: 0.8363 Pre: 0.8626 Rec: 0.8945 F1: 0.8783\n",
      "TP: 2781.0 TN: 1158.0 FP: 443.0 FN: 328.0\n",
      "val Loss: 0.2061 Acc: 0.9174 Pre: 0.9345 Rec: 0.9408 F1: 0.9377\n",
      "TP: 2925.0 TN: 1396.0 FP: 205.0 FN: 184.0\n",
      "test Loss: 0.7441 Acc: 0.6520 Pre: 0.7080 Rec: 0.7422 F1: 0.7247\n",
      "TP: 2395.0 TN: 1015.0 FP: 988.0 FN: 832.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3575 Acc: 0.8423 Pre: 0.8660 Rec: 0.9003 F1: 0.8828\n",
      "TP: 2799.0 TN: 1168.0 FP: 433.0 FN: 310.0\n",
      "val Loss: 0.2222 Acc: 0.9117 Pre: 0.9526 Rec: 0.9115 F1: 0.9316\n",
      "TP: 2834.0 TN: 1460.0 FP: 141.0 FN: 275.0\n",
      "test Loss: 0.8307 Acc: 0.6031 Pre: 0.7016 Rec: 0.6207 F1: 0.6587\n",
      "TP: 2003.0 TN: 1151.0 FP: 852.0 FN: 1224.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3383 Acc: 0.8569 Pre: 0.8789 Rec: 0.9083 F1: 0.8934\n",
      "TP: 2824.0 TN: 1212.0 FP: 389.0 FN: 285.0\n",
      "val Loss: 0.1664 Acc: 0.9403 Pre: 0.9552 Rec: 0.9543 F1: 0.9548\n",
      "TP: 2967.0 TN: 1462.0 FP: 139.0 FN: 142.0\n",
      "test Loss: 0.7604 Acc: 0.6405 Pre: 0.7139 Rec: 0.6966 F1: 0.7051\n",
      "TP: 2248.0 TN: 1102.0 FP: 901.0 FN: 979.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3335 Acc: 0.8622 Pre: 0.8803 Rec: 0.9157 F1: 0.8977\n",
      "TP: 2847.0 TN: 1214.0 FP: 387.0 FN: 262.0\n",
      "val Loss: 0.1847 Acc: 0.9289 Pre: 0.9548 Rec: 0.9366 F1: 0.9456\n",
      "TP: 2912.0 TN: 1463.0 FP: 138.0 FN: 197.0\n",
      "test Loss: 0.7717 Acc: 0.6421 Pre: 0.7122 Rec: 0.7047 F1: 0.7084\n",
      "TP: 2274.0 TN: 1084.0 FP: 919.0 FN: 953.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3273 Acc: 0.8643 Pre: 0.8805 Rec: 0.9193 F1: 0.8994\n",
      "TP: 2858.0 TN: 1213.0 FP: 388.0 FN: 251.0\n",
      "val Loss: 0.2788 Acc: 0.8979 Pre: 0.9716 Rec: 0.8707 F1: 0.9184\n",
      "TP: 2707.0 TN: 1522.0 FP: 79.0 FN: 402.0\n",
      "test Loss: 0.8452 Acc: 0.6013 Pre: 0.7217 Rec: 0.5761 F1: 0.6407\n",
      "TP: 1859.0 TN: 1286.0 FP: 717.0 FN: 1368.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3124 Acc: 0.8720 Pre: 0.8899 Rec: 0.9199 F1: 0.9046\n",
      "TP: 2860.0 TN: 1247.0 FP: 354.0 FN: 249.0\n",
      "val Loss: 0.1515 Acc: 0.9444 Pre: 0.9728 Rec: 0.9421 F1: 0.9572\n",
      "TP: 2929.0 TN: 1519.0 FP: 82.0 FN: 180.0\n",
      "test Loss: 0.9172 Acc: 0.5851 Pre: 0.7235 Rec: 0.5302 F1: 0.6119\n",
      "TP: 1711.0 TN: 1349.0 FP: 654.0 FN: 1516.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3174 Acc: 0.8692 Pre: 0.8892 Rec: 0.9161 F1: 0.9024\n",
      "TP: 2848.0 TN: 1246.0 FP: 355.0 FN: 261.0\n",
      "val Loss: 0.1328 Acc: 0.9510 Pre: 0.9574 Rec: 0.9688 F1: 0.9631\n",
      "TP: 3012.0 TN: 1467.0 FP: 134.0 FN: 97.0\n",
      "test Loss: 0.8554 Acc: 0.6359 Pre: 0.7003 Rec: 0.7168 F1: 0.7084\n",
      "TP: 2313.0 TN: 1013.0 FP: 990.0 FN: 914.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3038 Acc: 0.8792 Pre: 0.8996 Rec: 0.9196 F1: 0.9095\n",
      "TP: 2859.0 TN: 1282.0 FP: 319.0 FN: 250.0\n",
      "val Loss: 0.1337 Acc: 0.9503 Pre: 0.9678 Rec: 0.9566 F1: 0.9621\n",
      "TP: 2974.0 TN: 1502.0 FP: 99.0 FN: 135.0\n",
      "test Loss: 0.8330 Acc: 0.6180 Pre: 0.7232 Rec: 0.6170 F1: 0.6659\n",
      "TP: 1991.0 TN: 1241.0 FP: 762.0 FN: 1236.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3016 Acc: 0.8718 Pre: 0.8928 Rec: 0.9157 F1: 0.9041\n",
      "TP: 2847.0 TN: 1259.0 FP: 342.0 FN: 262.0\n",
      "val Loss: 0.1318 Acc: 0.9539 Pre: 0.9519 Rec: 0.9797 F1: 0.9656\n",
      "TP: 3046.0 TN: 1447.0 FP: 154.0 FN: 63.0\n",
      "test Loss: 0.8587 Acc: 0.6579 Pre: 0.7014 Rec: 0.7760 F1: 0.7368\n",
      "TP: 2504.0 TN: 937.0 FP: 1066.0 FN: 723.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2914 Acc: 0.8805 Pre: 0.8963 Rec: 0.9260 F1: 0.9109\n",
      "TP: 2879.0 TN: 1268.0 FP: 333.0 FN: 230.0\n",
      "val Loss: 0.1322 Acc: 0.9533 Pre: 0.9682 Rec: 0.9608 F1: 0.9645\n",
      "TP: 2987.0 TN: 1503.0 FP: 98.0 FN: 122.0\n",
      "test Loss: 0.8721 Acc: 0.6090 Pre: 0.7151 Rec: 0.6089 F1: 0.6577\n",
      "TP: 1965.0 TN: 1220.0 FP: 783.0 FN: 1262.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2979 Acc: 0.8775 Pre: 0.8941 Rec: 0.9238 F1: 0.9087\n",
      "TP: 2872.0 TN: 1261.0 FP: 340.0 FN: 237.0\n",
      "val Loss: 0.1319 Acc: 0.9537 Pre: 0.9620 Rec: 0.9682 F1: 0.9651\n",
      "TP: 3010.0 TN: 1482.0 FP: 119.0 FN: 99.0\n",
      "test Loss: 0.8070 Acc: 0.6361 Pre: 0.7080 Rec: 0.6982 F1: 0.7031\n",
      "TP: 2253.0 TN: 1074.0 FP: 929.0 FN: 974.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2916 Acc: 0.8754 Pre: 0.8941 Rec: 0.9202 F1: 0.9070\n",
      "TP: 2861.0 TN: 1262.0 FP: 339.0 FN: 248.0\n",
      "val Loss: 0.1311 Acc: 0.9537 Pre: 0.9471 Rec: 0.9849 F1: 0.9656\n",
      "TP: 3062.0 TN: 1430.0 FP: 171.0 FN: 47.0\n",
      "test Loss: 0.8636 Acc: 0.6467 Pre: 0.6897 Rec: 0.7769 F1: 0.7307\n",
      "TP: 2507.0 TN: 875.0 FP: 1128.0 FN: 720.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2876 Acc: 0.8864 Pre: 0.8997 Rec: 0.9318 F1: 0.9155\n",
      "TP: 2897.0 TN: 1278.0 FP: 323.0 FN: 212.0\n",
      "val Loss: 0.1287 Acc: 0.9524 Pre: 0.9563 Rec: 0.9723 F1: 0.9643\n",
      "TP: 3023.0 TN: 1463.0 FP: 138.0 FN: 86.0\n",
      "test Loss: 0.8699 Acc: 0.6570 Pre: 0.7012 Rec: 0.7738 F1: 0.7357\n",
      "TP: 2497.0 TN: 939.0 FP: 1064.0 FN: 730.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2994 Acc: 0.8762 Pre: 0.8932 Rec: 0.9228 F1: 0.9078\n",
      "TP: 2869.0 TN: 1258.0 FP: 343.0 FN: 240.0\n",
      "val Loss: 0.1274 Acc: 0.9546 Pre: 0.9608 Rec: 0.9707 F1: 0.9658\n",
      "TP: 3018.0 TN: 1478.0 FP: 123.0 FN: 91.0\n",
      "test Loss: 0.8296 Acc: 0.6379 Pre: 0.6999 Rec: 0.7233 F1: 0.7114\n",
      "TP: 2334.0 TN: 1002.0 FP: 1001.0 FN: 893.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2848 Acc: 0.8890 Pre: 0.9026 Rec: 0.9325 F1: 0.9173\n",
      "TP: 2899.0 TN: 1288.0 FP: 313.0 FN: 210.0\n",
      "val Loss: 0.1297 Acc: 0.9524 Pre: 0.9555 Rec: 0.9733 F1: 0.9643\n",
      "TP: 3026.0 TN: 1460.0 FP: 141.0 FN: 83.0\n",
      "test Loss: 0.8602 Acc: 0.6463 Pre: 0.6952 Rec: 0.7598 F1: 0.7261\n",
      "TP: 2452.0 TN: 928.0 FP: 1075.0 FN: 775.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2877 Acc: 0.8796 Pre: 0.8925 Rec: 0.9296 F1: 0.9107\n",
      "TP: 2890.0 TN: 1253.0 FP: 348.0 FN: 219.0\n",
      "val Loss: 0.1316 Acc: 0.9539 Pre: 0.9635 Rec: 0.9669 F1: 0.9652\n",
      "TP: 3006.0 TN: 1487.0 FP: 114.0 FN: 103.0\n",
      "test Loss: 0.8376 Acc: 0.6287 Pre: 0.6980 Rec: 0.7019 F1: 0.6999\n",
      "TP: 2265.0 TN: 1023.0 FP: 980.0 FN: 962.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2891 Acc: 0.8837 Pre: 0.8993 Rec: 0.9276 F1: 0.9132\n",
      "TP: 2884.0 TN: 1278.0 FP: 323.0 FN: 225.0\n",
      "val Loss: 0.1409 Acc: 0.9514 Pre: 0.9728 Rec: 0.9530 F1: 0.9628\n",
      "TP: 2963.0 TN: 1518.0 FP: 83.0 FN: 146.0\n",
      "test Loss: 0.8444 Acc: 0.6163 Pre: 0.7220 Rec: 0.6148 F1: 0.6641\n",
      "TP: 1984.0 TN: 1239.0 FP: 764.0 FN: 1243.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2818 Acc: 0.8902 Pre: 0.9045 Rec: 0.9321 F1: 0.9181\n",
      "TP: 2898.0 TN: 1295.0 FP: 306.0 FN: 211.0\n",
      "val Loss: 0.1353 Acc: 0.9531 Pre: 0.9581 Rec: 0.9714 F1: 0.9647\n",
      "TP: 3020.0 TN: 1469.0 FP: 132.0 FN: 89.0\n",
      "test Loss: 0.8219 Acc: 0.6484 Pre: 0.7064 Rec: 0.7360 F1: 0.7209\n",
      "TP: 2375.0 TN: 1016.0 FP: 987.0 FN: 852.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2870 Acc: 0.8864 Pre: 0.8992 Rec: 0.9325 F1: 0.9155\n",
      "TP: 2899.0 TN: 1276.0 FP: 325.0 FN: 210.0\n",
      "val Loss: 0.1222 Acc: 0.9558 Pre: 0.9659 Rec: 0.9672 F1: 0.9666\n",
      "TP: 3007.0 TN: 1495.0 FP: 106.0 FN: 102.0\n",
      "test Loss: 0.8246 Acc: 0.6191 Pre: 0.7024 Rec: 0.6641 F1: 0.6827\n",
      "TP: 2143.0 TN: 1095.0 FP: 908.0 FN: 1084.0\n",
      "\n",
      "Training complete in 92m 57s\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.]).to(device))\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'val_train', 'val', test_dl='test', num_epochs=25,\n",
    "                               verbose=True, log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += max(window, key=window.count)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.6117 Pre: 0.7095 Rec: 0.6275 F1: 0.6660\n",
      "TP: 2025.0 TN: 1174.0 FP: 829.0 FN: 1202.0\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed stats:\n",
      "(0.6252390057361377, 0.7205012182387748, 0.641462658816238, 0.6786885245901639, 2070, 1200, 803, 1157)\n"
     ]
    }
   ],
   "source": [
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
