{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/lfs/1/danfu/rekall_experiments/shot_experiments/shot_transitions'\n",
    "val_file = os.path.join(root_path, 'data/val.txt')\n",
    "test_file = os.path.join(root_path, 'data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, root_path):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append(os.path.join(\n",
    "                root_path,\n",
    "                'images/{}/{:06d}.jpg'.format(video, int(image))\n",
    "            ))\n",
    "            labels.append(int(label))\n",
    "    \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_paths, Y_val = read_file(val_file, root_path)\n",
    "test_paths, Y_test = read_file(test_file, root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 29072, 'val': 29072, 'test': 29536}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "test Loss: 0.0582 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0683 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0644 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0588 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0681 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0649 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0583 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0677 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0640 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0578 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0670 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0648 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0576 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0642 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0624 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0567 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0635 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0630 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0572 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0631 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0619 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0566 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0627 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0612 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0568 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0622 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0612 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0566 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0627 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0606 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0569 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0624 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0605 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0568 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0611 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0601 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0570 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0614 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "val Loss: 0.0601 Acc: 0.9880 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 28724.0 FP: 0.0 FN: 348.0\n",
      "test Loss: 0.0563 Acc: 0.9897 Pre: 0.0000 Rec: 0.0000 F1: 0.0000\n",
      "TP: 0.0 TN: 29233.0 FP: 0.0 FN: 303.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
