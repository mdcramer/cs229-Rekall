{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(video_path, annotation_path, dataset, sample_duration):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        video_path (string): Directory containing videos.\n",
    "        annotation_path (string): Name of annotation file.\n",
    "        dataset (string): \"val\" or \"test\"\n",
    "        sample_duration (int): Number of frames per segment.\n",
    "    \n",
    "    Need to return:\n",
    "        data (list): List of {video_path, image_list, class_index} dicts of (string, list, int).\n",
    "        class_names (dict): Dict with items (class_name, class_index).\n",
    "    \"\"\"\n",
    "    with open(annotation_path, 'rb') as f:\n",
    "        annotations = pickle.load(f)\n",
    "    if dataset == 'val':\n",
    "        class_indices = {\n",
    "            'long_val': 0,\n",
    "            'medium_val': 1,\n",
    "            'close_up_val': 2\n",
    "        }\n",
    "    elif dataset == 'test':\n",
    "        class_indices = {\n",
    "            'long_test': 0,\n",
    "            'medium_test': 1,\n",
    "            'close_up_test': 2\n",
    "        }\n",
    "    \n",
    "    def generate_image_list(segment_start, segment_end, sample_duration):\n",
    "        # regularly sample images from the segment\n",
    "        sample_duration = int(sample_duration)\n",
    "        increment = int((segment_end - segment_start + 1) / sample_duration)\n",
    "        if increment == 0:\n",
    "            # use all images, duplicate images at the end\n",
    "            return ([\n",
    "                '{}.jpg'.format(i)\n",
    "                for i in range(segment_start, segment_end + 1)\n",
    "            ] + [ '{}.jpg'.format(segment_end) for i in range(sample_duration - (segment_end - segment_start + 1)) ])[:sample_duration]\n",
    "        else:\n",
    "            # iterate through with increment\n",
    "            return [\n",
    "                '{}.jpg'.format(i)\n",
    "                for i in range(segment_start, segment_end + 1, increment)\n",
    "            ][:sample_duration]\n",
    "    data = [\n",
    "        {\n",
    "            'video_path': os.path.join(video_path, str(segment[0])),\n",
    "            'image_list': generate_image_list(segment[1], segment[2], sample_duration),\n",
    "            'class_index': class_indices[class_name]\n",
    "        }\n",
    "        for class_name in class_indices\n",
    "        for segment, _ in annotations[class_name]\n",
    "    ]\n",
    "\n",
    "    class_names = ['long', 'medium', 'close_up']\n",
    "    \n",
    "    return data, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 video_path,\n",
    "                 annotation_path,\n",
    "                 dataset,\n",
    "                 sample_duration,\n",
    "                 transform=None, \n",
    "                 stride = 1, \n",
    "                 max_size=None):\n",
    "        self.data, self.class_names = make_dataset(\n",
    "            video_path, annotation_path, dataset, sample_duration)\n",
    "        \n",
    "        paths = [\n",
    "            os.path.join(seg['video_path'], img_path)\n",
    "            for seg in self.data\n",
    "            for img_path in seg['image_list']\n",
    "        ]\n",
    "        labels = [\n",
    "            seg['class_index']\n",
    "            for seg in self.data\n",
    "            for img_path in seg['image_list']\n",
    "        ]\n",
    "        \n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/lfs/1/danfu/rekall_experiments/shot_scale_experiments/shot_scale'\n",
    "video_path = os.path.join(root_path, 'images')\n",
    "annotation_path = os.path.join(\n",
    "    root_path, 'shot_scale_labels_and_rekall_accuracy_val_test.pkl')\n",
    "image_datasets = {\n",
    "    'train': ImageDataset(\n",
    "        video_path, annotation_path, 'val', 16,\n",
    "        transform = data_transforms['train'],\n",
    "        stride=1, max_size=None\n",
    "    ),\n",
    "    'val': ImageDataset(\n",
    "        video_path, annotation_path, 'val', 16,\n",
    "        transform = data_transforms['val'],\n",
    "        stride=1, max_size=None\n",
    "    ),\n",
    "    'test': ImageDataset(\n",
    "        video_path, annotation_path, 'test', 16,\n",
    "        transform = data_transforms['val'],\n",
    "        stride=1, max_size=None\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 7168, 'val': 7168, 'test': 7200}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.8331 Acc: 0.6553\n",
      "val Loss: 0.2663 Acc: 0.8968\n",
      "test Loss: 0.6938 Acc: 0.7260\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "val Loss: 0.7797 Acc: 0.7552\n",
      "test Loss: 1.9956 Acc: 0.4986\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4852 Acc: 0.8096\n",
      "val Loss: 0.5220 Acc: 0.8323\n",
      "test Loss: 1.6526 Acc: 0.5094\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4125 Acc: 0.8351\n",
      "val Loss: 0.1764 Acc: 0.9357\n",
      "test Loss: 1.3971 Acc: 0.6242\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3964 Acc: 0.8428\n",
      "val Loss: 0.2416 Acc: 0.9141\n",
      "test Loss: 1.2268 Acc: 0.6326\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3431 Acc: 0.8634\n",
      "val Loss: 0.2513 Acc: 0.9074\n",
      "test Loss: 1.4070 Acc: 0.6308\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2575 Acc: 0.9016\n",
      "val Loss: 0.2993 Acc: 0.9092\n",
      "test Loss: 1.3705 Acc: 0.6086\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2210 Acc: 0.9166\n",
      "val Loss: 0.0550 Acc: 0.9820\n",
      "test Loss: 1.1844 Acc: 0.6811\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2101 Acc: 0.9220\n",
      "val Loss: 0.0427 Acc: 0.9877\n",
      "test Loss: 1.0306 Acc: 0.6975\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1881 Acc: 0.9291\n",
      "val Loss: 0.0343 Acc: 0.9898\n",
      "test Loss: 1.1152 Acc: 0.6871\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1784 Acc: 0.9395\n",
      "val Loss: 0.0393 Acc: 0.9887\n",
      "test Loss: 1.2002 Acc: 0.6810\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1725 Acc: 0.9375\n",
      "val Loss: 0.0395 Acc: 0.9886\n",
      "test Loss: 1.1681 Acc: 0.6717\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1624 Acc: 0.9410\n",
      "val Loss: 0.0317 Acc: 0.9911\n",
      "test Loss: 1.1371 Acc: 0.6867\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1525 Acc: 0.9439\n",
      "val Loss: 0.0301 Acc: 0.9908\n",
      "test Loss: 1.2082 Acc: 0.6742\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1494 Acc: 0.9452\n",
      "val Loss: 0.0270 Acc: 0.9915\n",
      "test Loss: 1.2654 Acc: 0.6750\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1537 Acc: 0.9422\n",
      "val Loss: 0.0283 Acc: 0.9907\n",
      "test Loss: 1.2314 Acc: 0.6810\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1604 Acc: 0.9460\n",
      "val Loss: 0.0316 Acc: 0.9916\n",
      "test Loss: 1.1622 Acc: 0.6785\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1519 Acc: 0.9452\n",
      "val Loss: 0.0281 Acc: 0.9912\n",
      "test Loss: 1.1135 Acc: 0.6808\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1539 Acc: 0.9473\n",
      "val Loss: 0.0305 Acc: 0.9905\n",
      "test Loss: 1.3536 Acc: 0.6607\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1436 Acc: 0.9482\n",
      "val Loss: 0.0303 Acc: 0.9918\n",
      "test Loss: 1.1444 Acc: 0.6693\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1429 Acc: 0.9499\n",
      "val Loss: 0.0273 Acc: 0.9929\n",
      "test Loss: 1.1582 Acc: 0.6850\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1446 Acc: 0.9488\n",
      "val Loss: 0.0286 Acc: 0.9919\n",
      "test Loss: 1.1410 Acc: 0.6847\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1568 Acc: 0.9434\n",
      "val Loss: 0.0258 Acc: 0.9916\n",
      "test Loss: 1.3334 Acc: 0.6610\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1515 Acc: 0.9436\n",
      "val Loss: 0.0251 Acc: 0.9923\n",
      "test Loss: 1.2052 Acc: 0.6829\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1469 Acc: 0.9475\n",
      "val Loss: 0.0271 Acc: 0.9916\n",
      "test Loss: 1.2129 Acc: 0.6714\n",
      "\n",
      "Training complete in 99m 6s\n",
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7892 Acc: 0.6807\n",
      "val Loss: 0.4563 Acc: 0.8643\n",
      "test Loss: 1.5161 Acc: 0.6872\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5830 Acc: 0.7656\n",
      "val Loss: 0.1812 Acc: 0.9392\n",
      "test Loss: 0.7857 Acc: 0.7068\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4650 Acc: 0.8147\n",
      "val Loss: 0.3120 Acc: 0.8705\n",
      "test Loss: 1.2239 Acc: 0.6571\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4074 Acc: 0.8412\n",
      "val Loss: 0.1350 Acc: 0.9597\n",
      "test Loss: 1.2969 Acc: 0.6381\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3540 Acc: 0.8629\n",
      "val Loss: 0.0856 Acc: 0.9683\n",
      "test Loss: 1.2262 Acc: 0.6629\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3366 Acc: 0.8714\n",
      "val Loss: 0.1358 Acc: 0.9491\n",
      "test Loss: 1.5922 Acc: 0.5964\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2294 Acc: 0.9138\n",
      "val Loss: 0.0465 Acc: 0.9858\n",
      "test Loss: 1.2625 Acc: 0.6828\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1951 Acc: 0.9280\n",
      "val Loss: 0.0439 Acc: 0.9865\n",
      "test Loss: 1.3649 Acc: 0.6676\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1770 Acc: 0.9351\n",
      "test Loss: 1.3664 Acc: 0.6724\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1716 Acc: 0.9369\n",
      "val Loss: 0.0344 Acc: 0.9905\n",
      "test Loss: 1.3197 Acc: 0.6642\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1662 Acc: 0.9408\n",
      "val Loss: 0.0318 Acc: 0.9907\n",
      "test Loss: 1.3093 Acc: 0.6924\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1563 Acc: 0.9424\n",
      "val Loss: 0.0298 Acc: 0.9916\n",
      "test Loss: 1.2887 Acc: 0.6743\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9435\n",
      "val Loss: 0.0259 Acc: 0.9918\n",
      "test Loss: 1.4033 Acc: 0.6657\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1429 Acc: 0.9524\n",
      "val Loss: 0.0275 Acc: 0.9920\n",
      "test Loss: 1.3329 Acc: 0.6615\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1456 Acc: 0.9468\n",
      "val Loss: 0.0296 Acc: 0.9909\n",
      "test Loss: 1.3975 Acc: 0.6501\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1370 Acc: 0.9540\n",
      "val Loss: 0.0228 Acc: 0.9933\n",
      "test Loss: 1.4036 Acc: 0.6729\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1448 Acc: 0.9449\n",
      "val Loss: 0.0243 Acc: 0.9915\n",
      "test Loss: 1.3983 Acc: 0.6671\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1397 Acc: 0.9515\n",
      "val Loss: 0.0245 Acc: 0.9922\n",
      "test Loss: 1.4128 Acc: 0.6672\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1364 Acc: 0.9506\n",
      "val Loss: 0.0246 Acc: 0.9927\n",
      "test Loss: 1.4343 Acc: 0.6610\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1439 Acc: 0.9475\n",
      "val Loss: 0.0227 Acc: 0.9929\n",
      "test Loss: 1.3842 Acc: 0.6804\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1412 Acc: 0.9495\n",
      "val Loss: 0.0233 Acc: 0.9918\n",
      "test Loss: 1.4459 Acc: 0.6586\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9494\n",
      "val Loss: 0.0235 Acc: 0.9923\n",
      "test Loss: 1.4639 Acc: 0.6635\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1355 Acc: 0.9524\n",
      "val Loss: 0.0247 Acc: 0.9926\n",
      "test Loss: 1.3314 Acc: 0.6683\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1301 Acc: 0.9549\n",
      "val Loss: 0.0208 Acc: 0.9934\n",
      "test Loss: 1.2906 Acc: 0.6889\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1310 Acc: 0.9520\n",
      "val Loss: 0.0216 Acc: 0.9930\n",
      "test Loss: 1.3459 Acc: 0.6796\n",
      "\n",
      "Training complete in 98m 2s\n",
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.8469 Acc: 0.6543\n",
      "val Loss: 0.3878 Acc: 0.8472\n",
      "test Loss: 0.9833 Acc: 0.6817\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5946 Acc: 0.7635\n",
      "val Loss: 0.2677 Acc: 0.9092\n",
      "test Loss: 1.5278 Acc: 0.6239\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4683 Acc: 0.8124\n",
      "val Loss: 0.1428 Acc: 0.9541\n",
      "test Loss: 0.9572 Acc: 0.6942\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4353 Acc: 0.8316\n",
      "val Loss: 1.1155 Acc: 0.6526\n",
      "test Loss: 2.5548 Acc: 0.4578\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3689 Acc: 0.8569\n",
      "val Loss: 0.0902 Acc: 0.9754\n",
      "test Loss: 0.9087 Acc: 0.6904\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3293 Acc: 0.8772\n",
      "val Loss: 0.0702 Acc: 0.9774\n",
      "test Loss: 1.1064 Acc: 0.7010\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2353 Acc: 0.9128\n",
      "val Loss: 0.0453 Acc: 0.9866\n",
      "test Loss: 1.1595 Acc: 0.6821\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2008 Acc: 0.9235\n",
      "val Loss: 0.0399 Acc: 0.9881\n",
      "test Loss: 1.1450 Acc: 0.6871\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1815 Acc: 0.9302\n",
      "val Loss: 0.0365 Acc: 0.9898\n",
      "test Loss: 1.1101 Acc: 0.6899\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1792 Acc: 0.9340\n",
      "val Loss: 0.0293 Acc: 0.9908\n",
      "test Loss: 1.2353 Acc: 0.6844\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1734 Acc: 0.9339\n",
      "val Loss: 0.0272 Acc: 0.9920\n",
      "test Loss: 1.2070 Acc: 0.6869\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1638 Acc: 0.9415\n",
      "val Loss: 0.0296 Acc: 0.9915\n",
      "test Loss: 1.3718 Acc: 0.6753\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1593 Acc: 0.9428\n",
      "val Loss: 0.0262 Acc: 0.9923\n",
      "test Loss: 1.2384 Acc: 0.6863\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1518 Acc: 0.9464\n",
      "val Loss: 0.0253 Acc: 0.9930\n",
      "test Loss: 1.1831 Acc: 0.6896\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1492 Acc: 0.9478\n",
      "val Loss: 0.0265 Acc: 0.9916\n",
      "test Loss: 1.4215 Acc: 0.6628\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1501 Acc: 0.9463\n",
      "val Loss: 0.0241 Acc: 0.9919\n",
      "test Loss: 1.2324 Acc: 0.6878\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9471\n",
      "val Loss: 0.0243 Acc: 0.9925\n",
      "test Loss: 1.2886 Acc: 0.6826\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1447 Acc: 0.9459\n",
      "val Loss: 0.0229 Acc: 0.9936\n",
      "test Loss: 1.1865 Acc: 0.6865\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1404 Acc: 0.9453\n",
      "val Loss: 0.0232 Acc: 0.9930\n",
      "test Loss: 1.3077 Acc: 0.6793\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1426 Acc: 0.9471\n",
      "val Loss: 0.0220 Acc: 0.9920\n",
      "test Loss: 1.3229 Acc: 0.6871\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1467 Acc: 0.9464\n",
      "val Loss: 0.0232 Acc: 0.9930\n",
      "test Loss: 1.2789 Acc: 0.6832\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9496\n",
      "val Loss: 0.0253 Acc: 0.9919\n",
      "test Loss: 1.3316 Acc: 0.6806\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1401 Acc: 0.9520\n",
      "val Loss: 0.0230 Acc: 0.9929\n",
      "test Loss: 1.2726 Acc: 0.6797\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9513\n",
      "val Loss: 0.0215 Acc: 0.9932\n",
      "test Loss: 1.3512 Acc: 0.6776\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1412 Acc: 0.9491\n",
      "val Loss: 0.0243 Acc: 0.9920\n",
      "test Loss: 1.4223 Acc: 0.6717\n",
      "\n",
      "Training complete in 96m 28s\n",
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.8165 Acc: 0.6662\n",
      "val Loss: 0.2432 Acc: 0.9131\n",
      "test Loss: 1.1056 Acc: 0.6690\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5781 Acc: 0.7679\n",
      "val Loss: 0.1656 Acc: 0.9411\n",
      "test Loss: 0.7968 Acc: 0.7122\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4578 Acc: 0.8179\n",
      "val Loss: 0.1505 Acc: 0.9429\n",
      "test Loss: 0.9478 Acc: 0.7137\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3986 Acc: 0.8401\n",
      "val Loss: 0.1180 Acc: 0.9618\n",
      "test Loss: 1.0153 Acc: 0.6779\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3497 Acc: 0.8616\n",
      "val Loss: 0.1396 Acc: 0.9455\n",
      "test Loss: 1.0796 Acc: 0.6874\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3243 Acc: 0.8717\n",
      "val Loss: 0.0828 Acc: 0.9718\n",
      "test Loss: 1.4558 Acc: 0.6631\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2305 Acc: 0.9135\n",
      "val Loss: 0.0466 Acc: 0.9854\n",
      "test Loss: 1.0472 Acc: 0.6947\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1906 Acc: 0.9294\n",
      "val Loss: 0.0456 Acc: 0.9874\n",
      "test Loss: 1.1041 Acc: 0.6789\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1866 Acc: 0.9291\n",
      "val Loss: 0.0373 Acc: 0.9873\n",
      "test Loss: 1.1675 Acc: 0.6808\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1763 Acc: 0.9361\n",
      "val Loss: 0.0354 Acc: 0.9894\n",
      "test Loss: 1.1914 Acc: 0.6765\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1609 Acc: 0.9411\n",
      "val Loss: 0.0304 Acc: 0.9908\n",
      "test Loss: 1.1994 Acc: 0.6682\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1539 Acc: 0.9452\n",
      "val Loss: 0.0287 Acc: 0.9909\n",
      "test Loss: 1.0857 Acc: 0.6942\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1480 Acc: 0.9459\n",
      "val Loss: 0.0361 Acc: 0.9904\n",
      "test Loss: 1.3280 Acc: 0.6578\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1509 Acc: 0.9466\n",
      "val Loss: 0.0255 Acc: 0.9926\n",
      "test Loss: 1.1679 Acc: 0.6763\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1359 Acc: 0.9510\n",
      "val Loss: 0.0244 Acc: 0.9918\n",
      "test Loss: 1.2371 Acc: 0.6810\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1449 Acc: 0.9498\n",
      "val Loss: 0.0231 Acc: 0.9929\n",
      "test Loss: 1.2155 Acc: 0.6760\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1354 Acc: 0.9528\n",
      "val Loss: 0.0259 Acc: 0.9904\n",
      "test Loss: 1.3030 Acc: 0.6763\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1374 Acc: 0.9496\n",
      "val Loss: 0.0250 Acc: 0.9923\n",
      "test Loss: 1.2825 Acc: 0.6726\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1357 Acc: 0.9484\n",
      "val Loss: 0.0241 Acc: 0.9926\n",
      "test Loss: 1.2670 Acc: 0.6719\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1390 Acc: 0.9521\n",
      "val Loss: 0.0255 Acc: 0.9927\n",
      "test Loss: 1.1882 Acc: 0.6658\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9509\n",
      "val Loss: 0.0245 Acc: 0.9920\n",
      "test Loss: 1.2765 Acc: 0.6778\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9523\n",
      "val Loss: 0.0265 Acc: 0.9914\n",
      "test Loss: 1.3253 Acc: 0.6657\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1348 Acc: 0.9527\n",
      "val Loss: 0.0203 Acc: 0.9934\n",
      "test Loss: 1.2270 Acc: 0.6826\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1346 Acc: 0.9530\n",
      "val Loss: 0.0254 Acc: 0.9929\n",
      "test Loss: 1.3167 Acc: 0.6697\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1337 Acc: 0.9509\n",
      "val Loss: 0.0217 Acc: 0.9937\n",
      "test Loss: 1.2413 Acc: 0.6775\n",
      "\n",
      "Training complete in 98m 36s\n",
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7931 Acc: 0.6706\n",
      "val Loss: 0.3404 Acc: 0.8588\n",
      "test Loss: 0.7587 Acc: 0.7238\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5369 Acc: 0.7846\n",
      "val Loss: 0.2256 Acc: 0.9176\n",
      "test Loss: 0.9243 Acc: 0.7122\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4442 Acc: 0.8238\n",
      "val Loss: 0.1311 Acc: 0.9615\n",
      "test Loss: 0.9992 Acc: 0.6775\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3854 Acc: 0.8465\n",
      "val Loss: 0.1064 Acc: 0.9623\n",
      "test Loss: 1.1535 Acc: 0.6660\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3506 Acc: 0.8641\n",
      "val Loss: 0.0818 Acc: 0.9736\n",
      "test Loss: 1.1368 Acc: 0.6965\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/transfer_learning'\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-78635045183e>, line 93)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-78635045183e>\"\u001b[0;36m, line \u001b[0;32m93\u001b[0m\n\u001b[0;31m    log_file_img.flush()\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning_tutorial'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 3)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    \n",
    "    # Compute per-class P/R/F1\n",
    "    def compute_prf1(preds, gts, class_name):\n",
    "        tp = len([1 for pred, gt in zip(preds, gts) if gt == class_name and pred == gt])\n",
    "        fp = len([1 for pred, gt in zip(preds, gts) if pred == class_name and pred != gt])\n",
    "        fn = len([1 for pred, gt in zip(preds, gts) if gt == class_name and pred != gt])\n",
    "\n",
    "        pre = tp / (tp + fp)\n",
    "        rec = tp / (tp + fn)\n",
    "        f1 = 2 * pre * rec  / (pre + rec)\n",
    "\n",
    "        return pre, rec, f1, tp, fp, fn\n",
    "    \n",
    "    def smooth_predictions(preds, window_radius = 3, segment_length = 16):\n",
    "        result = []\n",
    "        for start_idx in range(0, len(preds), segment_length):\n",
    "            for i in range(segment_length):\n",
    "                start = max(0, i - window_radius) + start_idx\n",
    "                end = min(len(preds), i + window_radius) + start_idx\n",
    "                window = preds[start:end]\n",
    "                result += [max(window, key=window.count)]\n",
    "\n",
    "        return result\n",
    "    \n",
    "    results = []\n",
    "    for class_name in [0, 1, 2]:\n",
    "        results.append((class_name, compute_prf1(predictions, gt_labels, class_name)))\n",
    "    \n",
    "    avg_pre = np.mean([res[1][0] for res in results])\n",
    "    avg_rec = np.mean([res[1][1] for res in results])\n",
    "    avg_f1 = np.mean([res[1][2] for res in results])\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\n'.format(\n",
    "                       seed,\n",
    "                       pre=avg_pre, rec=avg_rec,\n",
    "                       f1=avg_f1\n",
    "                   ))\n",
    "    for class_name in [0, 1, 2]:\n",
    "        log_file_img.write('{}\\n'.format(\n",
    "            (class_name, compute_prf1(predictions, gt_labels, class_name)))\n",
    "        )\n",
    "    log_file_img.flush()\n",
    "    \n",
    "    smoothed_preds = smooth_predictions(predictions)\n",
    "    results = []\n",
    "    for class_name in [0, 1, 2]:\n",
    "        results.append((class_name, compute_prf1(predictions, gt_labels, class_name)))\n",
    "    \n",
    "    avg_pre = np.mean([res[1][0] for res in results])\n",
    "    avg_rec = np.mean([res[1][1] for res in results])\n",
    "    avg_f1 = np.mean([res[1][2] for res in results])\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\n'.format(\n",
    "                       seed,\n",
    "                       pre=avg_pre, rec=avg_rec,\n",
    "                       f1=avg_f1\n",
    "                   ))\n",
    "    for class_name in [0, 1, 2]:\n",
    "        log_file_smoothed.write('{}\\n'.format(\n",
    "            (class_name, compute_prf1(smoothed_preds, gt_labels, class_name)))\n",
    "        )\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_corrects = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "\n",
    "# epoch_acc = running_corrects.double() / dataset_size\n",
    "# epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "# epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "# epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "# print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "#     epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "# print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "#     true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "# predictions = [p[0] for p in predictions]\n",
    "\n",
    "# smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "# print(\"Smoothed stats:\")\n",
    "# print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-class P/R/F1\n",
    "def compute_prf1(preds, gts, class_name):\n",
    "    tp = len([1 for pred, gt in zip(preds, gts) if gt == class_name and pred == gt])\n",
    "    fp = len([1 for pred, gt in zip(preds, gts) if pred == class_name and pred != gt])\n",
    "    fn = len([1 for pred, gt in zip(preds, gts) if gt == class_name and pred != gt])\n",
    "    \n",
    "    pre = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "    f1 = 2 * pre * rec  / (pre + rec)\n",
    "    \n",
    "    return pre, rec, f1, tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.7263820853743876, 0.4413265306122449, 0.5490610949484264, 1038, 391, 1314)\n",
      "1 (0.5333728863838624, 0.7644557823129252, 0.6283417787873492, 1798, 1573, 554)\n",
      "2 (0.8220833333333334, 0.7904647435897436, 0.8059640522875817, 1973, 427, 523)\n"
     ]
    }
   ],
   "source": [
    "for class_name in [0, 1, 2]:\n",
    "    print(class_name, compute_prf1(predictions, gt_labels, class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth predictions and compute again\n",
    "def smooth_predictions(preds, window_radius = 3, segment_length = 16):\n",
    "    result = []\n",
    "    for start_idx in range(0, len(preds), segment_length):\n",
    "        for i in range(segment_length):\n",
    "            start = max(0, i - window_radius) + start_idx\n",
    "            end = min(len(preds), i + window_radius) + start_idx\n",
    "            window = preds[start:end]\n",
    "            result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_preds = smooth_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.7317763623496107, 0.43962585034013607, 0.549269588313413, 1034, 379, 1318)\n",
      "1 (0.5334507042253521, 0.7729591836734694, 0.63125, 1818, 1590, 534)\n",
      "2 (0.8377469525010509, 0.7984775641025641, 0.8176410256410258, 1993, 386, 503)\n"
     ]
    }
   ],
   "source": [
    "for class_name in [0, 1, 2]:\n",
    "    print(class_name, compute_prf1(smoothed_preds, gt_labels, class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
