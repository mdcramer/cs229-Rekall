{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/train.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 64130, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3653 Acc: 0.8468 Pre: 0.7424 Rec: 0.7252 F1: 0.7337\n",
      "TP: 2000.0 TN: 6027.0 FP: 694.0 FN: 758.0\n",
      "val Loss: 0.1547 Acc: 0.9543 Pre: 0.9667 Rec: 0.8731 F1: 0.9175\n",
      "TP: 2408.0 TN: 6638.0 FP: 83.0 FN: 350.0\n",
      "test Loss: 0.2187 Acc: 0.9288 Pre: 0.9192 Rec: 0.8494 F1: 0.8829\n",
      "TP: 2014.0 TN: 4948.0 FP: 177.0 FN: 357.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2947 Acc: 0.8889 Pre: 0.8046 Rec: 0.8165 F1: 0.8105\n",
      "TP: 2252.0 TN: 6174.0 FP: 547.0 FN: 506.0\n",
      "val Loss: 0.1567 Acc: 0.9628 Pre: 0.9804 Rec: 0.8898 F1: 0.9329\n",
      "TP: 2454.0 TN: 6672.0 FP: 49.0 FN: 304.0\n",
      "test Loss: 0.2497 Acc: 0.9320 Pre: 0.9243 Rec: 0.8549 F1: 0.8883\n",
      "TP: 2027.0 TN: 4959.0 FP: 166.0 FN: 344.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2632 Acc: 0.9004 Pre: 0.8263 Rec: 0.8328 F1: 0.8295\n",
      "TP: 2297.0 TN: 6238.0 FP: 483.0 FN: 461.0\n",
      "val Loss: 0.1042 Acc: 0.9748 Pre: 0.9691 Rec: 0.9434 F1: 0.9561\n",
      "TP: 2602.0 TN: 6638.0 FP: 83.0 FN: 156.0\n",
      "test Loss: 0.2490 Acc: 0.9141 Pre: 0.8328 Rec: 0.9114 F1: 0.8703\n",
      "TP: 2161.0 TN: 4691.0 FP: 434.0 FN: 210.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2359 Acc: 0.9120 Pre: 0.8428 Rec: 0.8575 F1: 0.8501\n",
      "TP: 2365.0 TN: 6280.0 FP: 441.0 FN: 393.0\n",
      "val Loss: 0.1006 Acc: 0.9717 Pre: 0.9691 Rec: 0.9326 F1: 0.9505\n",
      "TP: 2572.0 TN: 6639.0 FP: 82.0 FN: 186.0\n",
      "test Loss: 0.1919 Acc: 0.9405 Pre: 0.8969 Rec: 0.9173 F1: 0.9070\n",
      "TP: 2175.0 TN: 4875.0 FP: 250.0 FN: 196.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2235 Acc: 0.9155 Pre: 0.8516 Rec: 0.8593 F1: 0.8554\n",
      "TP: 2370.0 TN: 6308.0 FP: 413.0 FN: 388.0\n",
      "val Loss: 0.0972 Acc: 0.9746 Pre: 0.9719 Rec: 0.9398 F1: 0.9556\n",
      "TP: 2592.0 TN: 6646.0 FP: 75.0 FN: 166.0\n",
      "test Loss: 0.1817 Acc: 0.9377 Pre: 0.8918 Rec: 0.9140 F1: 0.9027\n",
      "TP: 2167.0 TN: 4862.0 FP: 263.0 FN: 204.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2153 Acc: 0.9215 Pre: 0.8641 Rec: 0.8666 F1: 0.8653\n",
      "TP: 2390.0 TN: 6345.0 FP: 376.0 FN: 368.0\n",
      "val Loss: 0.0776 Acc: 0.9772 Pre: 0.9760 Rec: 0.9449 F1: 0.9602\n",
      "TP: 2606.0 TN: 6657.0 FP: 64.0 FN: 152.0\n",
      "test Loss: 0.1695 Acc: 0.9421 Pre: 0.9040 Rec: 0.9140 F1: 0.9090\n",
      "TP: 2167.0 TN: 4895.0 FP: 230.0 FN: 204.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1840 Acc: 0.9322 Pre: 0.8775 Rec: 0.8912 F1: 0.8843\n",
      "TP: 2458.0 TN: 6378.0 FP: 343.0 FN: 300.0\n",
      "val Loss: 0.0713 Acc: 0.9785 Pre: 0.9705 Rec: 0.9550 F1: 0.9627\n",
      "TP: 2634.0 TN: 6641.0 FP: 80.0 FN: 124.0\n",
      "test Loss: 0.1799 Acc: 0.9374 Pre: 0.8768 Rec: 0.9334 F1: 0.9042\n",
      "TP: 2213.0 TN: 4814.0 FP: 311.0 FN: 158.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1724 Acc: 0.9372 Pre: 0.8943 Rec: 0.8894 F1: 0.8918\n",
      "TP: 2453.0 TN: 6431.0 FP: 290.0 FN: 305.0\n",
      "val Loss: 0.0644 Acc: 0.9805 Pre: 0.9694 Rec: 0.9634 F1: 0.9664\n",
      "TP: 2657.0 TN: 6637.0 FP: 84.0 FN: 101.0\n",
      "test Loss: 0.1756 Acc: 0.9396 Pre: 0.8812 Rec: 0.9350 F1: 0.9073\n",
      "TP: 2217.0 TN: 4826.0 FP: 299.0 FN: 154.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1640 Acc: 0.9372 Pre: 0.8875 Rec: 0.8981 F1: 0.8928\n",
      "TP: 2477.0 TN: 6407.0 FP: 314.0 FN: 281.0\n",
      "val Loss: 0.0690 Acc: 0.9808 Pre: 0.9795 Rec: 0.9540 F1: 0.9666\n",
      "TP: 2631.0 TN: 6666.0 FP: 55.0 FN: 127.0\n",
      "test Loss: 0.1827 Acc: 0.9434 Pre: 0.9072 Rec: 0.9148 F1: 0.9110\n",
      "TP: 2169.0 TN: 4903.0 FP: 222.0 FN: 202.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1637 Acc: 0.9407 Pre: 0.8919 Rec: 0.9061 F1: 0.8989\n",
      "TP: 2499.0 TN: 6418.0 FP: 303.0 FN: 259.0\n",
      "val Loss: 0.0626 Acc: 0.9820 Pre: 0.9675 Rec: 0.9706 F1: 0.9690\n",
      "TP: 2677.0 TN: 6631.0 FP: 90.0 FN: 81.0\n",
      "test Loss: 0.1792 Acc: 0.9382 Pre: 0.8738 Rec: 0.9405 F1: 0.9060\n",
      "TP: 2230.0 TN: 4803.0 FP: 322.0 FN: 141.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1627 Acc: 0.9402 Pre: 0.8928 Rec: 0.9028 F1: 0.8978\n",
      "TP: 2490.0 TN: 6422.0 FP: 299.0 FN: 268.0\n",
      "val Loss: 0.0581 Acc: 0.9823 Pre: 0.9719 Rec: 0.9670 F1: 0.9695\n",
      "TP: 2667.0 TN: 6644.0 FP: 77.0 FN: 91.0\n",
      "test Loss: 0.1752 Acc: 0.9406 Pre: 0.8824 Rec: 0.9372 F1: 0.9090\n",
      "TP: 2222.0 TN: 4829.0 FP: 296.0 FN: 149.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1602 Acc: 0.9401 Pre: 0.8959 Rec: 0.8985 F1: 0.8972\n",
      "TP: 2478.0 TN: 6433.0 FP: 288.0 FN: 280.0\n",
      "val Loss: 0.0571 Acc: 0.9823 Pre: 0.9709 Rec: 0.9681 F1: 0.9695\n",
      "TP: 2670.0 TN: 6641.0 FP: 80.0 FN: 88.0\n",
      "test Loss: 0.1790 Acc: 0.9384 Pre: 0.8736 Rec: 0.9414 F1: 0.9062\n",
      "TP: 2232.0 TN: 4802.0 FP: 323.0 FN: 139.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1536 Acc: 0.9432 Pre: 0.8999 Rec: 0.9057 F1: 0.9028\n",
      "TP: 2498.0 TN: 6443.0 FP: 278.0 FN: 260.0\n",
      "val Loss: 0.0621 Acc: 0.9813 Pre: 0.9691 Rec: 0.9666 F1: 0.9679\n",
      "TP: 2666.0 TN: 6636.0 FP: 85.0 FN: 92.0\n",
      "test Loss: 0.1846 Acc: 0.9381 Pre: 0.8779 Rec: 0.9342 F1: 0.9052\n",
      "TP: 2215.0 TN: 4817.0 FP: 308.0 FN: 156.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1607 Acc: 0.9391 Pre: 0.8904 Rec: 0.9017 F1: 0.8961\n",
      "TP: 2487.0 TN: 6415.0 FP: 306.0 FN: 271.0\n",
      "val Loss: 0.0601 Acc: 0.9823 Pre: 0.9803 Rec: 0.9583 F1: 0.9692\n",
      "TP: 2643.0 TN: 6668.0 FP: 53.0 FN: 115.0\n",
      "test Loss: 0.1661 Acc: 0.9457 Pre: 0.9109 Rec: 0.9182 F1: 0.9145\n",
      "TP: 2177.0 TN: 4912.0 FP: 213.0 FN: 194.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1515 Acc: 0.9468 Pre: 0.9054 Rec: 0.9126 F1: 0.9090\n",
      "TP: 2517.0 TN: 6458.0 FP: 263.0 FN: 241.0\n",
      "val Loss: 0.0574 Acc: 0.9829 Pre: 0.9765 Rec: 0.9645 F1: 0.9704\n",
      "TP: 2660.0 TN: 6657.0 FP: 64.0 FN: 98.0\n",
      "test Loss: 0.1748 Acc: 0.9440 Pre: 0.8967 Rec: 0.9300 F1: 0.9130\n",
      "TP: 2205.0 TN: 4871.0 FP: 254.0 FN: 166.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1559 Acc: 0.9409 Pre: 0.8982 Rec: 0.8988 F1: 0.8985\n",
      "TP: 2479.0 TN: 6440.0 FP: 281.0 FN: 279.0\n",
      "val Loss: 0.0567 Acc: 0.9822 Pre: 0.9675 Rec: 0.9714 F1: 0.9694\n",
      "TP: 2679.0 TN: 6631.0 FP: 90.0 FN: 79.0\n",
      "test Loss: 0.1849 Acc: 0.9368 Pre: 0.8681 Rec: 0.9435 F1: 0.9042\n",
      "TP: 2237.0 TN: 4785.0 FP: 340.0 FN: 134.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1551 Acc: 0.9417 Pre: 0.8967 Rec: 0.9036 F1: 0.9001\n",
      "TP: 2492.0 TN: 6434.0 FP: 287.0 FN: 266.0\n",
      "val Loss: 0.0556 Acc: 0.9830 Pre: 0.9741 Rec: 0.9674 F1: 0.9707\n",
      "TP: 2668.0 TN: 6650.0 FP: 71.0 FN: 90.0\n",
      "test Loss: 0.1759 Acc: 0.9409 Pre: 0.8859 Rec: 0.9334 F1: 0.9090\n",
      "TP: 2213.0 TN: 4840.0 FP: 285.0 FN: 158.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9452 Pre: 0.9005 Rec: 0.9126 F1: 0.9065\n",
      "TP: 2517.0 TN: 6443.0 FP: 278.0 FN: 241.0\n",
      "val Loss: 0.0567 Acc: 0.9810 Pre: 0.9640 Rec: 0.9710 F1: 0.9675\n",
      "TP: 2678.0 TN: 6621.0 FP: 100.0 FN: 80.0\n",
      "test Loss: 0.1889 Acc: 0.9361 Pre: 0.8655 Rec: 0.9447 F1: 0.9034\n",
      "TP: 2240.0 TN: 4777.0 FP: 348.0 FN: 131.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9433 Pre: 0.9040 Rec: 0.9010 F1: 0.9025\n",
      "TP: 2485.0 TN: 6457.0 FP: 264.0 FN: 273.0\n",
      "val Loss: 0.0590 Acc: 0.9821 Pre: 0.9661 Rec: 0.9724 F1: 0.9693\n",
      "TP: 2682.0 TN: 6627.0 FP: 94.0 FN: 76.0\n",
      "test Loss: 0.1880 Acc: 0.9368 Pre: 0.8666 Rec: 0.9456 F1: 0.9044\n",
      "TP: 2242.0 TN: 4780.0 FP: 345.0 FN: 129.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1521 Acc: 0.9412 Pre: 0.9009 Rec: 0.8967 F1: 0.8988\n",
      "TP: 2473.0 TN: 6449.0 FP: 272.0 FN: 285.0\n",
      "val Loss: 0.0579 Acc: 0.9822 Pre: 0.9685 Rec: 0.9703 F1: 0.9694\n",
      "TP: 2676.0 TN: 6634.0 FP: 87.0 FN: 82.0\n",
      "test Loss: 0.1860 Acc: 0.9380 Pre: 0.8746 Rec: 0.9384 F1: 0.9054\n",
      "TP: 2225.0 TN: 4806.0 FP: 319.0 FN: 146.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1530 Acc: 0.9414 Pre: 0.8989 Rec: 0.8999 F1: 0.8994\n",
      "TP: 2482.0 TN: 6442.0 FP: 279.0 FN: 276.0\n",
      "val Loss: 0.0567 Acc: 0.9826 Pre: 0.9682 Rec: 0.9721 F1: 0.9701\n",
      "TP: 2681.0 TN: 6633.0 FP: 88.0 FN: 77.0\n",
      "test Loss: 0.1857 Acc: 0.9369 Pre: 0.8684 Rec: 0.9435 F1: 0.9044\n",
      "TP: 2237.0 TN: 4786.0 FP: 339.0 FN: 134.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1456 Acc: 0.9460 Pre: 0.9014 Rec: 0.9144 F1: 0.9078\n",
      "TP: 2522.0 TN: 6445.0 FP: 276.0 FN: 236.0\n",
      "val Loss: 0.0558 Acc: 0.9826 Pre: 0.9720 Rec: 0.9681 F1: 0.9700\n",
      "TP: 2670.0 TN: 6644.0 FP: 77.0 FN: 88.0\n",
      "test Loss: 0.1807 Acc: 0.9410 Pre: 0.8832 Rec: 0.9376 F1: 0.9096\n",
      "TP: 2223.0 TN: 4831.0 FP: 294.0 FN: 148.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9432 Pre: 0.8939 Rec: 0.9133 F1: 0.9035\n",
      "TP: 2519.0 TN: 6422.0 FP: 299.0 FN: 239.0\n",
      "val Loss: 0.0557 Acc: 0.9839 Pre: 0.9759 Rec: 0.9685 F1: 0.9722\n",
      "TP: 2671.0 TN: 6655.0 FP: 66.0 FN: 87.0\n",
      "test Loss: 0.1759 Acc: 0.9426 Pre: 0.8931 Rec: 0.9300 F1: 0.9112\n",
      "TP: 2205.0 TN: 4861.0 FP: 264.0 FN: 166.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9438 Pre: 0.8977 Rec: 0.9104 F1: 0.9041\n",
      "TP: 2511.0 TN: 6435.0 FP: 286.0 FN: 247.0\n",
      "val Loss: 0.0557 Acc: 0.9816 Pre: 0.9688 Rec: 0.9681 F1: 0.9684\n",
      "TP: 2670.0 TN: 6635.0 FP: 86.0 FN: 88.0\n",
      "test Loss: 0.1809 Acc: 0.9394 Pre: 0.8769 Rec: 0.9405 F1: 0.9076\n",
      "TP: 2230.0 TN: 4812.0 FP: 313.0 FN: 141.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1463 Acc: 0.9429 Pre: 0.8980 Rec: 0.9068 F1: 0.9024\n",
      "TP: 2501.0 TN: 6437.0 FP: 284.0 FN: 257.0\n",
      "val Loss: 0.0571 Acc: 0.9822 Pre: 0.9672 Rec: 0.9717 F1: 0.9694\n",
      "TP: 2680.0 TN: 6630.0 FP: 91.0 FN: 78.0\n",
      "test Loss: 0.1858 Acc: 0.9366 Pre: 0.8674 Rec: 0.9439 F1: 0.9041\n",
      "TP: 2238.0 TN: 4783.0 FP: 342.0 FN: 133.0\n",
      "\n",
      "Training complete in 51m 27s\n",
      "Best epoch: 22\n",
      "Best val Acc: 0.983859\n",
      "Best val Pre: 0.975886\n",
      "Best val Rec: 0.968455\n",
      "Best val F1: 0.972156\n",
      "Test Acc: 0.942636\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'val_train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=True)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/traditional_supervision_no_augmentation'\n",
    "model_ts = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['val']\n",
    "dataset_size = dataset_sizes['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9787 Pre: 0.9587 Rec: 0.9685 F1: 0.9636\n",
      "TP: 2671.0 TN: 6606.0 FP: 115.0 FN: 87.0\n",
      "Smoothed stats:\n",
      "(0.9592784048950311, 0.93033381712627, 0.9296591733139956, 0.9299963728690607, 2564, 6529, 192, 194)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
