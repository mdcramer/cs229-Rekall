{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup (for Windows 10)**\n",
    "\n",
    "1. Create a Python 3.7 'pytorch' environment with Anaconda Navigator\n",
    "2. Activate the environment and run 'install pytorch torchvision - c pytorch': https://medium.com/@iamHarin17/how-to-setup-a-python-environment-for-deep-learning-with-anaconda-f65ab78a362\n",
    "3. Run 'pip install' for 'matplotlib', 'tqdm' and 'scipy'\n",
    "4. Install Jupyter Notebook from Anaconda Navigator and open this notebook.\n",
    "\n",
    "**Helpful Links**\n",
    "\n",
    "DOS Nvidia GPU usage: https://wiki.tuflow.com/index.php?title=DOS_GPU_Usage\n",
    "\n",
    "cd C:\\Program Files\\NVIDIA Corporation\\NVSMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables to run notebook\n",
    "\n",
    "# data root\n",
    "data_root = 'C:\\\\_data\\\\' # set to whever the data is being stored\n",
    "\n",
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = .2     # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25\n",
    "\n",
    "# BrokenPipeError on Windows 10\n",
    "# https://discuss.pytorch.org/t/brokenpipeerror-errno-32-broken-pipe-when-i-run-cifar10-tutorial-py/6224/3\n",
    "global_num_workers = 0 # originally set to 4, so perhaps should be 4 on Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')        \n",
    "        img_tensor = self.transform(img)\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with  C:\\_data\\commercials\\data\\rekall_train.txt\n"
     ]
    }
   ],
   "source": [
    "if use_rekall_labels: # use Rekall label for training\n",
    "    train_file = os.path.join(data_root, 'commercials\\\\data\\\\rekall_train.txt')\n",
    "else:\n",
    "    train_file = os.path.join(data_root, 'commercials\\\\data\\\\train.txt')\n",
    "\n",
    "# continue to use true labels for validation and test\n",
    "val_file   = os.path.join(data_root, 'commercials\\\\data\\\\val.txt')\n",
    "test_file  = os.path.join(data_root, 'commercials\\\\data\\\\test.txt')\n",
    "\n",
    "print('Training with ', train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, load_percentage = 1):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = set(videos) # set of all videos\n",
    "        sorted(videos) # make sure they're in the same order each time, although they're alreayd sorted in files\n",
    "        # reduce set of unique videos by load percentage\n",
    "        num_videos = int(len(set(videos)) * load_percentage) # number of videos to use\n",
    "        videos = list(videos)[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append(data_root + 'commercials\\\\images\\\\{}\\\\{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file, data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)\n",
    "\n",
    "# https://stackoverflow.com/a/32577022/852795\n",
    "# train_paths, Y_train = zip(*random.sample(list(zip(train_paths, Y_train)), int(len(train_paths) * data_percentage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = global_num_workers,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 12955, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets\n",
    "}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time() # timestamp for beginning of training\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training time {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "\n",
    "    # Print total training time\n",
    "    time_elapsed = time.time() - since\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcram\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3215 Acc: 0.8646 Pre: 0.7985 Rec: 0.7571 F1: 0.7772\n",
      "TP: 3060.0 TN: 8141.0 FP: 772.0 FN: 982.0\n",
      "val Loss: 0.2341 Acc: 0.9055 Pre: 0.7730 Rec: 0.9558 F1: 0.8547\n",
      "TP: 2636.0 TN: 5947.0 FP: 774.0 FN: 122.0\n",
      "test Loss: 0.1985 Acc: 0.9234 Pre: 0.8369 Rec: 0.9414 F1: 0.8861\n",
      "TP: 2232.0 TN: 4690.0 FP: 435.0 FN: 139.0\n",
      "Training time 12m 37s\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2505 Acc: 0.9034 Pre: 0.8495 Rec: 0.8392 F1: 0.8443\n",
      "TP: 3392.0 TN: 8312.0 FP: 601.0 FN: 650.0\n",
      "val Loss: 0.1620 Acc: 0.9448 Pre: 0.8782 Rec: 0.9409 F1: 0.9085\n",
      "TP: 2595.0 TN: 6361.0 FP: 360.0 FN: 163.0\n",
      "test Loss: 0.1623 Acc: 0.9445 Pre: 0.9058 Rec: 0.9203 F1: 0.9130\n",
      "TP: 2182.0 TN: 4898.0 FP: 227.0 FN: 189.0\n",
      "Training time 24m 20s\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2325 Acc: 0.9114 Pre: 0.8627 Rec: 0.8516 F1: 0.8571\n",
      "TP: 3442.0 TN: 8365.0 FP: 548.0 FN: 600.0\n",
      "val Loss: 0.1565 Acc: 0.9452 Pre: 0.8733 Rec: 0.9496 F1: 0.9098\n",
      "TP: 2619.0 TN: 6341.0 FP: 380.0 FN: 139.0\n",
      "test Loss: 0.1490 Acc: 0.9474 Pre: 0.9030 Rec: 0.9342 F1: 0.9183\n",
      "TP: 2215.0 TN: 4887.0 FP: 238.0 FN: 156.0\n",
      "Training time 35m 57s\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2177 Acc: 0.9209 Pre: 0.8784 Rec: 0.8664 F1: 0.8723\n",
      "TP: 3502.0 TN: 8428.0 FP: 485.0 FN: 540.0\n",
      "val Loss: 0.1600 Acc: 0.9428 Pre: 0.8748 Rec: 0.9376 F1: 0.9051\n",
      "TP: 2586.0 TN: 6351.0 FP: 370.0 FN: 172.0\n",
      "test Loss: 0.1586 Acc: 0.9477 Pre: 0.9180 Rec: 0.9165 F1: 0.9173\n",
      "TP: 2173.0 TN: 4931.0 FP: 194.0 FN: 198.0\n",
      "Training time 47m 30s\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2089 Acc: 0.9232 Pre: 0.8835 Rec: 0.8684 F1: 0.8759\n",
      "TP: 3510.0 TN: 8450.0 FP: 463.0 FN: 532.0\n",
      "val Loss: 0.1852 Acc: 0.9291 Pre: 0.8257 Rec: 0.9587 F1: 0.8872\n",
      "TP: 2644.0 TN: 6163.0 FP: 558.0 FN: 114.0\n",
      "test Loss: 0.1748 Acc: 0.9369 Pre: 0.8716 Rec: 0.9388 F1: 0.9040\n",
      "TP: 2226.0 TN: 4797.0 FP: 328.0 FN: 145.0\n",
      "Training time 59m 3s\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2022 Acc: 0.9256 Pre: 0.8859 Rec: 0.8741 F1: 0.8800\n",
      "TP: 3533.0 TN: 8458.0 FP: 455.0 FN: 509.0\n",
      "val Loss: 0.2023 Acc: 0.9287 Pre: 0.8371 Rec: 0.9373 F1: 0.8844\n",
      "TP: 2585.0 TN: 6218.0 FP: 503.0 FN: 173.0\n",
      "test Loss: 0.1995 Acc: 0.9348 Pre: 0.8927 Rec: 0.9022 F1: 0.8974\n",
      "TP: 2139.0 TN: 4868.0 FP: 257.0 FN: 232.0\n",
      "Training time 70m 37s\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9348 Pre: 0.9003 Rec: 0.8894 F1: 0.8948\n",
      "TP: 3595.0 TN: 8515.0 FP: 398.0 FN: 447.0\n",
      "val Loss: 0.1863 Acc: 0.9349 Pre: 0.8432 Rec: 0.9536 F1: 0.8950\n",
      "TP: 2630.0 TN: 6232.0 FP: 489.0 FN: 128.0\n",
      "test Loss: 0.1623 Acc: 0.9456 Pre: 0.9044 Rec: 0.9258 F1: 0.9150\n",
      "TP: 2195.0 TN: 4893.0 FP: 232.0 FN: 176.0\n",
      "Training time 82m 9s\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1696 Acc: 0.9382 Pre: 0.9038 Rec: 0.8973 F1: 0.9006\n",
      "TP: 3627.0 TN: 8527.0 FP: 386.0 FN: 415.0\n",
      "val Loss: 0.1709 Acc: 0.9408 Pre: 0.8596 Rec: 0.9521 F1: 0.9035\n",
      "TP: 2626.0 TN: 6292.0 FP: 429.0 FN: 132.0\n",
      "test Loss: 0.1548 Acc: 0.9484 Pre: 0.9158 Rec: 0.9216 F1: 0.9186\n",
      "TP: 2185.0 TN: 4924.0 FP: 201.0 FN: 186.0\n",
      "Training time 93m 45s\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1605 Acc: 0.9403 Pre: 0.9079 Rec: 0.9000 F1: 0.9040\n",
      "TP: 3638.0 TN: 8544.0 FP: 369.0 FN: 404.0\n",
      "val Loss: 0.1583 Acc: 0.9449 Pre: 0.8829 Rec: 0.9347 F1: 0.9081\n",
      "TP: 2578.0 TN: 6379.0 FP: 342.0 FN: 180.0\n",
      "test Loss: 0.1592 Acc: 0.9493 Pre: 0.9403 Rec: 0.8967 F1: 0.9180\n",
      "TP: 2126.0 TN: 4990.0 FP: 135.0 FN: 245.0\n",
      "Training time 105m 58s\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1620 Acc: 0.9406 Pre: 0.9119 Rec: 0.8961 F1: 0.9039\n",
      "TP: 3622.0 TN: 8563.0 FP: 350.0 FN: 420.0\n",
      "val Loss: 0.1879 Acc: 0.9322 Pre: 0.8348 Rec: 0.9561 F1: 0.8913\n",
      "TP: 2637.0 TN: 6199.0 FP: 522.0 FN: 121.0\n",
      "test Loss: 0.1628 Acc: 0.9417 Pre: 0.8941 Rec: 0.9253 F1: 0.9094\n",
      "TP: 2194.0 TN: 4865.0 FP: 260.0 FN: 177.0\n",
      "Training time 117m 50s\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1618 Acc: 0.9404 Pre: 0.9073 Rec: 0.9010 F1: 0.9042\n",
      "TP: 3642.0 TN: 8541.0 FP: 372.0 FN: 400.0\n",
      "val Loss: 0.1799 Acc: 0.9356 Pre: 0.8467 Rec: 0.9511 F1: 0.8958\n",
      "TP: 2623.0 TN: 6246.0 FP: 475.0 FN: 135.0\n",
      "test Loss: 0.1631 Acc: 0.9432 Pre: 0.9014 Rec: 0.9211 F1: 0.9111\n",
      "TP: 2184.0 TN: 4886.0 FP: 239.0 FN: 187.0\n",
      "Training time 129m 56s\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9441 Pre: 0.9185 Rec: 0.9008 F1: 0.9096\n",
      "TP: 3641.0 TN: 8590.0 FP: 323.0 FN: 401.0\n",
      "val Loss: 0.1924 Acc: 0.9322 Pre: 0.8356 Rec: 0.9547 F1: 0.8912\n",
      "TP: 2633.0 TN: 6203.0 FP: 518.0 FN: 125.0\n",
      "test Loss: 0.1658 Acc: 0.9438 Pre: 0.8999 Rec: 0.9253 F1: 0.9125\n",
      "TP: 2194.0 TN: 4881.0 FP: 244.0 FN: 177.0\n",
      "Training time 141m 47s\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1528 Acc: 0.9443 Pre: 0.9152 Rec: 0.9052 F1: 0.9102\n",
      "TP: 3659.0 TN: 8574.0 FP: 339.0 FN: 383.0\n",
      "val Loss: 0.1995 Acc: 0.9318 Pre: 0.8344 Rec: 0.9554 F1: 0.8908\n",
      "TP: 2635.0 TN: 6198.0 FP: 523.0 FN: 123.0\n",
      "test Loss: 0.1685 Acc: 0.9413 Pre: 0.8926 Rec: 0.9258 F1: 0.9089\n",
      "TP: 2195.0 TN: 4861.0 FP: 264.0 FN: 176.0\n",
      "Training time 153m 41s\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1510 Acc: 0.9452 Pre: 0.9124 Rec: 0.9119 F1: 0.9122\n",
      "TP: 3686.0 TN: 8559.0 FP: 354.0 FN: 356.0\n",
      "val Loss: 0.1868 Acc: 0.9348 Pre: 0.8427 Rec: 0.9540 F1: 0.8949\n",
      "TP: 2631.0 TN: 6230.0 FP: 491.0 FN: 127.0\n",
      "test Loss: 0.1635 Acc: 0.9448 Pre: 0.9009 Rec: 0.9275 F1: 0.9140\n",
      "TP: 2199.0 TN: 4883.0 FP: 242.0 FN: 172.0\n",
      "Training time 165m 20s\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 0.9445 Pre: 0.9159 Rec: 0.9052 F1: 0.9105\n",
      "TP: 3659.0 TN: 8577.0 FP: 336.0 FN: 383.0\n",
      "val Loss: 0.1975 Acc: 0.9326 Pre: 0.8356 Rec: 0.9565 F1: 0.8920\n",
      "TP: 2638.0 TN: 6202.0 FP: 519.0 FN: 120.0\n",
      "test Loss: 0.1680 Acc: 0.9428 Pre: 0.8950 Rec: 0.9279 F1: 0.9112\n",
      "TP: 2200.0 TN: 4867.0 FP: 258.0 FN: 171.0\n",
      "Training time 176m 58s\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1537 Acc: 0.9437 Pre: 0.9188 Rec: 0.8988 F1: 0.9087\n",
      "TP: 3633.0 TN: 8592.0 FP: 321.0 FN: 409.0\n",
      "val Loss: 0.1926 Acc: 0.9334 Pre: 0.8388 Rec: 0.9547 F1: 0.8930\n",
      "TP: 2633.0 TN: 6215.0 FP: 506.0 FN: 125.0\n",
      "test Loss: 0.1663 Acc: 0.9424 Pre: 0.8943 Rec: 0.9275 F1: 0.9106\n",
      "TP: 2199.0 TN: 4865.0 FP: 260.0 FN: 172.0\n",
      "Training time 188m 35s\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9458 Pre: 0.9144 Rec: 0.9117 F1: 0.9130\n",
      "TP: 3685.0 TN: 8568.0 FP: 345.0 FN: 357.0\n",
      "val Loss: 0.1694 Acc: 0.9416 Pre: 0.8649 Rec: 0.9471 F1: 0.9041\n",
      "TP: 2612.0 TN: 6313.0 FP: 408.0 FN: 146.0\n",
      "test Loss: 0.1579 Acc: 0.9489 Pre: 0.9226 Rec: 0.9152 F1: 0.9189\n",
      "TP: 2170.0 TN: 4943.0 FP: 182.0 FN: 201.0\n",
      "Training time 200m 27s\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1549 Acc: 0.9426 Pre: 0.9143 Rec: 0.9005 F1: 0.9074\n",
      "TP: 3640.0 TN: 8572.0 FP: 341.0 FN: 402.0\n",
      "val Loss: 0.2042 Acc: 0.9268 Pre: 0.8207 Rec: 0.9576 F1: 0.8839\n",
      "TP: 2641.0 TN: 6144.0 FP: 577.0 FN: 117.0\n",
      "test Loss: 0.1711 Acc: 0.9396 Pre: 0.8842 Rec: 0.9308 F1: 0.9069\n",
      "TP: 2207.0 TN: 4836.0 FP: 289.0 FN: 164.0\n",
      "Training time 212m 27s\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1519 Acc: 0.9431 Pre: 0.9143 Rec: 0.9023 F1: 0.9082\n",
      "TP: 3647.0 TN: 8571.0 FP: 342.0 FN: 395.0\n",
      "val Loss: 0.1784 Acc: 0.9370 Pre: 0.8505 Rec: 0.9507 F1: 0.8978\n",
      "TP: 2622.0 TN: 6260.0 FP: 461.0 FN: 136.0\n",
      "test Loss: 0.1602 Acc: 0.9460 Pre: 0.9092 Rec: 0.9211 F1: 0.9151\n",
      "TP: 2184.0 TN: 4907.0 FP: 218.0 FN: 187.0\n",
      "Training time 224m 44s\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9423 Pre: 0.9126 Rec: 0.9015 F1: 0.9070\n",
      "TP: 3644.0 TN: 8564.0 FP: 349.0 FN: 398.0\n",
      "val Loss: 0.2079 Acc: 0.9286 Pre: 0.8261 Rec: 0.9558 F1: 0.8862\n",
      "TP: 2636.0 TN: 6166.0 FP: 555.0 FN: 122.0\n",
      "test Loss: 0.1658 Acc: 0.9438 Pre: 0.8970 Rec: 0.9291 F1: 0.9128\n",
      "TP: 2203.0 TN: 4872.0 FP: 253.0 FN: 168.0\n",
      "Training time 236m 56s\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1541 Acc: 0.9434 Pre: 0.9137 Rec: 0.9040 F1: 0.9088\n",
      "TP: 3654.0 TN: 8568.0 FP: 345.0 FN: 388.0\n",
      "val Loss: 0.1988 Acc: 0.9314 Pre: 0.8323 Rec: 0.9572 F1: 0.8904\n",
      "TP: 2640.0 TN: 6189.0 FP: 532.0 FN: 118.0\n",
      "test Loss: 0.1678 Acc: 0.9432 Pre: 0.8961 Rec: 0.9279 F1: 0.9117\n",
      "TP: 2200.0 TN: 4870.0 FP: 255.0 FN: 171.0\n",
      "Training time 249m 5s\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9438 Pre: 0.9126 Rec: 0.9067 F1: 0.9097\n",
      "TP: 3665.0 TN: 8562.0 FP: 351.0 FN: 377.0\n",
      "val Loss: 0.1860 Acc: 0.9344 Pre: 0.8406 Rec: 0.9558 F1: 0.8945\n",
      "TP: 2636.0 TN: 6221.0 FP: 500.0 FN: 122.0\n",
      "test Loss: 0.1626 Acc: 0.9441 Pre: 0.9003 Rec: 0.9258 F1: 0.9129\n",
      "TP: 2195.0 TN: 4882.0 FP: 243.0 FN: 176.0\n",
      "Training time 261m 14s\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1478 Acc: 0.9482 Pre: 0.9190 Rec: 0.9146 F1: 0.9168\n",
      "TP: 3697.0 TN: 8587.0 FP: 326.0 FN: 345.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2229 Acc: 0.9216 Pre: 0.8056 Rec: 0.9630 F1: 0.8773\n",
      "TP: 2656.0 TN: 6080.0 FP: 641.0 FN: 102.0\n",
      "test Loss: 0.1777 Acc: 0.9352 Pre: 0.8689 Rec: 0.9363 F1: 0.9013\n",
      "TP: 2220.0 TN: 4790.0 FP: 335.0 FN: 151.0\n",
      "Training time 273m 25s\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1502 Acc: 0.9443 Pre: 0.9146 Rec: 0.9060 F1: 0.9103\n",
      "TP: 3662.0 TN: 8571.0 FP: 342.0 FN: 380.0\n",
      "val Loss: 0.1868 Acc: 0.9334 Pre: 0.8390 Rec: 0.9543 F1: 0.8930\n",
      "TP: 2632.0 TN: 6216.0 FP: 505.0 FN: 126.0\n",
      "test Loss: 0.1624 Acc: 0.9438 Pre: 0.9022 Rec: 0.9224 F1: 0.9122\n",
      "TP: 2187.0 TN: 4888.0 FP: 237.0 FN: 184.0\n",
      "Training time 285m 37s\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1496 Acc: 0.9444 Pre: 0.9157 Rec: 0.9052 F1: 0.9104\n",
      "TP: 3659.0 TN: 8576.0 FP: 337.0 FN: 383.0\n",
      "val Loss: 0.1947 Acc: 0.9324 Pre: 0.8357 Rec: 0.9554 F1: 0.8916\n",
      "TP: 2635.0 TN: 6203.0 FP: 518.0 FN: 123.0\n",
      "test Loss: 0.1644 Acc: 0.9425 Pre: 0.8950 Rec: 0.9270 F1: 0.9107\n",
      "TP: 2198.0 TN: 4867.0 FP: 258.0 FN: 173.0\n",
      "Training time 297m 25s\n",
      "\n",
      "\n",
      "Training complete in 297m 25s\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(data_root, 'Commercials\\\\models\\\\transfer_learning')\n",
    "for seed in range(num_seeds):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=global_num_epochs, verbose=True,\n",
    "                               log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on seed: 0\n",
      "Acc: 0.9425 Pre: 0.8950 Rec: 0.9270 F1: 0.9107\n",
      "TP: 2198.0 TN: 4867.0 FP: 258.0 FN: 173.0\n",
      "Smoothed stats:\n",
      "(0.9401013874066169, 0.9004166666666666, 0.9114297764656263, 0.905889750576399, 2161, 4886, 239, 210)\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(data_root, 'Commercials\\\\models\\\\transfer_learning')\n",
    "log_file_img = open(os.path.join(path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(num_seeds):\n",
    "    print('Working on seed:', seed)\n",
    "    \n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(os.path.join(path, 'seed_{}.pth'.format(seed))))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(data_root, 'Commercials\\\\models\\\\transfer_learning')\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(os.path.join(path, 'seed_0.pth')))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9448 Pre: 0.9086 Rec: 0.9178 F1: 0.9131\n",
      "TP: 2176.0 TN: 4906.0 FP: 219.0 FN: 195.0\n",
      "Smoothed stats:\n",
      "(0.941435432230523, 0.90418410041841, 0.9114297764656263, 0.9077924805713086, 2161, 4896, 229, 210)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
