{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "F1 with Rekall labels (1 seed, 25 epochs, 16 batch size):\n",
    "* 0.8376 @ 5%\n",
    "* 0.9107 @ 20%\n",
    "* 0.9240 @ 40%\n",
    "* 0.9233 @ 60%\n",
    "* 0.9243 @ 80%\n",
    "* 0.9279 @ 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup (for Windows 10)**\n",
    "\n",
    "1. Create a Python 3.7 'pytorch' environment with Anaconda Navigator\n",
    "2. Activate the environment and run 'install pytorch torchvision - c pytorch': https://medium.com/@iamHarin17/how-to-setup-a-python-environment-for-deep-learning-with-anaconda-f65ab78a362\n",
    "3. Run 'pip install' for 'matplotlib', 'tqdm' and 'scipy'\n",
    "4. Install Jupyter Notebook from Anaconda Navigator and open this notebook.\n",
    "\n",
    "**Helpful Links**\n",
    "\n",
    "DOS Nvidia GPU usage: https://wiki.tuflow.com/index.php?title=DOS_GPU_Usage\n",
    "\n",
    "cd C:\\Program Files\\NVIDIA Corporation\\NVSMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables to run notebook\n",
    "\n",
    "# data root\n",
    "data_root = 'C:\\\\_data\\\\' # set to whever the data is being stored\n",
    "\n",
    "# hyperparameters\n",
    "# with m2200 - 15min with 8, 10min with 16, 9min with 24 and out of memory with 32\n",
    "global_batch_size = 16 # originally set to 4, but we've agreed to use 16 as default\n",
    "\n",
    "# parameters to control length of training\n",
    "use_rekall_labels = True # False will use 'true' labels - files need to be in 'commercials\\\\data\\\\'\n",
    "data_percentage = .05    # percentage of training data to us\n",
    "num_seeds = 1            # number of different seeds to run, originally 5\n",
    "global_num_epochs = 25   # originally 25\n",
    "\n",
    "# BrokenPipeError on Windows 10\n",
    "# https://discuss.pytorch.org/t/brokenpipeerror-errno-32-broken-pipe-when-i-run-cifar10-tutorial-py/6224/3\n",
    "global_num_workers = 0 # originally set to 4, so perhaps should be 4 on Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')        \n",
    "        img_tensor = self.transform(img)\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with  C:\\_data\\commercials\\data\\rekall_train.txt\n"
     ]
    }
   ],
   "source": [
    "if use_rekall_labels: # use Rekall label for training\n",
    "    train_file = os.path.join(data_root, 'commercials\\\\data\\\\rekall_train.txt')\n",
    "else:\n",
    "    train_file = os.path.join(data_root, 'commercials\\\\data\\\\train.txt')\n",
    "\n",
    "# continue to use true labels for validation and test\n",
    "val_file   = os.path.join(data_root, 'commercials\\\\data\\\\val.txt')\n",
    "test_file  = os.path.join(data_root, 'commercials\\\\data\\\\test.txt')\n",
    "\n",
    "print('Training with ', train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, load_percentage = 1):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    videos = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        \n",
    "        # find set of unique videos on file\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            videos.append(video)\n",
    "        videos = set(videos) # set of all videos\n",
    "        sorted(videos) # make sure they're in the same order each time, although they're alreayd sorted in files\n",
    "        # reduce set of unique videos by load percentage\n",
    "        num_videos = int(len(set(videos)) * load_percentage) # number of videos to use\n",
    "        videos = list(videos)[:num_videos] # take first 'num_videos'\n",
    "        f.seek(0) # go back to beginning of file\n",
    "        print('Loading data from first %d videos' % num_videos)\n",
    "        \n",
    "        # read in data only using videos in possibly reduced set from above\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            if video in videos: # load it up only if it's in the list of videos to use\n",
    "                paths.append(data_root + 'commercials\\\\images\\\\{}\\\\{:04d}.jpg'.format(video, int(image)))\n",
    "                labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from first 8 videos\n",
      "Loading data from first 21 videos\n",
      "Loading data from first 21 videos\n"
     ]
    }
   ],
   "source": [
    "train_paths, Y_train = read_file(train_file, data_percentage)\n",
    "val_paths  , Y_val   = read_file(val_file)\n",
    "test_paths , Y_test  = read_file(test_file)\n",
    "\n",
    "# https://stackoverflow.com/a/32577022/852795\n",
    "# train_paths, Y_train = zip(*random.sample(list(zip(train_paths, Y_train)), int(len(train_paths) * data_percentage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_train is the same as val\n",
    "image_datasets = {\n",
    "    'train'    : ImageDataset(train_paths, Y_train, transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths  , Y_val  , transform = data_transforms['train'], stride=1, max_size=None),\n",
    "    'val'      : ImageDataset(val_paths  , Y_val  , transform = data_transforms['val']  , stride=1, max_size=None),\n",
    "    'test'     : ImageDataset(test_paths , Y_test , transform = data_transforms['val']  , stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = global_batch_size,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = global_num_workers,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3292, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets\n",
    "}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_data(model, criterion, optimizer, scheduler, dl, phase, epoch, num_epochs, verbose=True, log_file=None):\n",
    "    \n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "            loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    dataset_size = len(inputs)\n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    if verbose:\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "            phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "        print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "            true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "    if log_file is not None:\n",
    "        log_file.write('Phase: {0}\\t'\n",
    "                       'Epoch: [{1}/{2}]\\t'\n",
    "                       'Loss: {loss_c:.4f}\\t'\n",
    "                       'Acc: {acc:.4f}\\t'\n",
    "                       'Pre: {pre:.4f}\\t'\n",
    "                       'Rec: {rec:.4f}\\t'\n",
    "                       'F1: {f1:.4f}\\t'\n",
    "                       'TP: {tp} '\n",
    "                       'TN: {tn} '\n",
    "                       'FP: {fp} '\n",
    "                       'FN: {fn}\\n'.format(\n",
    "                           phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                           acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                           f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                           fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                       ))\n",
    "        log_file.flush()\n",
    "\n",
    "#     # deep copy the model\n",
    "#     if phase == 'val' and epoch_f1 > best_f1:\n",
    "#         best_acc = epoch_acc\n",
    "#         best_f1 = epoch_f1\n",
    "#         best_precision = epoch_pre\n",
    "#         best_recall = epoch_recall\n",
    "#         best_epoch = epoch\n",
    "#         best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#     if phase == 'test' and best_epoch == epoch:\n",
    "#         best_test_acc = epoch_acc\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    \n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time() # timestamp for beginning of training\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        if epoch != num_epochs - 1:\n",
    "            \n",
    "            # only train if it's not the last epoch\n",
    "            scheduler.step()\n",
    "            model.train()  # Set model to training mode\n",
    "            dl = dataloaders[train_dl]\n",
    "            dataset_size = dataset_sizes[train_dl]\n",
    "            pass_data(model, criterion, optimizer, scheduler, dl, 'train', epoch, num_epochs, verbose, log_file)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # on final epoch run train, validation and test\n",
    "            for phase in phases:\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dl = dataloaders[train_dl]\n",
    "                    dataset_size = dataset_sizes[train_dl]                \n",
    "                elif phase == 'val':\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dl = dataloaders[val_dl]\n",
    "                    dataset_size = dataset_sizes[val_dl]\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dl = dataloaders[test_dl]\n",
    "                    dataset_size = dataset_sizes[test_dl]\n",
    "                pass_data(model, criterion, optimizer, scheduler, dl, phase, epoch, num_epochs, verbose, log_file)\n",
    "\n",
    "        # print end-of-epoch stats\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training time {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "\n",
    "    # print total training time\n",
    "    time_elapsed = time.time() - since\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 92.3835 Acc: 234.1667 Pre: 0.7809 Rec: 0.6347 F1: 0.7002\n",
      "TP: 563.0 TN: 2247.0 FP: 158.0 FN: 324.0\n",
      "Training time 2m 33s\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 61.8823 Acc: 251.5000 Pre: 0.8479 Rec: 0.8422 F1: 0.8450\n",
      "TP: 747.0 TN: 2271.0 FP: 134.0 FN: 140.0\n",
      "Training time 4m 57s\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 55.8463 Acc: 253.7500 Pre: 0.8628 Rec: 0.8579 F1: 0.8604\n",
      "TP: 761.0 TN: 2284.0 FP: 121.0 FN: 126.0\n",
      "Training time 7m 21s\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 49.5428 Acc: 254.8333 Pre: 0.8698 Rec: 0.8658 F1: 0.8678\n",
      "TP: 768.0 TN: 2290.0 FP: 115.0 FN: 119.0\n",
      "Training time 9m 44s\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 47.3934 Acc: 256.9167 Pre: 0.8906 Rec: 0.8715 F1: 0.8809\n",
      "TP: 773.0 TN: 2310.0 FP: 95.0 FN: 114.0\n",
      "Training time 12m 7s\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 43.5735 Acc: 259.1667 Pre: 0.8965 Rec: 0.8985 F1: 0.8975\n",
      "TP: 797.0 TN: 2313.0 FP: 92.0 FN: 90.0\n",
      "Training time 14m 31s\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 39.8725 Acc: 260.0833 Pre: 0.9212 Rec: 0.8828 F1: 0.9016\n",
      "TP: 783.0 TN: 2338.0 FP: 67.0 FN: 104.0\n",
      "Training time 16m 53s\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 38.1904 Acc: 260.0000 Pre: 0.9040 Rec: 0.9019 F1: 0.9029\n",
      "TP: 800.0 TN: 2320.0 FP: 85.0 FN: 87.0\n",
      "Training time 19m 15s\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 35.3510 Acc: 260.0833 Pre: 0.8943 Rec: 0.9154 F1: 0.9047\n",
      "TP: 812.0 TN: 2309.0 FP: 96.0 FN: 75.0\n",
      "Training time 21m 37s\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 34.1343 Acc: 262.0833 Pre: 0.9214 Rec: 0.9121 F1: 0.9167\n",
      "TP: 809.0 TN: 2336.0 FP: 69.0 FN: 78.0\n",
      "Training time 24m 0s\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 34.5929 Acc: 262.3333 Pre: 0.9169 Rec: 0.9211 F1: 0.9190\n",
      "TP: 817.0 TN: 2331.0 FP: 74.0 FN: 70.0\n",
      "Training time 26m 23s\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 32.3751 Acc: 263.2500 Pre: 0.9274 Rec: 0.9222 F1: 0.9248\n",
      "TP: 818.0 TN: 2341.0 FP: 64.0 FN: 69.0\n",
      "Training time 28m 45s\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 32.1618 Acc: 261.6667 Pre: 0.9200 Rec: 0.9076 F1: 0.9137\n",
      "TP: 805.0 TN: 2335.0 FP: 70.0 FN: 82.0\n",
      "Training time 31m 7s\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 32.9358 Acc: 262.0833 Pre: 0.9224 Rec: 0.9109 F1: 0.9166\n",
      "TP: 808.0 TN: 2337.0 FP: 68.0 FN: 79.0\n",
      "Training time 33m 30s\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 33.5655 Acc: 261.7500 Pre: 0.9211 Rec: 0.9076 F1: 0.9143\n",
      "TP: 805.0 TN: 2336.0 FP: 69.0 FN: 82.0\n",
      "Training time 35m 52s\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 34.4763 Acc: 262.9167 Pre: 0.9252 Rec: 0.9200 F1: 0.9226\n",
      "TP: 816.0 TN: 2339.0 FP: 66.0 FN: 71.0\n",
      "Training time 38m 14s\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 34.1340 Acc: 261.9167 Pre: 0.9165 Rec: 0.9154 F1: 0.9160\n",
      "TP: 812.0 TN: 2331.0 FP: 74.0 FN: 75.0\n",
      "Training time 40m 36s\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 31.2913 Acc: 262.1667 Pre: 0.9254 Rec: 0.9087 F1: 0.9170\n",
      "TP: 806.0 TN: 2340.0 FP: 65.0 FN: 81.0\n",
      "Training time 42m 59s\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 33.4914 Acc: 262.8333 Pre: 0.9241 Rec: 0.9200 F1: 0.9220\n",
      "TP: 816.0 TN: 2338.0 FP: 67.0 FN: 71.0\n",
      "Training time 45m 22s\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 32.5610 Acc: 262.6667 Pre: 0.9269 Rec: 0.9143 F1: 0.9205\n",
      "TP: 811.0 TN: 2341.0 FP: 64.0 FN: 76.0\n",
      "Training time 47m 44s\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 32.6487 Acc: 261.9167 Pre: 0.9222 Rec: 0.9087 F1: 0.9154\n",
      "TP: 806.0 TN: 2337.0 FP: 68.0 FN: 81.0\n",
      "Training time 50m 7s\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 33.1659 Acc: 261.6667 Pre: 0.9143 Rec: 0.9143 F1: 0.9143\n",
      "TP: 811.0 TN: 2329.0 FP: 76.0 FN: 76.0\n",
      "Training time 52m 29s\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 31.0499 Acc: 263.6667 Pre: 0.9184 Rec: 0.9391 F1: 0.9287\n",
      "TP: 833.0 TN: 2331.0 FP: 74.0 FN: 54.0\n",
      "Training time 54m 52s\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 30.8529 Acc: 263.0833 Pre: 0.9292 Rec: 0.9177 F1: 0.9234\n",
      "TP: 814.0 TN: 2343.0 FP: 62.0 FN: 73.0\n",
      "Training time 57m 14s\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 31.2506 Acc: 262.8333 Pre: 0.9241 Rec: 0.9200 F1: 0.9220\n",
      "TP: 816.0 TN: 2338.0 FP: 67.0 FN: 71.0\n",
      "val Loss: 508.0511 Acc: 1138.1429 Pre: 0.6536 Rec: 0.9612 F1: 0.7781\n",
      "TP: 2651.0 TN: 5316.0 FP: 1405.0 FN: 107.0\n",
      "test Loss: 263.8292 Acc: 828.5000 Pre: 0.7528 Rec: 0.9439 F1: 0.8376\n",
      "TP: 2238.0 TN: 4390.0 FP: 735.0 FN: 133.0\n",
      "Training time 64m 42s\n",
      "\n",
      "\n",
      "Training complete in 64m 42s\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(data_root, 'Commercials\\\\models\\\\transfer_learning')\n",
    "for seed in range(num_seeds):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=global_num_epochs, verbose=True,\n",
    "                               log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on seed: 0\n",
      "Acc: 0.8842 Pre: 0.7528 Rec: 0.9439 F1: 0.8376\n",
      "TP: 2238.0 TN: 4390.0 FP: 735.0 FN: 133.0\n",
      "Smoothed stats:\n",
      "(0.8970117395944504, 0.7790575916230367, 0.9413749472796289, 0.8525592055003821, 2232, 4492, 633, 139)\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(data_root, 'Commercials\\\\models\\\\transfer_learning')\n",
    "log_file_img = open(os.path.join(path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(num_seeds):\n",
    "    print('Working on seed:', seed)\n",
    "    \n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(os.path.join(path, 'seed_{}.pth'.format(seed))))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(data_root, 'Commercials\\\\models\\\\transfer_learning')\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(os.path.join(path, 'seed_0.pth')))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9448 Pre: 0.9086 Rec: 0.9178 F1: 0.9131\n",
      "TP: 2176.0 TN: 4906.0 FP: 219.0 FN: 195.0\n",
      "Smoothed stats:\n",
      "(0.941435432230523, 0.90418410041841, 0.9114297764656263, 0.9077924805713086, 2161, 4896, 229, 210)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
