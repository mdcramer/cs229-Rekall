{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup (for Windows 10)**\n",
    "\n",
    "1. Create a Python 3.7 'pytorch' environment with Anaconda Navigator\n",
    "2. Activate the environment and run 'install pytorch torchvision - c pytorch': https://medium.com/@iamHarin17/how-to-setup-a-python-environment-for-deep-learning-with-anaconda-f65ab78a362\n",
    "3. Run 'pip install' for 'matplotlib', 'tqdm' and 'scipy'\n",
    "4. Install Jupyter Notebook from Anaconda Navigator and open this notebook.\n",
    "\n",
    "**Helpful Links**\n",
    "\n",
    "DOS Nvidia GPU usage: https://wiki.tuflow.com/index.php?title=DOS_GPU_Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables to run notebook\n",
    "\n",
    "# data root\n",
    "data_root = 'C:\\_data/' # set to whever the data is being stored\n",
    "\n",
    "# BrokenPipeError on Windows 10\n",
    "# https://discuss.pytorch.org/t/brokenpipeerror-errno-32-broken-pipe-when-i-run-cifar10-tutorial-py/6224/3\n",
    "global_num_workers = 0 # originally set to 4, so perhaps should be 4 on Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.RandomResizedCrop(224),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #         transforms.Resize((310, 310)),\n",
    "#         transforms.Resize((224, 224)),\n",
    "# #         transforms.Resize(256),\n",
    "# #         transforms.CenterCrop(224),\n",
    "# #         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = data_root + 'commercials/data/train.txt'\n",
    "val_file   = data_root + 'commercials/data/val.txt'\n",
    "test_file  = data_root + 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append(data_root + 'commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val_train': ImageDataset(val_paths, Y_val, transform = data_transforms['train'],\n",
    "                       stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size = 4,\n",
    "                                              shuffle = 'train' in x,\n",
    "                                              num_workers = global_num_workers,\n",
    "                                              pin_memory = True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 64130, 'val_train': 9479, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time() # timestamp for beginning of training\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training time {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "\n",
    "    # Print total training time\n",
    "    time_elapsed = time.time() - since\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcram\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3456 Acc: 0.8539 Pre: 0.7525 Rec: 0.7418 F1: 0.7471\n",
      "TP: 2046.0 TN: 6048.0 FP: 673.0 FN: 712.0\n",
      "val Loss: 0.1682 Acc: 0.9478 Pre: 0.9748 Rec: 0.8423 F1: 0.9037\n",
      "TP: 2323.0 TN: 6661.0 FP: 60.0 FN: 435.0\n",
      "test Loss: 0.2428 Acc: 0.9153 Pre: 0.9272 Rec: 0.7946 F1: 0.8558\n",
      "TP: 1884.0 TN: 4977.0 FP: 148.0 FN: 487.0\n",
      "Training time 15m 9s\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2689 Acc: 0.8979 Pre: 0.8219 Rec: 0.8285 F1: 0.8252\n",
      "TP: 2285.0 TN: 6226.0 FP: 495.0 FN: 473.0\n",
      "val Loss: 0.0942 Acc: 0.9736 Pre: 0.9491 Rec: 0.9608 F1: 0.9550\n",
      "TP: 2650.0 TN: 6579.0 FP: 142.0 FN: 108.0\n",
      "test Loss: 0.2511 Acc: 0.9204 Pre: 0.8293 Rec: 0.9422 F1: 0.8821\n",
      "TP: 2234.0 TN: 4665.0 FP: 460.0 FN: 137.0\n",
      "Training time 29m 3s\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2132 Acc: 0.9189 Pre: 0.8568 Rec: 0.8658 F1: 0.8613\n",
      "TP: 2388.0 TN: 6322.0 FP: 399.0 FN: 370.0\n",
      "val Loss: 0.1166 Acc: 0.9720 Pre: 0.9419 Rec: 0.9634 F1: 0.9525\n",
      "TP: 2657.0 TN: 6557.0 FP: 164.0 FN: 101.0\n",
      "test Loss: 0.2597 Acc: 0.9110 Pre: 0.8071 Rec: 0.9443 F1: 0.8704\n",
      "TP: 2239.0 TN: 4590.0 FP: 535.0 FN: 132.0\n",
      "Training time 42m 47s\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2051 Acc: 0.9230 Pre: 0.8611 Rec: 0.8767 F1: 0.8688\n",
      "TP: 2418.0 TN: 6331.0 FP: 390.0 FN: 340.0\n",
      "val Loss: 0.1089 Acc: 0.9681 Pre: 0.9741 Rec: 0.9148 F1: 0.9435\n",
      "TP: 2523.0 TN: 6654.0 FP: 67.0 FN: 235.0\n",
      "test Loss: 0.2123 Acc: 0.9390 Pre: 0.9315 Rec: 0.8714 F1: 0.9004\n",
      "TP: 2066.0 TN: 4973.0 FP: 152.0 FN: 305.0\n",
      "Training time 56m 32s\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9289 Pre: 0.8751 Rec: 0.8814 F1: 0.8783\n",
      "TP: 2431.0 TN: 6374.0 FP: 347.0 FN: 327.0\n",
      "val Loss: 0.0761 Acc: 0.9782 Pre: 0.9715 Rec: 0.9529 F1: 0.9621\n",
      "TP: 2628.0 TN: 6644.0 FP: 77.0 FN: 130.0\n",
      "test Loss: 0.1950 Acc: 0.9457 Pre: 0.9095 Rec: 0.9199 F1: 0.9147\n",
      "TP: 2181.0 TN: 4908.0 FP: 217.0 FN: 190.0\n",
      "Training time 70m 25s\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1843 Acc: 0.9316 Pre: 0.8792 Rec: 0.8869 F1: 0.8830\n",
      "TP: 2446.0 TN: 6385.0 FP: 336.0 FN: 312.0\n",
      "val Loss: 0.0740 Acc: 0.9802 Pre: 0.9659 Rec: 0.9659 F1: 0.9659\n",
      "TP: 2664.0 TN: 6627.0 FP: 94.0 FN: 94.0\n",
      "test Loss: 0.2725 Acc: 0.9261 Pre: 0.8493 Rec: 0.9317 F1: 0.8886\n",
      "TP: 2209.0 TN: 4733.0 FP: 392.0 FN: 162.0\n",
      "Training time 84m 19s\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1586 Acc: 0.9412 Pre: 0.8901 Rec: 0.9104 F1: 0.9002\n",
      "TP: 2511.0 TN: 6411.0 FP: 310.0 FN: 247.0\n",
      "val Loss: 0.0659 Acc: 0.9815 Pre: 0.9641 Rec: 0.9728 F1: 0.9684\n",
      "TP: 2683.0 TN: 6621.0 FP: 100.0 FN: 75.0\n",
      "test Loss: 0.2651 Acc: 0.9238 Pre: 0.8368 Rec: 0.9431 F1: 0.8868\n",
      "TP: 2236.0 TN: 4689.0 FP: 436.0 FN: 135.0\n",
      "Training time 98m 8s\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1470 Acc: 0.9462 Pre: 0.9009 Rec: 0.9159 F1: 0.9083\n",
      "TP: 2526.0 TN: 6443.0 FP: 278.0 FN: 232.0\n",
      "val Loss: 0.0630 Acc: 0.9810 Pre: 0.9600 Rec: 0.9753 F1: 0.9676\n",
      "TP: 2690.0 TN: 6609.0 FP: 112.0 FN: 68.0\n",
      "test Loss: 0.2759 Acc: 0.9197 Pre: 0.8260 Rec: 0.9452 F1: 0.8816\n",
      "TP: 2241.0 TN: 4653.0 FP: 472.0 FN: 130.0\n",
      "Training time 112m 20s\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1377 Acc: 0.9488 Pre: 0.9063 Rec: 0.9191 F1: 0.9127\n",
      "TP: 2535.0 TN: 6459.0 FP: 262.0 FN: 223.0\n",
      "val Loss: 0.0561 Acc: 0.9836 Pre: 0.9724 Rec: 0.9714 F1: 0.9719\n",
      "TP: 2679.0 TN: 6645.0 FP: 76.0 FN: 79.0\n",
      "test Loss: 0.2411 Acc: 0.9288 Pre: 0.8515 Rec: 0.9384 F1: 0.8929\n",
      "TP: 2225.0 TN: 4737.0 FP: 388.0 FN: 146.0\n",
      "Training time 126m 9s\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1354 Acc: 0.9480 Pre: 0.9072 Rec: 0.9148 F1: 0.9110\n",
      "TP: 2523.0 TN: 6463.0 FP: 258.0 FN: 235.0\n",
      "val Loss: 0.0521 Acc: 0.9850 Pre: 0.9834 Rec: 0.9648 F1: 0.9740\n",
      "TP: 2661.0 TN: 6676.0 FP: 45.0 FN: 97.0\n",
      "test Loss: 0.2046 Acc: 0.9396 Pre: 0.8911 Rec: 0.9216 F1: 0.9061\n",
      "TP: 2185.0 TN: 4858.0 FP: 267.0 FN: 186.0\n",
      "Training time 139m 51s\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1233 Acc: 0.9556 Pre: 0.9217 Rec: 0.9260 F1: 0.9239\n",
      "TP: 2554.0 TN: 6504.0 FP: 217.0 FN: 204.0\n",
      "val Loss: 0.0487 Acc: 0.9860 Pre: 0.9768 Rec: 0.9750 F1: 0.9759\n",
      "TP: 2689.0 TN: 6657.0 FP: 64.0 FN: 69.0\n",
      "test Loss: 0.2361 Acc: 0.9325 Pre: 0.8610 Rec: 0.9380 F1: 0.8979\n",
      "TP: 2224.0 TN: 4766.0 FP: 359.0 FN: 147.0\n",
      "Training time 153m 26s\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9499 Pre: 0.9093 Rec: 0.9195 F1: 0.9144\n",
      "TP: 2536.0 TN: 6468.0 FP: 253.0 FN: 222.0\n",
      "val Loss: 0.0460 Acc: 0.9871 Pre: 0.9821 Rec: 0.9735 F1: 0.9778\n",
      "TP: 2685.0 TN: 6672.0 FP: 49.0 FN: 73.0\n",
      "test Loss: 0.2049 Acc: 0.9382 Pre: 0.8828 Rec: 0.9279 F1: 0.9048\n",
      "TP: 2200.0 TN: 4833.0 FP: 292.0 FN: 171.0\n",
      "Training time 167m 25s\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9518 Pre: 0.9137 Rec: 0.9213 F1: 0.9175\n",
      "TP: 2541.0 TN: 6481.0 FP: 240.0 FN: 217.0\n",
      "val Loss: 0.0474 Acc: 0.9863 Pre: 0.9789 Rec: 0.9739 F1: 0.9764\n",
      "TP: 2686.0 TN: 6663.0 FP: 58.0 FN: 72.0\n",
      "test Loss: 0.2058 Acc: 0.9378 Pre: 0.8793 Rec: 0.9313 F1: 0.9045\n",
      "TP: 2208.0 TN: 4822.0 FP: 303.0 FN: 163.0\n",
      "Training time 181m 23s\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1230 Acc: 0.9573 Pre: 0.9218 Rec: 0.9322 F1: 0.9270\n",
      "TP: 2571.0 TN: 6503.0 FP: 218.0 FN: 187.0\n",
      "val Loss: 0.0457 Acc: 0.9867 Pre: 0.9799 Rec: 0.9743 F1: 0.9771\n",
      "TP: 2687.0 TN: 6666.0 FP: 55.0 FN: 71.0\n",
      "test Loss: 0.2155 Acc: 0.9372 Pre: 0.8758 Rec: 0.9338 F1: 0.9039\n",
      "TP: 2214.0 TN: 4811.0 FP: 314.0 FN: 157.0\n",
      "Training time 195m 19s\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1312 Acc: 0.9509 Pre: 0.9105 Rec: 0.9220 F1: 0.9162\n",
      "TP: 2543.0 TN: 6471.0 FP: 250.0 FN: 215.0\n",
      "val Loss: 0.0463 Acc: 0.9879 Pre: 0.9867 Rec: 0.9714 F1: 0.9790\n",
      "TP: 2679.0 TN: 6685.0 FP: 36.0 FN: 79.0\n",
      "test Loss: 0.1869 Acc: 0.9473 Pre: 0.9106 Rec: 0.9241 F1: 0.9173\n",
      "TP: 2191.0 TN: 4910.0 FP: 215.0 FN: 180.0\n",
      "Training time 209m 17s\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1241 Acc: 0.9536 Pre: 0.9193 Rec: 0.9213 F1: 0.9203\n",
      "TP: 2541.0 TN: 6498.0 FP: 223.0 FN: 217.0\n",
      "val Loss: 0.0475 Acc: 0.9853 Pre: 0.9729 Rec: 0.9768 F1: 0.9749\n",
      "TP: 2694.0 TN: 6646.0 FP: 75.0 FN: 64.0\n",
      "test Loss: 0.2294 Acc: 0.9325 Pre: 0.8602 Rec: 0.9393 F1: 0.8980\n",
      "TP: 2227.0 TN: 4763.0 FP: 362.0 FN: 144.0\n",
      "Training time 223m 18s\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1260 Acc: 0.9545 Pre: 0.9160 Rec: 0.9289 F1: 0.9224\n",
      "TP: 2562.0 TN: 6486.0 FP: 235.0 FN: 196.0\n",
      "val Loss: 0.0450 Acc: 0.9878 Pre: 0.9871 Rec: 0.9706 F1: 0.9788\n",
      "TP: 2677.0 TN: 6686.0 FP: 35.0 FN: 81.0\n",
      "test Loss: 0.1994 Acc: 0.9433 Pre: 0.8968 Rec: 0.9275 F1: 0.9119\n",
      "TP: 2199.0 TN: 4872.0 FP: 253.0 FN: 172.0\n",
      "Training time 237m 12s\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1236 Acc: 0.9555 Pre: 0.9174 Rec: 0.9307 F1: 0.9240\n",
      "TP: 2567.0 TN: 6490.0 FP: 231.0 FN: 191.0\n",
      "val Loss: 0.0452 Acc: 0.9865 Pre: 0.9768 Rec: 0.9768 F1: 0.9768\n",
      "TP: 2694.0 TN: 6657.0 FP: 64.0 FN: 64.0\n",
      "test Loss: 0.2153 Acc: 0.9380 Pre: 0.8731 Rec: 0.9405 F1: 0.9056\n",
      "TP: 2230.0 TN: 4801.0 FP: 324.0 FN: 141.0\n",
      "Training time 251m 17s\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1174 Acc: 0.9566 Pre: 0.9202 Rec: 0.9318 F1: 0.9260\n",
      "TP: 2570.0 TN: 6498.0 FP: 223.0 FN: 188.0\n",
      "val Loss: 0.0478 Acc: 0.9880 Pre: 0.9911 Rec: 0.9674 F1: 0.9791\n",
      "TP: 2668.0 TN: 6697.0 FP: 24.0 FN: 90.0\n",
      "test Loss: 0.1903 Acc: 0.9474 Pre: 0.9212 Rec: 0.9119 F1: 0.9165\n",
      "TP: 2162.0 TN: 4940.0 FP: 185.0 FN: 209.0\n",
      "Training time 265m 23s\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1241 Acc: 0.9538 Pre: 0.9137 Rec: 0.9289 F1: 0.9213\n",
      "TP: 2562.0 TN: 6479.0 FP: 242.0 FN: 196.0\n",
      "val Loss: 0.0459 Acc: 0.9867 Pre: 0.9789 Rec: 0.9753 F1: 0.9771\n",
      "TP: 2690.0 TN: 6663.0 FP: 58.0 FN: 68.0\n",
      "test Loss: 0.2227 Acc: 0.9345 Pre: 0.8681 Rec: 0.9350 F1: 0.9003\n",
      "TP: 2217.0 TN: 4788.0 FP: 337.0 FN: 154.0\n",
      "Training time 279m 9s\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1225 Acc: 0.9556 Pre: 0.9260 Rec: 0.9210 F1: 0.9235\n",
      "TP: 2540.0 TN: 6518.0 FP: 203.0 FN: 218.0\n",
      "val Loss: 0.0452 Acc: 0.9871 Pre: 0.9796 Rec: 0.9761 F1: 0.9778\n",
      "TP: 2692.0 TN: 6665.0 FP: 56.0 FN: 66.0\n",
      "test Loss: 0.2135 Acc: 0.9360 Pre: 0.8718 Rec: 0.9350 F1: 0.9023\n",
      "TP: 2217.0 TN: 4799.0 FP: 326.0 FN: 154.0\n",
      "Training time 293m 2s\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1247 Acc: 0.9538 Pre: 0.9200 Rec: 0.9213 F1: 0.9207\n",
      "TP: 2541.0 TN: 6500.0 FP: 221.0 FN: 217.0\n",
      "val Loss: 0.0486 Acc: 0.9851 Pre: 0.9698 Rec: 0.9793 F1: 0.9746\n",
      "TP: 2701.0 TN: 6637.0 FP: 84.0 FN: 57.0\n",
      "test Loss: 0.2461 Acc: 0.9281 Pre: 0.8483 Rec: 0.9410 F1: 0.8922\n",
      "TP: 2231.0 TN: 4726.0 FP: 399.0 FN: 140.0\n",
      "Training time 306m 51s\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1255 Acc: 0.9537 Pre: 0.9143 Rec: 0.9278 F1: 0.9210\n",
      "TP: 2559.0 TN: 6481.0 FP: 240.0 FN: 199.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0461 Acc: 0.9854 Pre: 0.9733 Rec: 0.9768 F1: 0.9750\n",
      "TP: 2694.0 TN: 6647.0 FP: 74.0 FN: 64.0\n",
      "test Loss: 0.2325 Acc: 0.9317 Pre: 0.8582 Rec: 0.9393 F1: 0.8969\n",
      "TP: 2227.0 TN: 4757.0 FP: 368.0 FN: 144.0\n",
      "Training time 320m 34s\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9535 Pre: 0.9166 Rec: 0.9242 F1: 0.9204\n",
      "TP: 2549.0 TN: 6489.0 FP: 232.0 FN: 209.0\n",
      "val Loss: 0.0440 Acc: 0.9876 Pre: 0.9800 Rec: 0.9772 F1: 0.9786\n",
      "TP: 2695.0 TN: 6666.0 FP: 55.0 FN: 63.0\n",
      "test Loss: 0.2206 Acc: 0.9357 Pre: 0.8708 Rec: 0.9355 F1: 0.9020\n",
      "TP: 2218.0 TN: 4796.0 FP: 329.0 FN: 153.0\n",
      "Training time 334m 25s\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1264 Acc: 0.9536 Pre: 0.9136 Rec: 0.9282 F1: 0.9209\n",
      "TP: 2560.0 TN: 6479.0 FP: 242.0 FN: 198.0\n",
      "val Loss: 0.0451 Acc: 0.9868 Pre: 0.9786 Rec: 0.9761 F1: 0.9773\n",
      "TP: 2692.0 TN: 6662.0 FP: 59.0 FN: 66.0\n",
      "test Loss: 0.2197 Acc: 0.9342 Pre: 0.8665 Rec: 0.9363 F1: 0.9001\n",
      "TP: 2220.0 TN: 4783.0 FP: 342.0 FN: 151.0\n",
      "Training time 347m 59s\n",
      "\n",
      "\n",
      "Training complete in 347m 59s\n",
      "val_train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3552 Acc: 0.8528 Pre: 0.7523 Rec: 0.7368 F1: 0.7445\n",
      "TP: 2032.0 TN: 6052.0 FP: 669.0 FN: 726.0\n",
      "val Loss: 0.1215 Acc: 0.9618 Pre: 0.9069 Rec: 0.9681 F1: 0.9365\n",
      "TP: 2670.0 TN: 6447.0 FP: 274.0 FN: 88.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1c44b45d071f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n\u001b[0;32m     25\u001b[0m                                \u001b[1;34m'val_train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                                log_file=log_file, return_best=False)\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_ts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'seed_{}.pth'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-b82b39313d37>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl, num_epochs, return_best, verbose, log_file)\u001b[0m\n\u001b[0;32m     56\u001b[0m                     preds = torch.where(\n\u001b[0;32m     57\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                         torch.tensor([0.]).to(device))\n\u001b[0;32m     60\u001b[0m                     target = torch.where(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'val_train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=False)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acc: 0.9400 Pre: 0.8912 Rec: 0.9228 F1: 0.9068\n",
      "TP: 2188.0 TN: 4858.0 FP: 267.0 FN: 183.0\n",
      "Smoothed stats:\n",
      "(0.9340981856990395, 0.8813490451036164, 0.9148038802193167, 0.8977649006622517, 2169, 4833, 292, 202)\n",
      "1\n",
      "Acc: 0.9506 Pre: 0.9216 Rec: 0.9224 F1: 0.9220\n",
      "TP: 2187.0 TN: 4939.0 FP: 186.0 FN: 184.0\n",
      "Smoothed stats:\n",
      "(0.9450373532550693, 0.9145154464663563, 0.9114297764656263, 0.912970004224757, 2161, 4923, 202, 210)\n",
      "2\n",
      "Acc: 0.9452 Pre: 0.8911 Rec: 0.9418 F1: 0.9157\n",
      "TP: 2233.0 TN: 4852.0 FP: 273.0 FN: 138.0\n",
      "Smoothed stats:\n",
      "(0.9389007470651014, 0.8883475436459602, 0.9228173766343315, 0.9052544476623914, 2188, 4850, 275, 183)\n",
      "3\n",
      "Acc: 0.9344 Pre: 0.8609 Rec: 0.9452 F1: 0.9011\n",
      "TP: 2241.0 TN: 4763.0 FP: 362.0 FN: 130.0\n",
      "Smoothed stats:\n",
      "(0.9288954108858057, 0.8601097178683386, 0.9257697174188106, 0.8917326833231769, 2195, 4768, 357, 176)\n",
      "4\n",
      "Acc: 0.9338 Pre: 0.8692 Rec: 0.9308 F1: 0.8990\n",
      "TP: 2207.0 TN: 4793.0 FP: 332.0 FN: 164.0\n",
      "Smoothed stats:\n",
      "(0.9303628601921025, 0.8678869876641464, 0.9198650358498524, 0.893120393120393, 2181, 4793, 332, 190)\n"
     ]
    }
   ],
   "source": [
    "path = 'models/transfer_learning'\n",
    "\n",
    "log_file_img = open(os.path.join(\n",
    "    path, 'test_results_image_classifier.log'), 'w')\n",
    "log_file_smoothed = open(os.path.join(\n",
    "    path, 'test_results_smoothed.log'), 'w')\n",
    "\n",
    "for seed in range(5):\n",
    "    print(seed)\n",
    "    model_ts = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "    model_ts.load_state_dict(torch.load(\n",
    "        os.path.join(path, 'seed_{}.pth'.format(seed))\n",
    "    ))\n",
    "    model_ts.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model = model_ts.eval()   # Set model to evaluate mode\n",
    "    dl = dataloaders['test']\n",
    "    dataset_size = dataset_sizes['test']\n",
    "    \n",
    "    running_corrects = 0\n",
    "    true_positives = 0.\n",
    "    true_negatives = 0.\n",
    "    false_positives = 0.\n",
    "    false_negatives = 0.\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    predictions = []\n",
    "    gt_labels = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.where(\n",
    "                outputs >= 0.,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "            target = torch.where(\n",
    "                labels >= 0.5,\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device)\n",
    "            )\n",
    "\n",
    "        predictions += preds.cpu().numpy().tolist()\n",
    "        gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        # statistics\n",
    "        label_vals = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        correct = preds.view(label_vals.shape) == label_vals.data\n",
    "        running_corrects += torch.sum(correct)\n",
    "\n",
    "        true_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        true_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 1.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_positives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 0.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "        false_negatives += torch.sum(\n",
    "            torch.where(\n",
    "                (correct == 0.) * (label_vals == 1.),\n",
    "                torch.tensor([1.]).to(device),\n",
    "                torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "        num_fp = torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        )\n",
    "\n",
    "    #     if num_fp > 0:\n",
    "    #         print(num_fp)\n",
    "    #         print(torch.where(\n",
    "    #             (correct == 0.) * (label_vals == 0.),\n",
    "    #             torch.tensor([1.]).to(device),\n",
    "    #             torch.tensor([0.]).to(device)))\n",
    "    #         print(i)\n",
    "    #         out = torchvision.utils.make_grid(inputs)\n",
    "    # #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "    #         imshow(out)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    epoch_acc = running_corrects.double() / dataset_size\n",
    "    epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "    epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "    epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "    print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "        epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positives.data, true_negatives.data, false_positives.data, \n",
    "        false_negatives.data))\n",
    "    \n",
    "    log_file_img.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                       f1=epoch_f1, tp=int(true_positives.data),\n",
    "                       tn=int(true_negatives.data),\n",
    "                       fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                   ))\n",
    "    log_file_img.flush()\n",
    "\n",
    "    predictions = [p[0] for p in predictions]\n",
    "\n",
    "    smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "    print(\"Smoothed stats:\")\n",
    "    print(acc_prf1(smoothed_preds, gt_labels))\n",
    "    \n",
    "    sm_acc, sm_pre, sm_rec, sm_f1, sm_tp, sm_tn, sm_fp, sm_fn = acc_prf1(\n",
    "        smoothed_preds, gt_labels)\n",
    "    \n",
    "    log_file_smoothed.write('Seed: {0}\\t'\n",
    "                   'Acc: {acc:.4f}\\t'\n",
    "                   'Pre: {pre:.4f}\\t'\n",
    "                   'Rec: {rec:.4f}\\t'\n",
    "                   'F1: {f1:.4f}\\t'\n",
    "                   'TP: {tp} '\n",
    "                   'TN: {tn} '\n",
    "                   'FP: {fp} '\n",
    "                   'FN: {fn}\\n'.format(\n",
    "                       seed,\n",
    "                       acc=sm_acc, pre=sm_pre, rec=sm_rec,\n",
    "                       f1=sm_f1, tp=sm_tp,\n",
    "                       tn=sm_tn,\n",
    "                       fp=sm_fp, fn=sm_fn\n",
    "                   ))\n",
    "    log_file_smoothed.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/transfer_learning'\n",
    "model_ts = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9421 Pre: 0.8904 Rec: 0.9317 F1: 0.9106\n",
      "TP: 2209.0 TN: 4853.0 FP: 272.0 FN: 162.0\n",
      "Smoothed stats:\n",
      "(0.9327641408751334, 0.8783948115119579, 0.9139603542808942, 0.8958247209590741, 2167, 4825, 300, 204)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
