{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.Resize((310, 310)),\n",
    "        transforms.Resize((224, 224)),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.RandomResizedCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "#         transforms.Resize((310, 310)),\n",
    "        transforms.Resize((224, 224)),\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, stride = 1, max_size=None):\n",
    "        self.paths = paths[::stride]\n",
    "        if max_size is not None:\n",
    "            self.paths = self.paths[:max_size]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.paths[idx]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'commercials/data/train.txt'\n",
    "val_file = 'commercials/data/val.txt'\n",
    "test_file = 'commercials/data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            video, image, label = line.split(' ')\n",
    "            paths.append('commercials/images/{}/{:04d}.jpg'.format(video, int(image)))\n",
    "            labels.append(int(label))\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, Y_train = read_file(train_file)\n",
    "val_paths, Y_val = read_file(val_file)\n",
    "test_paths, Y_test = read_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': ImageDataset(train_paths, Y_train, transform = data_transforms['train'],\n",
    "                          stride=1, max_size=None),\n",
    "    'val': ImageDataset(val_paths, Y_val, transform = data_transforms['val'],\n",
    "                       stride=1, max_size=None),\n",
    "    'test': ImageDataset(test_paths, Y_test, transform = data_transforms['val'],\n",
    "                        stride=1, max_size=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=64,\n",
    "                                              shuffle='train' in x,\n",
    "                                              num_workers=16,\n",
    "                                              pin_memory=True)\n",
    "                                              for x in image_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x])\n",
    "    for x in image_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 64130, 'val': 9479, 'test': 7496}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_dl, val_dl, test_dl=None,\n",
    "                num_epochs=25, return_best=False, verbose=True, log_file=None):\n",
    "    print(train_dl, val_dl, test_dl)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    phases = ['train', 'val', 'test'] if test_dl is not None else ['train', 'val']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                dl = dataloaders[train_dl]\n",
    "                dataset_size = dataset_sizes[train_dl]\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dl = dataloaders[val_dl]\n",
    "                dataset_size = dataset_sizes[val_dl]\n",
    "            else:\n",
    "                model.eval()\n",
    "                dl = dataloaders[test_dl]\n",
    "                dataset_size = dataset_sizes[test_dl]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            true_positives = 0.\n",
    "            true_negatives = 0.\n",
    "            false_positives = 0.\n",
    "            false_negatives = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.where(\n",
    "                        outputs >= 0.,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                    target = torch.where(\n",
    "                        labels >= 0.5,\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device)\n",
    "                    )\n",
    "                    loss = criterion(outputs.view(target.shape), target)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_vals = torch.where(\n",
    "                    labels >= 0.5,\n",
    "                    torch.tensor([1.]).to(device),\n",
    "                    torch.tensor([0.]).to(device)\n",
    "                )\n",
    "                correct = preds.view(label_vals.shape) == label_vals.data\n",
    "                running_corrects += torch.sum(correct)\n",
    "                \n",
    "                true_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                true_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 1.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_positives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 0.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "                false_negatives += torch.sum(\n",
    "                    torch.where(\n",
    "                        (correct == 0.) * (label_vals == 1.),\n",
    "                        torch.tensor([1.]).to(device),\n",
    "                        torch.tensor([0.]).to(device))\n",
    "                )\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "            epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "            epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "                print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "            if log_file is not None:\n",
    "                log_file.write('Phase: {0}\\t'\n",
    "                               'Epoch: [{1}/{2}]\\t'\n",
    "                               'Loss: {loss_c:.4f}\\t'\n",
    "                               'Acc: {acc:.4f}\\t'\n",
    "                               'Pre: {pre:.4f}\\t'\n",
    "                               'Rec: {rec:.4f}\\t'\n",
    "                               'F1: {f1:.4f}\\t'\n",
    "                               'TP: {tp} '\n",
    "                               'TN: {tn} '\n",
    "                               'FP: {fp} '\n",
    "                               'FN: {fn}\\n'.format(\n",
    "                                   phase, epoch + 1, num_epochs, loss_c=epoch_loss,\n",
    "                                   acc=epoch_acc, pre=epoch_pre, rec=epoch_recall,\n",
    "                                   f1=epoch_f1, tp=int(true_positives.data), tn=int(true_negatives.data),\n",
    "                                   fp=int(false_positives.data), fn=int(false_negatives.data)\n",
    "                               ))\n",
    "                log_file.flush()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_acc = epoch_acc\n",
    "                best_f1 = epoch_f1\n",
    "                best_precision = epoch_pre\n",
    "                best_recall = epoch_recall\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test' and best_epoch == epoch:\n",
    "                best_test_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    if return_best:\n",
    "        print('Best epoch: {}'.format(best_epoch))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "        print('Best val Pre: {:4f}'.format(best_precision))\n",
    "        print('Best val Rec: {:4f}'.format(best_recall))\n",
    "        print('Best val F1: {:4f}'.format(best_f1))\n",
    "        print('Test Acc: {:4f}'.format(best_test_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val test\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.2342 Acc: 0.9562 Pre: 0.8838 Rec: 0.9724 F1: 0.9260\n",
      "TP: 17591.0 TN: 43728.0 FP: 2312.0 FN: 499.0\n",
      "val Loss: 0.1951 Acc: 0.9611 Pre: 0.8951 Rec: 0.9811 F1: 0.9362\n",
      "TP: 2706.0 TN: 6404.0 FP: 317.0 FN: 52.0\n",
      "test Loss: 0.2726 Acc: 0.9622 Pre: 0.9210 Rec: 0.9633 F1: 0.9417\n",
      "TP: 2284.0 TN: 4929.0 FP: 196.0 FN: 87.0\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.1351 Acc: 0.9776 Pre: 0.9411 Rec: 0.9821 F1: 0.9612\n",
      "TP: 17767.0 TN: 44928.0 FP: 1112.0 FN: 323.0\n",
      "val Loss: 0.1869 Acc: 0.9636 Pre: 0.9031 Rec: 0.9801 F1: 0.9400\n",
      "TP: 2703.0 TN: 6431.0 FP: 290.0 FN: 55.0\n",
      "test Loss: 0.2748 Acc: 0.9658 Pre: 0.9315 Rec: 0.9629 F1: 0.9469\n",
      "TP: 2283.0 TN: 4957.0 FP: 168.0 FN: 88.0\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0872 Acc: 0.9837 Pre: 0.9537 Rec: 0.9904 F1: 0.9717\n",
      "TP: 17916.0 TN: 45171.0 FP: 869.0 FN: 174.0\n",
      "val Loss: 0.2018 Acc: 0.9688 Pre: 0.9179 Rec: 0.9804 F1: 0.9481\n",
      "TP: 2704.0 TN: 6479.0 FP: 242.0 FN: 54.0\n",
      "test Loss: 0.3282 Acc: 0.9605 Pre: 0.9233 Rec: 0.9544 F1: 0.9386\n",
      "TP: 2263.0 TN: 4937.0 FP: 188.0 FN: 108.0\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0566 Acc: 0.9887 Pre: 0.9656 Rec: 0.9953 F1: 0.9802\n",
      "TP: 18005.0 TN: 45399.0 FP: 641.0 FN: 85.0\n",
      "val Loss: 0.2487 Acc: 0.9641 Pre: 0.9084 Rec: 0.9750 F1: 0.9405\n",
      "TP: 2689.0 TN: 6450.0 FP: 271.0 FN: 69.0\n",
      "test Loss: 0.3859 Acc: 0.9684 Pre: 0.9517 Rec: 0.9481 F1: 0.9499\n",
      "TP: 2248.0 TN: 5011.0 FP: 114.0 FN: 123.0\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0392 Acc: 0.9922 Pre: 0.9751 Rec: 0.9978 F1: 0.9863\n",
      "TP: 18050.0 TN: 45579.0 FP: 461.0 FN: 40.0\n",
      "val Loss: 0.2446 Acc: 0.9746 Pre: 0.9408 Rec: 0.9739 F1: 0.9571\n",
      "TP: 2686.0 TN: 6552.0 FP: 169.0 FN: 72.0\n",
      "test Loss: 0.4354 Acc: 0.9666 Pre: 0.9447 Rec: 0.9502 F1: 0.9474\n",
      "TP: 2253.0 TN: 4993.0 FP: 132.0 FN: 118.0\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9945 Pre: 0.9817 Rec: 0.9990 F1: 0.9903\n",
      "TP: 18072.0 TN: 45704.0 FP: 336.0 FN: 18.0\n",
      "val Loss: 0.2708 Acc: 0.9718 Pre: 0.9326 Rec: 0.9735 F1: 0.9526\n",
      "TP: 2685.0 TN: 6527.0 FP: 194.0 FN: 73.0\n",
      "test Loss: 0.4656 Acc: 0.9641 Pre: 0.9394 Rec: 0.9477 F1: 0.9435\n",
      "TP: 2247.0 TN: 4980.0 FP: 145.0 FN: 124.0\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0168 Acc: 0.9961 Pre: 0.9864 Rec: 0.9999 F1: 0.9931\n",
      "TP: 18088.0 TN: 45790.0 FP: 250.0 FN: 2.0\n",
      "val Loss: 0.3017 Acc: 0.9742 Pre: 0.9410 Rec: 0.9721 F1: 0.9563\n",
      "TP: 2681.0 TN: 6553.0 FP: 168.0 FN: 77.0\n",
      "test Loss: 0.5626 Acc: 0.9673 Pre: 0.9551 Rec: 0.9410 F1: 0.9479\n",
      "TP: 2231.0 TN: 5020.0 FP: 105.0 FN: 140.0\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0136 Acc: 0.9969 Pre: 0.9891 Rec: 1.0000 F1: 0.9945\n",
      "TP: 18090.0 TN: 45841.0 FP: 199.0 FN: 0.0\n",
      "val Loss: 0.3020 Acc: 0.9743 Pre: 0.9411 Rec: 0.9724 F1: 0.9565\n",
      "TP: 2682.0 TN: 6553.0 FP: 168.0 FN: 76.0\n",
      "test Loss: 0.5425 Acc: 0.9692 Pre: 0.9557 Rec: 0.9464 F1: 0.9510\n",
      "TP: 2244.0 TN: 5021.0 FP: 104.0 FN: 127.0\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0124 Acc: 0.9973 Pre: 0.9904 Rec: 1.0000 F1: 0.9952\n",
      "TP: 18090.0 TN: 45864.0 FP: 176.0 FN: 0.0\n",
      "val Loss: 0.3021 Acc: 0.9731 Pre: 0.9380 Rec: 0.9717 F1: 0.9546\n",
      "TP: 2680.0 TN: 6544.0 FP: 177.0 FN: 78.0\n",
      "test Loss: 0.5485 Acc: 0.9695 Pre: 0.9565 Rec: 0.9464 F1: 0.9515\n",
      "TP: 2244.0 TN: 5023.0 FP: 102.0 FN: 127.0\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0114 Acc: 0.9975 Pre: 0.9913 Rec: 0.9999 F1: 0.9956\n",
      "TP: 18088.0 TN: 45882.0 FP: 158.0 FN: 2.0\n",
      "val Loss: 0.3224 Acc: 0.9787 Pre: 0.9587 Rec: 0.9685 F1: 0.9636\n",
      "TP: 2671.0 TN: 6606.0 FP: 115.0 FN: 87.0\n",
      "test Loss: 0.6219 Acc: 0.9688 Pre: 0.9608 Rec: 0.9397 F1: 0.9501\n",
      "TP: 2228.0 TN: 5034.0 FP: 91.0 FN: 143.0\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0110 Acc: 0.9975 Pre: 0.9913 Rec: 1.0000 F1: 0.9957\n",
      "TP: 18090.0 TN: 45882.0 FP: 158.0 FN: 0.0\n",
      "val Loss: 0.3087 Acc: 0.9705 Pre: 0.9287 Rec: 0.9732 F1: 0.9504\n",
      "TP: 2684.0 TN: 6515.0 FP: 206.0 FN: 74.0\n",
      "test Loss: 0.5329 Acc: 0.9684 Pre: 0.9502 Rec: 0.9498 F1: 0.9500\n",
      "TP: 2252.0 TN: 5007.0 FP: 118.0 FN: 119.0\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0103 Acc: 0.9979 Pre: 0.9925 Rec: 1.0000 F1: 0.9962\n",
      "TP: 18090.0 TN: 45903.0 FP: 137.0 FN: 0.0\n",
      "val Loss: 0.3191 Acc: 0.9742 Pre: 0.9426 Rec: 0.9703 F1: 0.9562\n",
      "TP: 2676.0 TN: 6558.0 FP: 163.0 FN: 82.0\n",
      "test Loss: 0.5810 Acc: 0.9693 Pre: 0.9577 Rec: 0.9447 F1: 0.9512\n",
      "TP: 2240.0 TN: 5026.0 FP: 99.0 FN: 131.0\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0096 Acc: 0.9979 Pre: 0.9927 Rec: 1.0000 F1: 0.9963\n",
      "TP: 18090.0 TN: 45907.0 FP: 133.0 FN: 0.0\n",
      "val Loss: 0.3270 Acc: 0.9763 Pre: 0.9506 Rec: 0.9688 F1: 0.9596\n",
      "TP: 2672.0 TN: 6582.0 FP: 139.0 FN: 86.0\n",
      "test Loss: 0.6026 Acc: 0.9695 Pre: 0.9577 Rec: 0.9452 F1: 0.9514\n",
      "TP: 2241.0 TN: 5026.0 FP: 99.0 FN: 130.0\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0092 Acc: 0.9980 Pre: 0.9930 Rec: 1.0000 F1: 0.9965\n",
      "TP: 18090.0 TN: 45913.0 FP: 127.0 FN: 0.0\n",
      "val Loss: 0.3220 Acc: 0.9723 Pre: 0.9357 Rec: 0.9714 F1: 0.9532\n",
      "TP: 2679.0 TN: 6537.0 FP: 184.0 FN: 79.0\n",
      "test Loss: 0.5731 Acc: 0.9691 Pre: 0.9522 Rec: 0.9498 F1: 0.9510\n",
      "TP: 2252.0 TN: 5012.0 FP: 113.0 FN: 119.0\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0091 Acc: 0.9980 Pre: 0.9929 Rec: 0.9999 F1: 0.9964\n",
      "TP: 18089.0 TN: 45910.0 FP: 130.0 FN: 1.0\n",
      "val Loss: 0.3469 Acc: 0.9781 Pre: 0.9573 Rec: 0.9677 F1: 0.9625\n",
      "TP: 2669.0 TN: 6602.0 FP: 119.0 FN: 89.0\n",
      "test Loss: 0.6642 Acc: 0.9684 Pre: 0.9603 Rec: 0.9388 F1: 0.9495\n",
      "TP: 2226.0 TN: 5033.0 FP: 92.0 FN: 145.0\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0089 Acc: 0.9982 Pre: 0.9936 Rec: 0.9999 F1: 0.9967\n",
      "TP: 18089.0 TN: 45923.0 FP: 117.0 FN: 1.0\n",
      "val Loss: 0.3184 Acc: 0.9749 Pre: 0.9462 Rec: 0.9688 F1: 0.9574\n",
      "TP: 2672.0 TN: 6569.0 FP: 152.0 FN: 86.0\n",
      "test Loss: 0.5968 Acc: 0.9692 Pre: 0.9573 Rec: 0.9447 F1: 0.9510\n",
      "TP: 2240.0 TN: 5025.0 FP: 100.0 FN: 131.0\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0090 Acc: 0.9981 Pre: 0.9932 Rec: 1.0000 F1: 0.9966\n",
      "TP: 18090.0 TN: 45917.0 FP: 123.0 FN: 0.0\n",
      "val Loss: 0.3089 Acc: 0.9715 Pre: 0.9316 Rec: 0.9735 F1: 0.9521\n",
      "TP: 2685.0 TN: 6524.0 FP: 197.0 FN: 73.0\n",
      "test Loss: 0.5497 Acc: 0.9689 Pre: 0.9511 Rec: 0.9507 F1: 0.9509\n",
      "TP: 2254.0 TN: 5009.0 FP: 116.0 FN: 117.0\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0087 Acc: 0.9982 Pre: 0.9937 Rec: 1.0000 F1: 0.9968\n",
      "TP: 18090.0 TN: 45925.0 FP: 115.0 FN: 0.0\n",
      "val Loss: 0.3300 Acc: 0.9763 Pre: 0.9496 Rec: 0.9699 F1: 0.9596\n",
      "TP: 2675.0 TN: 6579.0 FP: 142.0 FN: 83.0\n",
      "test Loss: 0.6313 Acc: 0.9684 Pre: 0.9579 Rec: 0.9414 F1: 0.9496\n",
      "TP: 2232.0 TN: 5027.0 FP: 98.0 FN: 139.0\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0090 Acc: 0.9981 Pre: 0.9934 Rec: 1.0000 F1: 0.9967\n",
      "TP: 18090.0 TN: 45919.0 FP: 121.0 FN: 0.0\n",
      "val Loss: 0.3072 Acc: 0.9710 Pre: 0.9297 Rec: 0.9739 F1: 0.9513\n",
      "TP: 2686.0 TN: 6518.0 FP: 203.0 FN: 72.0\n",
      "test Loss: 0.5403 Acc: 0.9691 Pre: 0.9492 Rec: 0.9532 F1: 0.9512\n",
      "TP: 2260.0 TN: 5004.0 FP: 121.0 FN: 111.0\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 0.9981 Pre: 0.9934 Rec: 0.9998 F1: 0.9966\n",
      "TP: 18087.0 TN: 45920.0 FP: 120.0 FN: 3.0\n",
      "val Loss: 0.3679 Acc: 0.9787 Pre: 0.9597 Rec: 0.9674 F1: 0.9635\n",
      "TP: 2668.0 TN: 6609.0 FP: 112.0 FN: 90.0\n",
      "test Loss: 0.7178 Acc: 0.9680 Pre: 0.9619 Rec: 0.9359 F1: 0.9487\n",
      "TP: 2219.0 TN: 5037.0 FP: 88.0 FN: 152.0\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0089 Acc: 0.9981 Pre: 0.9934 Rec: 0.9999 F1: 0.9967\n",
      "TP: 18089.0 TN: 45920.0 FP: 120.0 FN: 1.0\n",
      "val Loss: 0.3267 Acc: 0.9746 Pre: 0.9442 Rec: 0.9699 F1: 0.9569\n",
      "TP: 2675.0 TN: 6563.0 FP: 158.0 FN: 83.0\n",
      "test Loss: 0.6135 Acc: 0.9686 Pre: 0.9568 Rec: 0.9435 F1: 0.9501\n",
      "TP: 2237.0 TN: 5024.0 FP: 101.0 FN: 134.0\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0090 Acc: 0.9981 Pre: 0.9935 Rec: 1.0000 F1: 0.9967\n",
      "TP: 18090.0 TN: 45921.0 FP: 119.0 FN: 0.0\n",
      "val Loss: 0.3156 Acc: 0.9710 Pre: 0.9309 Rec: 0.9724 F1: 0.9512\n",
      "TP: 2682.0 TN: 6522.0 FP: 199.0 FN: 76.0\n",
      "test Loss: 0.5544 Acc: 0.9696 Pre: 0.9515 Rec: 0.9523 F1: 0.9519\n",
      "TP: 2258.0 TN: 5010.0 FP: 115.0 FN: 113.0\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0088 Acc: 0.9982 Pre: 0.9937 Rec: 0.9999 F1: 0.9968\n",
      "TP: 18089.0 TN: 45925.0 FP: 115.0 FN: 1.0\n",
      "val Loss: 0.3116 Acc: 0.9719 Pre: 0.9332 Rec: 0.9732 F1: 0.9528\n",
      "TP: 2684.0 TN: 6529.0 FP: 192.0 FN: 74.0\n",
      "test Loss: 0.5525 Acc: 0.9688 Pre: 0.9503 Rec: 0.9511 F1: 0.9507\n",
      "TP: 2255.0 TN: 5007.0 FP: 118.0 FN: 116.0\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0090 Acc: 0.9981 Pre: 0.9932 Rec: 1.0000 F1: 0.9966\n",
      "TP: 18090.0 TN: 45916.0 FP: 124.0 FN: 0.0\n",
      "val Loss: 0.3233 Acc: 0.9756 Pre: 0.9476 Rec: 0.9699 F1: 0.9586\n",
      "TP: 2675.0 TN: 6573.0 FP: 148.0 FN: 83.0\n",
      "test Loss: 0.6050 Acc: 0.9689 Pre: 0.9564 Rec: 0.9447 F1: 0.9506\n",
      "TP: 2240.0 TN: 5023.0 FP: 102.0 FN: 131.0\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0096 Acc: 0.9983 Pre: 0.9940 Rec: 0.9999 F1: 0.9969\n",
      "TP: 18088.0 TN: 45931.0 FP: 109.0 FN: 2.0\n",
      "val Loss: 0.3495 Acc: 0.9786 Pre: 0.9584 Rec: 0.9685 F1: 0.9634\n",
      "TP: 2671.0 TN: 6605.0 FP: 116.0 FN: 87.0\n",
      "test Loss: 0.6702 Acc: 0.9686 Pre: 0.9615 Rec: 0.9384 F1: 0.9498\n",
      "TP: 2225.0 TN: 5036.0 FP: 89.0 FN: 146.0\n",
      "\n",
      "Training complete in 54m 43s\n",
      "Best epoch: 9\n",
      "Best val Acc: 0.978690\n",
      "Best val Pre: 0.958722\n",
      "Best val Rec: 0.968455\n",
      "Best val F1: 0.963564\n",
      "Test Acc: 0.968783\n"
     ]
    }
   ],
   "source": [
    "path = 'models/traditional_supervision_no_augmentation'\n",
    "for seed in range(1):\n",
    "    torch.manual_seed(seed)\n",
    "    model_ts = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ts.fc.in_features\n",
    "    model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    model_ts = model_ts.to(device)\n",
    "\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.]).to(device))\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.]).to(device))\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ts = optim.SGD(model_ts.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler_ts = lr_scheduler.StepLR(optimizer_ts, step_size=7, gamma=0.1)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'seed_{}.log'.format(seed)), 'w') as log_file:\n",
    "        model_ts = train_model(model_ts, criterion, optimizer_ts, exp_lr_scheduler_ts,\n",
    "                               'train', 'val', test_dl='test', num_epochs=25, verbose=True,\n",
    "                               log_file=log_file, return_best=True)\n",
    "        torch.save(model_ts.state_dict(), os.path.join(path, 'seed_{}.pth'.format(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/traditional_supervision_no_augmentation'\n",
    "model_ts = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ts.fc.in_features\n",
    "model_ts.fc = nn.Linear(num_ftrs, 1)\n",
    "model_ts.load_state_dict(torch.load(\n",
    "    os.path.join(path, 'seed_0.pth')\n",
    "))\n",
    "model_ts.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ts.eval()   # Set model to evaluate mode\n",
    "dl = dataloaders['val']\n",
    "dataset_size = dataset_sizes['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_negs(predictions, gt):\n",
    "    correct = np.where(np.array(predictions) == np.array(gt), 1, 0)\n",
    "    incorrect = np.where(np.array(predictions) == np.array(gt), 0, 1)\n",
    "    \n",
    "    tp = np.where(correct * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    tn = np.where(correct * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    fp = np.where(incorrect * np.where(predictions == np.array(1), 1, 0), 1, 0)\n",
    "    fn = np.where(incorrect * np.where(predictions == np.array(0), 1, 0), 1, 0)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def acc_prf1(predictions, gt):\n",
    "    tp, tn, fp, fn = pos_negs(predictions, gt)\n",
    "    \n",
    "    acc = (np.sum(tp) + np.sum(tn)) / (np.sum(tp) + np.sum(tn) + np.sum(fp) + np.sum(fn))\n",
    "    precision = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return acc, precision, recall, f1, np.sum(tp), np.sum(tn), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def smooth_predictions(preds, window_radius = 3):\n",
    "    result = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_radius)\n",
    "        end = min(len(preds), i + window_radius)\n",
    "        window = preds[start:end]\n",
    "        result += [max(window, key=window.count)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9787 Pre: 0.9587 Rec: 0.9685 F1: 0.9636\n",
      "TP: 2671.0 TN: 6606.0 FP: 115.0 FN: 87.0\n",
      "Smoothed stats:\n",
      "(0.9592784048950311, 0.93033381712627, 0.9296591733139956, 0.9299963728690607, 2564, 6529, 192, 194)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "true_positives = 0.\n",
    "true_negatives = 0.\n",
    "false_positives = 0.\n",
    "false_negatives = 0.\n",
    "\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "gt_labels = []\n",
    "# Iterate over data.\n",
    "for inputs, labels in dl:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.where(\n",
    "            outputs >= 0.,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "        target = torch.where(\n",
    "            labels >= 0.5,\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device)\n",
    "        )\n",
    "        \n",
    "    predictions += preds.cpu().numpy().tolist()\n",
    "    gt_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # statistics\n",
    "    label_vals = torch.where(\n",
    "        labels >= 0.5,\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device)\n",
    "    )\n",
    "    correct = preds.view(label_vals.shape) == label_vals.data\n",
    "    running_corrects += torch.sum(correct)\n",
    "\n",
    "    true_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    true_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 1.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_positives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 0.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    false_negatives += torch.sum(\n",
    "        torch.where(\n",
    "            (correct == 0.) * (label_vals == 1.),\n",
    "            torch.tensor([1.]).to(device),\n",
    "            torch.tensor([0.]).to(device))\n",
    "    )\n",
    "    \n",
    "    num_fp = torch.sum(\n",
    "    torch.where(\n",
    "        (correct == 0.) * (label_vals == 0.),\n",
    "        torch.tensor([1.]).to(device),\n",
    "        torch.tensor([0.]).to(device))\n",
    "    )\n",
    "\n",
    "#     if num_fp > 0:\n",
    "#         print(num_fp)\n",
    "#         print(torch.where(\n",
    "#             (correct == 0.) * (label_vals == 0.),\n",
    "#             torch.tensor([1.]).to(device),\n",
    "#             torch.tensor([0.]).to(device)))\n",
    "#         print(i)\n",
    "#         out = torchvision.utils.make_grid(inputs)\n",
    "# #         imshow(out, title=preds.cpu().numpy().tolist())\n",
    "#         imshow(out)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "epoch_acc = running_corrects.double() / dataset_size\n",
    "epoch_pre = safe_divide(true_positives, (true_positives + false_positives))\n",
    "epoch_recall = safe_divide(true_positives, (true_positives + false_negatives))\n",
    "epoch_f1 = safe_divide(2 * epoch_pre * epoch_recall, (epoch_pre + epoch_recall))\n",
    "\n",
    "print('Acc: {:.4f} Pre: {:.4f} Rec: {:.4f} F1: {:.4f}'.format(\n",
    "    epoch_acc, epoch_pre, epoch_recall, epoch_f1))\n",
    "print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "    true_positives.data, true_negatives.data, false_positives.data, false_negatives.data))\n",
    "\n",
    "predictions = [p[0] for p in predictions]\n",
    "\n",
    "smoothed_preds = smooth_predictions(predictions, 3)\n",
    "\n",
    "print(\"Smoothed stats:\")\n",
    "print(acc_prf1(smoothed_preds, gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sequential_ws] *",
   "language": "python",
   "name": "conda-env-sequential_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
